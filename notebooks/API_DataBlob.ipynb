{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b1eceb09",
   "metadata": {},
   "source": [
    "---\n",
    "description: This module contains all classes encapsulating the datablob routes of\n",
    "  the the server.\n",
    "output-file: api_datablob.html\n",
    "title: API_DataBlob\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882516b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp components.datablob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08a7958",
   "metadata": {},
   "source": [
    "Note: \n",
    "\n",
    "While writing doc strings, please use the below syntax for linking methods/classes. So that the methods/classes gets highlighted in the browser and clicking on it will take the user to the linked function\n",
    "\n",
    "    - To link a method from the class same file please use the `method_name` format.\n",
    "    - To link a method from a different Class (can in a seperate file also) please use `Classname.method_name` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a456e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt.testing.activate_by_import: Testing environment activated.\n"
     ]
    }
   ],
   "source": [
    "from airt.testing import activate_by_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d63a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542b956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import pandas as pd\n",
    "from fastcore.foundation import patch\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from airt.logger import get_logger, set_level\n",
    "from airt.helper import (\n",
    "    get_data,\n",
    "    post_data,\n",
    "    delete_data,\n",
    "    add_ready_column,\n",
    "    generate_df,\n",
    "    get_values_from_item,\n",
    "    get_attributes_from_instances,\n",
    "    add_example_to_docs\n",
    ")\n",
    "\n",
    "from airt.components.client import Client\n",
    "from airt.components.datasource import DataSource\n",
    "from airt.components.progress_status import ProgressStatus\n",
    "from airt.constant import CLIENT_DB_USERNAME, CLIENT_DB_PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91219338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import quote_plus as urlquote\n",
    "\n",
    "import logging\n",
    "import pytest\n",
    "import tempfile\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "from sqlmodel import create_engine\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.mgmt.storage import StorageManagementClient\n",
    "\n",
    "import airt.sanitizer\n",
    "from airt.docstring.helpers import run_examples_from_docstring\n",
    "from airt.constant import SERVICE_USERNAME, SERVICE_PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b675308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5664f29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: This is an info\n",
      "[WARNING] __main__: This is a warning\n",
      "[ERROR] __main__: This is an error\n"
     ]
    }
   ],
   "source": [
    "display(logger.getEffectiveLevel())\n",
    "assert logger.getEffectiveLevel() == logging.INFO\n",
    "\n",
    "logger.debug(\"This is a debug message\")\n",
    "logger.info(\"This is an info\")\n",
    "logger.warning(\"This is a warning\")\n",
    "logger.error(\"This is an error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c43fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_S3_URI = \"s3://test-airt-service/ecommerce_behavior_notebooks\"\n",
    "TEST_S3_CSV_URI = \"s3://test-airt-service/ecommerce_behavior_csv\"\n",
    "TEST_AZURE_URI = \"https://testairtservice.blob.core.windows.net/test-container/ecommerce_behavior_notebooks\"\n",
    "RANDOM_UUID_FOR_TESTING = \"00000000-0000-0000-0000-000000000000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85334dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "DEFAULT_AZURE_BLOB_STORAGE_REGION = \"westeurope\"\n",
    "DEFAULT_S3_REGION = \"eu-west-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6fc713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "class DataBlob:\n",
    "    \"\"\"A class for importing and processing data from sources such as CSV/parquet files, databases, AWS S3 buckets, and Azure Blob Storage.\n",
    "\n",
    "    Currently, the only way to instantiate the DataBlob class is to call one of the following static methods\n",
    "    `from_local`, `from_mysql`, `from_clickhouse`, `from_s3`, or `from_azure_blob_storage` which imports the data in\n",
    "    the parquet file format from:\n",
    "\n",
    "     - a local CSV/parquet file,\n",
    "\n",
    "     - a MySql database,\n",
    "\n",
    "     - a ClickHouse database\n",
    "\n",
    "     - an AWS S3 bucket, and\n",
    "\n",
    "     - an Azure Blob Storage respectively.\n",
    "\n",
    "    We intend to support additional databases and storage mediums in future releases.\n",
    "    \"\"\"\n",
    "\n",
    "    BASIC_DB_COLS = [\n",
    "        \"uuid\",\n",
    "        \"datasources\",\n",
    "        \"type\",\n",
    "        \"source\",\n",
    "        \"region\",\n",
    "        \"cloud_provider\",\n",
    "        \"tags\",\n",
    "        \"pulled_on\",\n",
    "        \"completed_steps\",\n",
    "        \"total_steps\",\n",
    "        \"folder_size\",\n",
    "    ]\n",
    "\n",
    "    ALL_DB_COLS = BASIC_DB_COLS + [\"user\", \"error\", \"disabled\"]\n",
    "\n",
    "    COLS_TO_RENAME = {\n",
    "        \"uuid\": \"datablob_uuid\",\n",
    "        \"datasources\": \"datasource_uuids\",\n",
    "        \"user\": \"user_uuid\",\n",
    "    }\n",
    "\n",
    "    _default_provider_and_regions: List[Tuple[str, str]] = []\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        uuid: str,\n",
    "        type: Optional[str] = None,\n",
    "        source: Optional[str] = None,\n",
    "        region: Optional[str] = None,\n",
    "        cloud_provider: Optional[str] = None,\n",
    "        datasources: Optional[List[str]] = None,\n",
    "        total_steps: Optional[int] = None,\n",
    "        completed_steps: Optional[int] = None,\n",
    "        folder_size: Optional[int] = None,\n",
    "        disabled: Optional[bool] = None,\n",
    "        pulled_on: Optional[str] = None,\n",
    "        user: Optional[str] = None,\n",
    "        tags: Optional[List] = None,\n",
    "        error: Optional[str] = None,\n",
    "    ):\n",
    "        \"\"\"Constructs a new DataBlob instance.\n",
    "\n",
    "        Warning:\n",
    "            Do not construct this object directly by calling the constructor, please use `from_s3`, `from_azure_blob_storage`, \n",
    "            `from_mysql`, `from_clickhouse` or `from_local` methods instead.\n",
    "\n",
    "        Args:\n",
    "            uuid: Datablob uuid.\n",
    "            source: The URI of the data that was used to create the datablob.\n",
    "            type: The type of source used to generate the datablob. Depending on the source type, one of the following \n",
    "                values will be assigned: \"s3\", \"local\", \"db\", or \"azure_blob_storage\".\n",
    "            region: The destination cloud provider's region to store the datablob. If None (default value) then the default region will be assigned based on the cloud provider.\n",
    "            cloud_provider: Cloud storage provider's name to store the datablob. Currently, the API only supports **aws** and **azure** as cloud storage providers.\n",
    "            datasources: The uuids of the datasources created from the datablob.\n",
    "            total_steps: The number of steps required to upload the datablob to the server.\n",
    "            completed_steps: The number of steps completed during the datablob's upload to the server.\n",
    "            folder_size: The uploaded datablob's size in bytes.\n",
    "            disabled: A flag that indicates the datablob's status. If the datablob is deleted, then **False** will be set.\n",
    "            pulled_on: The most recent date the datablob was uploaded.\n",
    "            user: The uuid of the user who created the datablob.\n",
    "            tags: Tag names associated with the datablob.\n",
    "            error: Contains the error message if the processing of the datablob fails.\n",
    "        \"\"\"\n",
    "        self.uuid = uuid\n",
    "        self.type = type\n",
    "        self.source = source\n",
    "        self.region = region\n",
    "        self.cloud_provider = cloud_provider\n",
    "        self.datasources = datasources\n",
    "        self.total_steps = total_steps\n",
    "        self.completed_steps = completed_steps\n",
    "        self.folder_size = folder_size\n",
    "        self.disabled = disabled\n",
    "        self.pulled_on = pulled_on\n",
    "        self.user = user\n",
    "        self.tags = tags\n",
    "        self.error = error\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_tag_name_and_datasource_id(res: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Get tag name and datasource ids as string seperated by comma.\n",
    "\n",
    "        Args:\n",
    "            res: The response object.\n",
    "\n",
    "        Returns:\n",
    "            The modified response object with tag name and datasource ids as string seperated by comma.\n",
    "        \"\"\"\n",
    "        res[\"tags\"] = get_values_from_item(res[\"tags\"], \"name\")\n",
    "        res[\"datasources\"] = get_values_from_item(res[\"datasources\"])\n",
    "\n",
    "        return res\n",
    "\n",
    "    @staticmethod\n",
    "    def from_s3(\n",
    "        *,\n",
    "        uri: str,\n",
    "        access_key: Optional[str] = None,\n",
    "        secret_key: Optional[str] = None,\n",
    "        cloud_provider: Optional[str] = None,\n",
    "        region: Optional[str] = None,\n",
    "        tag: Optional[str] = None,\n",
    "    ) -> \"DataBlob\":\n",
    "        \"\"\"Create and return a datablob that encapsulates the data from an AWS S3 bucket.\n",
    "\n",
    "        Args:\n",
    "            uri: AWS S3 bucket uri.\n",
    "            access_key: Access key for the S3 bucket. If **None** (default value), then the value\n",
    "                from **AWS_ACCESS_KEY_ID** environment variable will be used.\n",
    "            secret_key: Secret key for the S3 bucket. If **None** (default value), then the value\n",
    "                from **AWS_SECRET_ACCESS_KEY** environment variable will be used.\n",
    "            cloud_provider: The destination cloud storage provider's name to store the datablob. Currently, the API only supports **aws** and **azure** as cloud storage providers.\n",
    "                If **None** (default value), then **aws**  will be used as the cloud storage provider.\n",
    "            region: The region of the destination cloud provider where the datablob will be stored. If **None** (default value) then the default region will be assigned based on \n",
    "                the cloud provider. In the case of **aws**, the datablob's source bucket region will be used, whereas **azure** will use **westeurope**. The supported AWS regions \n",
    "                are: ap-northeast-1, ap-northeast-2, ap-south-1, ap-southeast-1, ap-southeast-2, ca-central-1, eu-central-1, eu-north-1, eu-west-1, eu-west-2, eu-west-3, sa-east-1, \n",
    "                us-east-1, us-east-2, us-west-1, us-west-2. The supported Azure Blob Storage regions are: australiacentral, australiacentral2, australiaeast, australiasoutheast, \n",
    "                brazilsouth, canadacentral, canadaeast, centralindia, centralus, eastasia, eastus, eastus2, francecentral, francesouth, germanynorth, germanywestcentral, japaneast, \n",
    "                japanwest, koreacentral, koreasouth, northcentralus, northeurope, norwayeast, norwaywest, southafricanorth, southafricawest, southcentralus, southeastasia, southindia, \n",
    "                switzerlandnorth, switzerlandwest, uaecentral, uaenorth, uksouth, ukwest, westcentralus, westeurope, westindia, westus, westus2.\n",
    "            tag: A string to tag the datablob. If not passed, then the tag **latest** will be assigned to the datablob.\n",
    "\n",
    "        Returns:\n",
    "            An instance of the `DataBlob` class.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If parameters to the API are invalid.\n",
    "            ConnectionError: If the server address is invalid or not reachable.\n",
    "\n",
    "        Here's an example of how to create a Datablob from an AWS S3 bucket:\n",
    "        \n",
    "        Example:\n",
    "            ```python\n",
    "            # Importing necessary libraries\n",
    "            from  airt.client import Client, DataBlob\n",
    "\n",
    "            # Authenticate\n",
    "            Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")\n",
    "\n",
    "            # Create a datablob\n",
    "            # In this example, the access_key and the secret_key are set in the \n",
    "            # AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables. The region\n",
    "            # is set to eu-west-3, feel free to change the cloud provider and the region \n",
    "            # to suit your needs.\n",
    "            db = DataBlob.from_s3(\n",
    "                uri=\"{fill in uri}\",\n",
    "                cloud_provider=\"aws\",\n",
    "                region=\"eu-west-3\"\n",
    "            )\n",
    "            \n",
    "            # Display the status in a progress bar\n",
    "            db.progress_bar()\n",
    "\n",
    "            # Print the details of the newly created datablob\n",
    "            # If the upload is successful, the ready flag should be set to True\n",
    "            print(db.details())\n",
    "            ```\n",
    "        \"\"\"\n",
    "        access_key = (\n",
    "            access_key if access_key is not None else os.environ[\"AWS_ACCESS_KEY_ID\"]\n",
    "        )\n",
    "        secret_key = (\n",
    "            secret_key\n",
    "            if secret_key is not None\n",
    "            else os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "        )\n",
    "        \n",
    "        cloud_provider, region = DataBlob._get_cloud_provider_and_region(cloud_provider=cloud_provider, region=region, set_source_region=True) # type: ignore\n",
    "\n",
    "        response = Client._post_data(\n",
    "            relative_url=\"/datablob/from_s3\",\n",
    "            json=dict(\n",
    "                uri=uri,\n",
    "                access_key=access_key,\n",
    "                secret_key=secret_key,\n",
    "                region=region,\n",
    "                cloud_provider=cloud_provider,\n",
    "                tag=tag,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return DataBlob(\n",
    "            uuid=response[\"uuid\"], type=response[\"type\"], source=response[\"source\"]\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def from_azure_blob_storage(\n",
    "        cls,\n",
    "        uri: str,\n",
    "        credential: str,\n",
    "        cloud_provider: Optional[str] = None,\n",
    "        region: Optional[str] = None,\n",
    "        tag: Optional[str] = None,\n",
    "    ) -> \"DataBlob\":\n",
    "        \"\"\"Create and return a datablob that encapsulates the data from an Azure Blob Storage.\n",
    "\n",
    "        Args:\n",
    "            uri: Azure Blob Storage URI of the source file.\n",
    "            credential: Credential to access the Azure Blob Storage.\n",
    "            cloud_provider: The destination cloud storage provider's name to store the datablob. Currently, the API only supports **aws** and **azure** as cloud storage providers.\n",
    "                If **None** (default value), then **azure**  will be used as the cloud storage provider.\n",
    "            region: The destination cloud provider's region to store the datablob. If **None** (default value) then the default region will be assigned based on the cloud \n",
    "                provider. In the case of **aws**, **eu-west-1** will be used and in the case of **azure**, **westeurope** will be used. The supported AWS regions \n",
    "                are: ap-northeast-1, ap-northeast-2, ap-south-1, ap-southeast-1, ap-southeast-2, ca-central-1, eu-central-1, eu-north-1, eu-west-1, eu-west-2, eu-west-3, sa-east-1, \n",
    "                us-east-1, us-east-2, us-west-1, us-west-2. The supported Azure Blob Storage regions are: australiacentral, australiacentral2, australiaeast, australiasoutheast, \n",
    "                brazilsouth, canadacentral, canadaeast, centralindia, centralus, eastasia, eastus, eastus2, francecentral, francesouth, germanynorth, germanywestcentral, japaneast, \n",
    "                japanwest, koreacentral, koreasouth, northcentralus, northeurope, norwayeast, norwaywest, southafricanorth, southafricawest, southcentralus, southeastasia, southindia, \n",
    "                switzerlandnorth, switzerlandwest, uaecentral, uaenorth, uksouth, ukwest, westcentralus, westeurope, westindia, westus, westus2.\n",
    "            tag: A string to tag the datablob. If not passed, then the tag **latest** will be assigned to the datablob.\n",
    "\n",
    "        Returns:\n",
    "            An instance of the `DataBlob` class.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If parameters to the API are invalid.\n",
    "            ConnectionError: If the server address is invalid or not reachable.\n",
    "            \n",
    "        To create a Datablob from Azure Blob Storage, you must have a valid Azure Blob Storage credential.\n",
    "\n",
    "        If you don't know how to get the Azure Blob Storage credential, you can follow the below python example. It's one of the ways to get the Azure Blob Storage credential.\n",
    "\n",
    "        - If you don't already have it, please install the Azure Storage Management (azure-mgmt-storage) and Azure Resource Management (azure-mgmt-resource) python client libraries using pip.\n",
    "\n",
    "        - Ensure the following four environment variables are set into your current working environment with appropriate values.\n",
    "\n",
    "            - AZURE_TENANT_ID\n",
    "\n",
    "            - AZURE_CLIENT_ID\n",
    "\n",
    "            - AZURE_CLIENT_SECRET\n",
    "\n",
    "            - AZURE_SUBSCRIPTION_ID\n",
    "\n",
    "        - Assign the resource group name in the GROUP_NAME variable and the storage account name in the STORAGE_ACCOUNT_NAME variable.\n",
    "\n",
    "        - Below is a sample code to create a datablob and storing it in S3. Please copy it and replace the placeholders with appropriate values\n",
    "            \n",
    "        Example:\n",
    "            ```python\n",
    "            # Importing necessary libraries\n",
    "            import os\n",
    "\n",
    "            from azure.identity import DefaultAzureCredential\n",
    "            from azure.mgmt.storage import StorageManagementClient\n",
    "\n",
    "            from  airt.client import Client, DataBlob\n",
    "\n",
    "            # Create a credential for accessing Azure Blob Storage\n",
    "            # Setting the required environment variables\n",
    "            os.environ[\"AZURE_SUBSCRIPTION_ID\"] = \"{fill in azure_subscription_id}\"\n",
    "            os.environ[\"AZURE_CLIENT_ID\"] = \"{fill in azure_client_id}\"\n",
    "            os.environ[\"AZURE_CLIENT_SECRET\"] = \"{fill in azure_client_secret}\"\n",
    "            os.environ[\"AZURE_TENANT_ID\"]= \"{fill in azure_tenant_id}\"\n",
    "\n",
    "            # Setting the resource group name and storage account name\n",
    "            azure_group_name = \"{fill in azure_group_name}\"\n",
    "            azure_storage_account_name = \"{fill in azure_storage_account_name}\"\n",
    "\n",
    "            # Retrieving the credential\n",
    "            azure_storage_client = StorageManagementClient(\n",
    "                DefaultAzureCredential(), os.environ[\"AZURE_SUBSCRIPTION_ID\"]\n",
    "            )\n",
    "            azure_storage_keys = azure_storage_client.storage_accounts.list_keys(\n",
    "                azure_group_name, azure_storage_account_name\n",
    "            )\n",
    "            azure_storage_keys = {v.key_name: v.value for v in azure_storage_keys.keys}\n",
    "            credential = azure_storage_keys['key1']\n",
    "\n",
    "\n",
    "            # Authenticate\n",
    "            Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")\n",
    "            \n",
    "            # Create a datablob\n",
    "            # In this example, the datablob will be stored in an AWS S3 bucket. The region\n",
    "            # is set to eu-west-1 (default), feel free to change the cloud provider and\n",
    "            # the region to suit your needs.\n",
    "            db = DataBlob.from_azure_blob_storage(\n",
    "                uri=\"{fill in uri}\",\n",
    "                cloud_provider=\"aws\", \n",
    "                credential=credential\n",
    "            )\n",
    "            \n",
    "            # Display the status in a progress bar\n",
    "            db.progress_bar()\n",
    "            \n",
    "            # Print the details of the newly created datablob\n",
    "            # If the upload is successful, the ready flag should be set to True\n",
    "            print(db.details())\n",
    "            ```\n",
    "        \"\"\"\n",
    "        cloud_provider, region = DataBlob._get_cloud_provider_and_region(cloud_provider=cloud_provider, region=region, default_cloud_provider=\"azure\") # type: ignore\n",
    "\n",
    "        response = Client._post_data(\n",
    "            relative_url=\"/datablob/from_azure_blob_storage\",\n",
    "            json=dict(\n",
    "                uri=uri,\n",
    "                credential=credential,\n",
    "                region=region,\n",
    "                cloud_provider=cloud_provider,\n",
    "                tag=tag,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return DataBlob(\n",
    "            uuid=response[\"uuid\"], type=response[\"type\"], source=response[\"source\"]\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def from_mysql(\n",
    "        *,\n",
    "        host: str,\n",
    "        database: str,\n",
    "        table: str,\n",
    "        port: int = 3306,\n",
    "        cloud_provider: Optional[str] = None,\n",
    "        region: Optional[str] = None,\n",
    "        username: Optional[str] = None,\n",
    "        password: Optional[str] = None,\n",
    "        tag: Optional[str] = None,\n",
    "    ) -> \"DataBlob\":\n",
    "        \"\"\"Create and return a datablob that encapsulates the data from a mysql database.\n",
    "\n",
    "        If the database requires authentication, pass the username/password as parameters or store it in\n",
    "        the **AIRT_CLIENT_DB_USERNAME** and **AIRT_CLIENT_DB_PASSWORD** environment variables.\n",
    "\n",
    "        Args:\n",
    "            host: Remote database host name.\n",
    "            database: Database name.\n",
    "            table: Table name.\n",
    "            port: Host port number. If not passed, then the default value **3306** will be used.\n",
    "            cloud_provider: The destination cloud storage provider's name to store the datablob. Currently, the API only supports **aws** and **azure** as cloud storage providers.\n",
    "                If **None** (default value), then **aws**  will be used as the cloud storage provider.\n",
    "            region: The destination cloud provider's region to store the datablob. If **None** (default value) then the default region will be assigned based on the cloud \n",
    "                provider. In the case of **aws**, **eu-west-1** will be used and in the case of **azure**, **westeurope** will be used. The supported AWS regions \n",
    "                are: ap-northeast-1, ap-northeast-2, ap-south-1, ap-southeast-1, ap-southeast-2, ca-central-1, eu-central-1, eu-north-1, eu-west-1, eu-west-2, eu-west-3, sa-east-1, \n",
    "                us-east-1, us-east-2, us-west-1, us-west-2. The supported Azure Blob Storage regions are: australiacentral, australiacentral2, australiaeast, australiasoutheast, \n",
    "                brazilsouth, canadacentral, canadaeast, centralindia, centralus, eastasia, eastus, eastus2, francecentral, francesouth, germanynorth, germanywestcentral, japaneast, \n",
    "                japanwest, koreacentral, koreasouth, northcentralus, northeurope, norwayeast, norwaywest, southafricanorth, southafricawest, southcentralus, southeastasia, southindia, \n",
    "                switzerlandnorth, switzerlandwest, uaecentral, uaenorth, uksouth, ukwest, westcentralus, westeurope, westindia, westus, westus2.\n",
    "            username: Database username. If not passed, the default value **\"root\"** will be used unless the value is explicitly set in the environment variable \n",
    "                **AIRT_CLIENT_DB_USERNAME**.            \n",
    "            password: Database password. If not passed, the default value **\"\"** will be used unless the value is explicitly set in the environment variable \n",
    "                **AIRT_CLIENT_DB_PASSWORD**. \n",
    "            tag: A string to tag the datablob. If not passed, then the tag **latest** will be assigned to the datablob.\n",
    "\n",
    "        Returns:\n",
    "           An instance of the `DataBlob` class.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If parameters to the API are invalid.\n",
    "            ConnectionError: If the server address is invalid or not reachable.\n",
    "\n",
    "        Here's an example of how to create a Datablob from a MySQL database:\n",
    "        \n",
    "        Example:\n",
    "            ```python\n",
    "            # Importing necessary libraries\n",
    "            from  airt.client import Client, DataBlob\n",
    "\n",
    "            # Authenticate\n",
    "            Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")\n",
    "\n",
    "            # Create a datablob\n",
    "            # In this example, the datablob will be stored in an AWS S3 bucket. The region\n",
    "            # is set to eu-west-3, feel free to change the cloud provider and the region \n",
    "            # to suit your needs.\n",
    "            db = DataBlob.from_mysql(\n",
    "                username=\"{fill in database_username}\",\n",
    "                password=\"{fill in database_password}\",\n",
    "                host=\"{fill in host}\",\n",
    "                database=\"{fill in database}\",\n",
    "                table=\"{fill in table}\",\n",
    "                port=\"{fill in port}\",\n",
    "                cloud_provider=\"aws\",\n",
    "                region=\"eu-west-3\"\n",
    "            )\n",
    "\n",
    "            # Display the status in a progress bar\n",
    "            db.progress_bar()\n",
    "\n",
    "            # Print the details of the newly created datablob\n",
    "            # If the upload is successful, the ready flag should be set to True\n",
    "            print(db.details())\n",
    "            ```\n",
    "        \"\"\"\n",
    "        username = (\n",
    "            username\n",
    "            if username is not None\n",
    "            else os.environ.get(CLIENT_DB_USERNAME, \"root\")\n",
    "        )\n",
    "\n",
    "        password = (\n",
    "            password if password is not None else os.environ.get(CLIENT_DB_PASSWORD, \"\")\n",
    "        )\n",
    "\n",
    "        cloud_provider, region = DataBlob._get_cloud_provider_and_region(cloud_provider, region) # type: ignore\n",
    "\n",
    "        json_req = dict(\n",
    "            host=host,\n",
    "            port=port,\n",
    "            username=username,\n",
    "            password=password,\n",
    "            database=database,\n",
    "            table=table,\n",
    "            region=region,\n",
    "            cloud_provider=cloud_provider,\n",
    "            tag=tag,\n",
    "        )\n",
    "\n",
    "        response = Client._post_data(relative_url=f\"/datablob/from_mysql\", json=json_req)\n",
    "\n",
    "        return DataBlob(\n",
    "            uuid=response[\"uuid\"], type=response[\"type\"], source=response[\"source\"]\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def from_clickhouse(\n",
    "        *,\n",
    "        host: str,\n",
    "        database: str,\n",
    "        table: str,\n",
    "        protocol: str,\n",
    "        index_column: str,\n",
    "        timestamp_column: str,\n",
    "        port: int = 0,\n",
    "        cloud_provider: Optional[str] = None,\n",
    "        region: Optional[str] = None,\n",
    "        username: Optional[str] = None,\n",
    "        password: Optional[str] = None,\n",
    "        filters: Optional[Dict[str, Any]] = None,\n",
    "        tag: Optional[str] = None,\n",
    "    ) -> \"DataBlob\":\n",
    "        \"\"\"Create and return a datablob that encapsulates the data from a ClickHouse database.\n",
    "\n",
    "        If the database requires authentication, pass the username/password as parameters or store it in\n",
    "        the **CLICKHOUSE_USERNAME** and **CLICKHOUSE_PASSWORD** environment variables.\n",
    "\n",
    "        Args:\n",
    "            host: Remote database host name.\n",
    "            database: Database name.\n",
    "            table: Table name.\n",
    "            protocol: Protocol to use. The valid values are \"native\" and \"http\".\n",
    "            index_column: The column to use as index (row labels).\n",
    "            timestamp_column: Timestamp column name in the tabel.\n",
    "            port: Host port number. If not passed, then the default value **0** will be used.\n",
    "            cloud_provider: The destination cloud storage provider's name to store the datablob. Currently, the API only supports **aws** and **azure** as cloud storage providers.\n",
    "                If **None** (default value), then **aws**  will be used as the cloud storage provider.\n",
    "            region: The destination cloud provider's region to store the datablob. If **None** (default value) then the default region will be assigned based on the cloud \n",
    "                provider. In the case of **aws**, **eu-west-1** will be used and in the case of **azure**, **westeurope** will be used. The supported AWS regions \n",
    "                are: ap-northeast-1, ap-northeast-2, ap-south-1, ap-southeast-1, ap-southeast-2, ca-central-1, eu-central-1, eu-north-1, eu-west-1, eu-west-2, eu-west-3, sa-east-1, \n",
    "                us-east-1, us-east-2, us-west-1, us-west-2. The supported Azure Blob Storage regions are: australiacentral, australiacentral2, australiaeast, australiasoutheast, \n",
    "                brazilsouth, canadacentral, canadaeast, centralindia, centralus, eastasia, eastus, eastus2, francecentral, francesouth, germanynorth, germanywestcentral, japaneast, \n",
    "                japanwest, koreacentral, koreasouth, northcentralus, northeurope, norwayeast, norwaywest, southafricanorth, southafricawest, southcentralus, southeastasia, southindia, \n",
    "                switzerlandnorth, switzerlandwest, uaecentral, uaenorth, uksouth, ukwest, westcentralus, westeurope, westindia, westus, westus2.\n",
    "            username: Database username. If not passed, the default value \"root\" will be used unless the value is explicitly set in the environment variable \n",
    "                **CLICKHOUSE_USERNAME**.\n",
    "            password: Database password. If not passed, the default value \"root\" will be used unless the value is explicitly set in the environment variable \n",
    "                **CLICKHOUSE_PASSWORD**.            \n",
    "            filters: Additional parameters to be used when importing data. For example, if you want to filter and extract data only for a specific user_id, pass {\"user_id\": 1}.\n",
    "            tag: A string to tag the datablob. If not passed, then the tag **latest** will be assigned to the datablob.\n",
    "\n",
    "        Returns:\n",
    "           An instance of the `DataBlob` class.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If parameters to the API are invalid.\n",
    "            ConnectionError: If the server address is invalid or not reachable.\n",
    "\n",
    "        Here's an example of how to create a Datablob from a ClickHouse database:\n",
    "        \n",
    "        Example:\n",
    "            ```python\n",
    "            # Importing necessary libraries\n",
    "            from  airt.client import Client, DataBlob\n",
    "\n",
    "            # Authenticate\n",
    "            Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")\n",
    "\n",
    "            # Create a datablob\n",
    "            # In this example, the datablob will be stored in an AWS S3 bucket. The region\n",
    "            # is set to eu-west-3, feel free to change the cloud provider and the region \n",
    "            # to suit your needs.\n",
    "            db = DataBlob.from_clickhouse(\n",
    "                username=\"{fill in database_username}\",\n",
    "                password=\"{fill in database_password}\",\n",
    "                host=\"{fill in host}\",\n",
    "                database=\"{fill in database}\",\n",
    "                table=\"{fill in table}\",\n",
    "                index_column=\"{fill in index_column}\",\n",
    "                timestamp_column=\"{fill in timestamp_column}\",\n",
    "                port=\"{fill in port}\", \n",
    "                filters={fill in filters},\n",
    "                protocol=\"native\",\n",
    "                cloud_provider=\"aws\",\n",
    "                region=\"eu-west-3\"\n",
    "            )\n",
    "\n",
    "            # Display the status in a progress bar\n",
    "            db.progress_bar()\n",
    "\n",
    "            # Print the details of the newly created datablob\n",
    "            # If the upload is successful, the ready flag should be set to True\n",
    "            print(db.details())\n",
    "            ```\n",
    "        \"\"\"\n",
    "        username = (\n",
    "            username\n",
    "            if username is not None\n",
    "            else os.environ.get(\"CLICKHOUSE_USERNAME\", \"root\")\n",
    "        )\n",
    "\n",
    "        password = (\n",
    "            password\n",
    "            if password is not None\n",
    "            else os.environ.get(\"CLICKHOUSE_PASSWORD\", \"\")\n",
    "        )\n",
    "\n",
    "        cloud_provider, region = DataBlob._get_cloud_provider_and_region(cloud_provider, region) # type: ignore\n",
    "\n",
    "        json_req = dict(\n",
    "            host=host,\n",
    "            database=database,\n",
    "            table=table,\n",
    "            protocol=protocol,\n",
    "            port=port,\n",
    "            username=username,\n",
    "            password=password,\n",
    "            index_column=index_column,\n",
    "            timestamp_column=timestamp_column,\n",
    "            filters=filters,\n",
    "            region=region,\n",
    "            cloud_provider=cloud_provider,\n",
    "            tag=tag,\n",
    "        )\n",
    "\n",
    "        response = Client._post_data(\n",
    "            relative_url=f\"/datablob/from_clickhouse\", json=json_req\n",
    "        )\n",
    "\n",
    "        return DataBlob(\n",
    "            uuid=response[\"uuid\"], type=response[\"type\"], source=response[\"source\"]\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _upload_to_s3_with_retry(\n",
    "        file_to_upload: Path,\n",
    "        presigned_url: str,\n",
    "        presigned_fields: Dict[str, Any],\n",
    "        max_retry: int = 3,\n",
    "        curr_iteration: int = 1,\n",
    "    ):\n",
    "        \"\"\"Upload local files to s3 using presigned url\n",
    "\n",
    "        Args:\n",
    "            file_to_upload: path of file to upload\n",
    "            presigned_url: presigned url to upload to\n",
    "            presigned_fields: presigned fields provided by boto3\n",
    "            max_retry: maximum retry count\n",
    "            curr_iteration: current iteration count for internal use\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(file_to_upload, \"rb\") as f:\n",
    "                files = {\"file\": (str(file_to_upload), f)}\n",
    "                response = requests.post(\n",
    "                    presigned_url, data=presigned_fields, files=files\n",
    "                )\n",
    "                if not response.status_code == 204:\n",
    "                    raise ValueError(response.text)\n",
    "\n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            if curr_iteration == max_retry:\n",
    "                raise e\n",
    "            DataBlob._upload_to_s3_with_retry(\n",
    "                file_to_upload,\n",
    "                presigned_url,\n",
    "                presigned_fields,\n",
    "                max_retry,\n",
    "                curr_iteration + 1,\n",
    "            )\n",
    "\n",
    "    @staticmethod\n",
    "    def from_local(\n",
    "        path: Union[str, Path],\n",
    "        cloud_provider: Optional[str] = None,\n",
    "        region: Optional[str] = None,\n",
    "        tag: Optional[str] = None,\n",
    "        show_progress: Optional[bool] = True,\n",
    "    ) -> \"DataBlob\":\n",
    "        \"\"\"Create and return a datablob from local file.\n",
    "        \n",
    "        The API currently allows users to create datablobs from CSV or Parquet files. We intend to support additional file formats in future releases.\n",
    "\n",
    "        Args:\n",
    "            path: The relative or absolute path to a local file or to a directory containing the source files.\n",
    "            cloud_provider: The destination cloud storage provider's name to store the datablob. Currently, the API only supports **aws** and **azure** as cloud storage providers.\n",
    "                If **None** (default value), then **aws**  will be used as the cloud storage provider.\n",
    "            region: The destination cloud provider's region to store the datablob. If **None** (default value) then the default region will be assigned based on the cloud \n",
    "                provider. In the case of **aws**, **eu-west-1** will be used and in the case of **azure**, **westeurope** will be used. The supported AWS regions \n",
    "                are: ap-northeast-1, ap-northeast-2, ap-south-1, ap-southeast-1, ap-southeast-2, ca-central-1, eu-central-1, eu-north-1, eu-west-1, eu-west-2, eu-west-3, sa-east-1, \n",
    "                us-east-1, us-east-2, us-west-1, us-west-2. The supported Azure Blob Storage regions are: australiacentral, australiacentral2, australiaeast, australiasoutheast, \n",
    "                brazilsouth, canadacentral, canadaeast, centralindia, centralus, eastasia, eastus, eastus2, francecentral, francesouth, germanynorth, germanywestcentral, japaneast, \n",
    "                japanwest, koreacentral, koreasouth, northcentralus, northeurope, norwayeast, norwaywest, southafricanorth, southafricawest, southcentralus, southeastasia, southindia, \n",
    "                switzerlandnorth, switzerlandwest, uaecentral, uaenorth, uksouth, ukwest, westcentralus, westeurope, westindia, westus, westus2.\n",
    "            tag: A string to tag the datablob. If not passed, then the tag **latest** will be assigned to the datablob.\n",
    "            show_progress: Flag to set the progressbar visibility. If not passed, then the default value **True** will be used.\n",
    "\n",
    "        Returns:\n",
    "           An instance of the `DataBlob` class.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If parameters to the API are invalid.\n",
    "            ConnectionError: If the server address is invalid or not reachable.\n",
    "\n",
    "        Here's an example of how to create a Datablob from a local file:\n",
    "        \n",
    "        Example:\n",
    "            ```python\n",
    "            # Importing necessary libraries\n",
    "            from  airt.client import Client, DataBlob\n",
    "\n",
    "            # Authenticate\n",
    "            Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")\n",
    "\n",
    "            # Create a datablob\n",
    "            # In this example, the datablob will be stored in an AWS S3 bucket. The region\n",
    "            # is set to eu-west-3, feel free to change the cloud provider and the region \n",
    "            # to suit your needs.\n",
    "            db = DataBlob.from_local(\n",
    "                path=\"{fill in path}\",\n",
    "                cloud_provider=\"aws\",\n",
    "                region=\"eu-west-3\"\n",
    "            )\n",
    "\n",
    "            # Display the status in a progress bar\n",
    "            db.progress_bar()\n",
    "\n",
    "            # Print the details of the newly created datablob\n",
    "            # If the upload is successful, the ready flag should be set to True\n",
    "            print(db.details())\n",
    "\n",
    "            ```\n",
    "        \"\"\"\n",
    "        path = Path(path)\n",
    "        cloud_provider, region = DataBlob._get_cloud_provider_and_region(cloud_provider, region) # type: ignore\n",
    "\n",
    "        # Step 1: get presigned URL\n",
    "        _path = f\"local:{str(path)}\"\n",
    "\n",
    "        response = Client._post_data(\n",
    "            relative_url=f\"/datablob/from_local/start\",\n",
    "            json=dict(path=_path, region=region, cloud_provider=cloud_provider, tag=tag),\n",
    "        )\n",
    "\n",
    "        # Step 2: download the csv to the s3 bucket\n",
    "        files = list(path.glob(\"*\")) if path.is_dir() else [path]\n",
    "\n",
    "        # Initiate progress bar\n",
    "        t = tqdm(total=len(files), disable=not show_progress)\n",
    "\n",
    "        for file_to_upload in files:\n",
    "            DataBlob._upload_to_s3_with_retry(\n",
    "                file_to_upload=file_to_upload,\n",
    "                presigned_url=response[\"presigned\"][\"url\"],\n",
    "                presigned_fields=response[\"presigned\"][\"fields\"],\n",
    "            )\n",
    "            t.update()\n",
    "\n",
    "        t.close()\n",
    "        return DataBlob(uuid=response[\"uuid\"], type=response[\"type\"])\n",
    "\n",
    "    @staticmethod\n",
    "    def ls(\n",
    "        offset: int = 0,\n",
    "        limit: int = 100,\n",
    "        disabled: bool = False,\n",
    "        completed: bool = False,\n",
    "    ) -> List[\"DataBlob\"]:\n",
    "        \"\"\"Return the list of DataBlob instances\n",
    "\n",
    "        Args:\n",
    "            offset: The number of datablobs to offset at the beginning. If **None**,\n",
    "                then the default value **0** will be used.\n",
    "            limit: The maximum number of datablobs to return from the server. If **None**,\n",
    "                then the default value **100** will be used.\n",
    "            disabled: If set to **True**, then only the deleted datablobs will be returned.\n",
    "                Else, the default value **False** will be used to return only the list\n",
    "                of active datablobs.\n",
    "            completed: If set to **True**, then only the datablobs that are successfully downloaded\n",
    "                to the server will be returned. Else, the default value **False** will be used to\n",
    "                return all the datablobs.\n",
    "\n",
    "        Returns:\n",
    "            A list of DataBlob instances available in the server.\n",
    "\n",
    "        Raises:\n",
    "            ConnectionError: If the server address is invalid or not reachable.\n",
    "        \"\"\"\n",
    "        lists = Client._get_data(\n",
    "            relative_url=f\"/datablob/?disabled={disabled}&completed={completed}&offset={offset}&limit={limit}\"\n",
    "        )\n",
    "\n",
    "        dbx = [\n",
    "            DataBlob(\n",
    "                uuid=db[\"uuid\"],\n",
    "                type=db[\"type\"],\n",
    "                source=db[\"source\"],\n",
    "                region=db[\"region\"],\n",
    "                cloud_provider=db[\"cloud_provider\"],\n",
    "                datasources=db[\"datasources\"],\n",
    "                total_steps=db[\"total_steps\"],\n",
    "                completed_steps=db[\"completed_steps\"],\n",
    "                folder_size=db[\"folder_size\"],\n",
    "                disabled=db[\"disabled\"],\n",
    "                pulled_on=db[\"pulled_on\"],\n",
    "                user=db[\"user\"],\n",
    "                tags=db[\"tags\"],\n",
    "                error=db[\"error\"],\n",
    "            )\n",
    "            for db in lists\n",
    "        ]\n",
    "\n",
    "        return dbx\n",
    "\n",
    "    @staticmethod\n",
    "    def as_df(dbx: List[\"DataBlob\"]) -> pd.DataFrame:\n",
    "        \"\"\"Return the details of datablob instances as a pandas dataframe.\n",
    "\n",
    "        Args:\n",
    "            dbx: List of datablob instances.\n",
    "\n",
    "        Returns:\n",
    "            Details of all the datablobs in a dataframe.\n",
    "\n",
    "        Raises:\n",
    "            ConnectionError: If the server address is invalid or not reachable.\n",
    "        \"\"\"\n",
    "        db_lists = get_attributes_from_instances(dbx, DataBlob.ALL_DB_COLS)  # type: ignore\n",
    "\n",
    "        for db in db_lists:\n",
    "            db = DataBlob._get_tag_name_and_datasource_id(db)\n",
    "\n",
    "        lists_df = generate_df(db_lists, DataBlob.BASIC_DB_COLS)\n",
    "        df = add_ready_column(lists_df)\n",
    "\n",
    "        df = df.rename(columns=DataBlob.COLS_TO_RENAME)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def is_ready(self) -> bool:\n",
    "        \"\"\"Check if the method's progress is complete.\n",
    "\n",
    "        !!! info\n",
    "\n",
    "            This method will return `True` immediately and will not wait for the progress to finish\n",
    "            if the datablob is created using the `from_local` method.\n",
    "\n",
    "        Returns:\n",
    "            **True** if the upload progress is completed, else **False**.\n",
    "        \"\"\"\n",
    "        if self.type in [\"local\"]:\n",
    "            return True\n",
    "\n",
    "        progress_status = ProgressStatus(relative_url=f\"/datablob/{self.uuid}\")\n",
    "\n",
    "        return progress_status.is_ready()\n",
    "\n",
    "    def progress_bar(self, sleep_for: Union[int, float] = 5, timeout: int = 0):\n",
    "        \"\"\"Blocks the execution and displays a progress bar showing the remote action progress.\n",
    "\n",
    "        !!! info\n",
    "\n",
    "            This method will not check the progress if the datablob is created using the\n",
    "            `from_local` method.\n",
    "\n",
    "        Args:\n",
    "            sleep_for: The time interval in seconds between successive API calls.\n",
    "            timeout: The maximum time allowed in seconds for the asynchronous call to complete. If not the\n",
    "                progressbar will be terminated.\n",
    "\n",
    "        Raises:\n",
    "            ConnectionError: If the server address is invalid or not reachable.\n",
    "            TimeoutError: in case of connection timeout.\n",
    "        \"\"\"\n",
    "        if self.type not in [\"local\"]:\n",
    "            progress_status = ProgressStatus(\n",
    "                relative_url=f\"/datablob/{self.uuid}\",\n",
    "                sleep_for=sleep_for,\n",
    "                timeout=timeout,\n",
    "            )\n",
    "\n",
    "            progress_status.progress_bar()\n",
    "\n",
    "    def wait(self, sleep_for: Union[int, float] = 1, timeout: int = 0):\n",
    "        \"\"\"Blocks execution while waiting for the remote action to complete.\n",
    "\n",
    "        !!! info\n",
    "\n",
    "            This method will not check the progress if the datablob is created using the\n",
    "            `from_local` method.\n",
    "\n",
    "        Args:\n",
    "            sleep_for: The time interval in seconds between successive API calls.\n",
    "            timeout: The maximum time allowed in seconds for the asynchronous call to complete. If not the\n",
    "                progressbar will be terminated.\n",
    "\n",
    "        Raises:\n",
    "            ConnectionError: If the server address is invalid or not reachable.\n",
    "            TimeoutError: in case of timeout.\n",
    "        \"\"\"\n",
    "        if self.type not in [\"local\"]:\n",
    "            progress_status = ProgressStatus(\n",
    "                relative_url=f\"/datablob/{self.uuid}\",\n",
    "                sleep_for=sleep_for,\n",
    "                timeout=timeout,\n",
    "            )\n",
    "\n",
    "            progress_status.wait()\n",
    "\n",
    "    def to_datasource(\n",
    "        self,\n",
    "        *,\n",
    "        file_type:str,\n",
    "        index_column: str,\n",
    "        sort_by: Union[str, List[str]],\n",
    "        deduplicate_data: bool = False,\n",
    "        blocksize: str = \"256MB\",\n",
    "        **kwargs,\n",
    "    ) -> DataSource:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def details(self) -> pd.DataFrame:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def tag(self, name: str) -> pd.DataFrame:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def delete(self) -> pd.DataFrame:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377253dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "def _docstring_example():\n",
    "    \"\"\"\n",
    "    Example:\n",
    "        ```python\n",
    "        # Importing necessary libraries\n",
    "        from  airt.client import Client, DataBlob\n",
    "\n",
    "        # Authenticate\n",
    "        Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")\n",
    "\n",
    "        # Create a datablob\n",
    "        # In this example, the datablob will be stored in an AWS S3 bucket. The \n",
    "        # access_key and the secret_key are set in the AWS_ACCESS_KEY_ID and \n",
    "        # AWS_SECRET_ACCESS_KEY environment variables, and the region is set to \n",
    "        # eu-west-3; feel free to change the cloud provider and the region to \n",
    "        # suit your needs.\n",
    "        db = DataBlob.from_s3(\n",
    "            uri=\"{fill in uri}\",\n",
    "            cloud_provider=\"aws\",\n",
    "            region=\"eu-west-3\"\n",
    "        )\n",
    "\n",
    "        # Display the status in a progress bar\n",
    "        # Call the wait method to wait for the progress to finish but\n",
    "        # without displaying an interactive progress bar.\n",
    "        db.progress_bar()\n",
    "        \n",
    "        # Display the ready status\n",
    "        # If the datablob is successfully uploaded, True will be returned.\n",
    "        print(db.is_ready())\n",
    "\n",
    "        # Print the details of the newly created datablob\n",
    "        print(db.details())\n",
    "        \n",
    "        # Display the details of all datablob created by the currently\n",
    "        # logged-in user\n",
    "        print(DataBlob.as_df(DataBlob.ls()))\n",
    "        \n",
    "        # Create a datasource\n",
    "        ds = db.to_datasource(\n",
    "            file_type=\"{fill in file_type}\",\n",
    "            index_column=\"{fill in index_column}\",\n",
    "            sort_by=\"{fill in sort_by}\",\n",
    "        )\n",
    "\n",
    "        # Display the status in a progress bar\n",
    "        ds.progress_bar()\n",
    "\n",
    "        # Display the head of the data to ensure everything is fine.\n",
    "        print(ds.head())\n",
    "        \n",
    "        # Tag the datablob\n",
    "        print(db.tag(name=\"{fill in tag_name}\"))\n",
    "\n",
    "        # Delete the datablob\n",
    "        print(db.delete())\n",
    "        ```\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be19b4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Example:                                                                                                        \n",
       "                                                                                                                 \n",
       "     # Importing necessary libraries                                                                             \n",
       "     from  airt.client import Client, DataBlob                                                                   \n",
       "                                                                                                                 \n",
       "     # Authenticate                                                                                              \n",
       "     Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")                              \n",
       "                                                                                                                 \n",
       "     # Create a datablob                                                                                         \n",
       "     # In this example, the datablob will be stored in an AWS S3 bucket. The                                     \n",
       "     # access_key and the secret_key are set in the AWS_ACCESS_KEY_ID and                                        \n",
       "     # AWS_SECRET_ACCESS_KEY environment variables, and the region is set to                                     \n",
       "     # eu-west-3; feel free to change the cloud provider and the region to                                       \n",
       "     # suit your needs.                                                                                          \n",
       "     db = DataBlob.from_s3(                                                                                      \n",
       "         uri=\"{fill in uri}\",                                                                                    \n",
       "         cloud_provider=\"aws\",                                                                                   \n",
       "         region=\"eu-west-3\"                                                                                      \n",
       "     )                                                                                                           \n",
       "                                                                                                                 \n",
       "     # Display the status in a progress bar                                                                      \n",
       "     # Call the wait method to wait for the progress to finish but                                               \n",
       "     # without displaying an interactive progress bar.                                                           \n",
       "     db.progress_bar()                                                                                           \n",
       "                                                                                                                 \n",
       "     # Display the ready status                                                                                  \n",
       "     # If the datablob is successfully uploaded, True will be returned.                                          \n",
       "     print(db.is_ready())                                                                                        \n",
       "                                                                                                                 \n",
       "     # Print the details of the newly created datablob                                                           \n",
       "     print(db.details())                                                                                         \n",
       "                                                                                                                 \n",
       "     # Display the details of all datablob created by the currently                                              \n",
       "     # logged-in user                                                                                            \n",
       "     print(DataBlob.as_df(DataBlob.ls()))                                                                        \n",
       "                                                                                                                 \n",
       "     # Create a datasource                                                                                       \n",
       "     ds = db.to_datasource(                                                                                      \n",
       "         file_type=\"{fill in file_type}\",                                                                        \n",
       "         index_column=\"{fill in index_column}\",                                                                  \n",
       "         sort_by=\"{fill in sort_by}\",                                                                            \n",
       "     )                                                                                                           \n",
       "                                                                                                                 \n",
       "     # Display the status in a progress bar                                                                      \n",
       "     ds.progress_bar()                                                                                           \n",
       "                                                                                                                 \n",
       "     # Display the head of the data to ensure everything is fine.                                                \n",
       "     print(ds.head())                                                                                            \n",
       "                                                                                                                 \n",
       "     # Tag the datablob                                                                                          \n",
       "     print(db.tag(name=\"{fill in tag_name}\"))                                                                    \n",
       "                                                                                                                 \n",
       "     # Delete the datablob                                                                                       \n",
       "     print(db.delete())                                                                                          \n",
       "                                                                                                                 \n",
       "  stdout  \n",
       "  True                                                                                                         \n",
       "                            datablob_uuid datasource_uuids  ... disabled ready                                 \n",
       "  0  2266a8b6-b242-4400-96e6-a3eda7157482           &lt;none&gt;  ...    False  True                                 \n",
       "                                                                                                               \n",
       "  [1 rows x 13 columns]                                                                                        \n",
       "                            datablob_uuid datasource_uuids  ... folder_size ready                              \n",
       "  0  2266a8b6-b242-4400-96e6-a3eda7157482           &lt;none&gt;  ...    10191763  True                              \n",
       "                                                                                                               \n",
       "  [1 rows x 10 columns]                                                                                        \n",
       "                           event_time  ...                          user_session                               \n",
       "  user_id                              ...                                                                     \n",
       "  253624608 2019-11-03 14:26:26+00:00  ...  6c1f98d8-064e-4688-a8db-d261d9f94979                               \n",
       "  253624608 2019-11-03 14:26:38+00:00  ...  6c1f98d8-064e-4688-a8db-d261d9f94979                               \n",
       "  253624608 2019-11-04 05:56:10+00:00  ...  6718074b-3058-41c2-a082-970cdeeb4a8e                               \n",
       "  275256741 2019-11-01 02:23:03+00:00  ...  48b5b9c0-3d1b-4380-94f8-dcadb9dd7b5c                               \n",
       "  280194708 2019-11-06 15:23:02+00:00  ...  4c51d9d1-8000-4050-a921-3b6fc29db8e9                               \n",
       "  280194708 2019-11-06 15:23:43+00:00  ...  4c51d9d1-8000-4050-a921-3b6fc29db8e9                               \n",
       "  280194708 2019-11-06 15:23:55+00:00  ...  4c51d9d1-8000-4050-a921-3b6fc29db8e9                               \n",
       "  301823874 2019-11-02 08:09:20+00:00  ...  4d2cb750-093f-413a-ba27-ba862507d22d                               \n",
       "  301823874 2019-11-02 08:10:59+00:00  ...  4d2cb750-093f-413a-ba27-ba862507d22d                               \n",
       "  301823874 2019-11-02 08:14:46+00:00  ...  4d2cb750-093f-413a-ba27-ba862507d22d                               \n",
       "                                                                                                               \n",
       "  [10 rows x 8 columns]                                                                                        \n",
       "                            datablob_uuid  ... ready                                                           \n",
       "  0  2266a8b6-b242-4400-96e6-a3eda7157482  ...  True                                                           \n",
       "                                                                                                               \n",
       "  [1 rows x 10 columns]                                                                                        \n",
       "                            datablob_uuid  ... ready                                                           \n",
       "  0  2266a8b6-b242-4400-96e6-a3eda7157482  ...  True                                                           \n",
       "                                                                                                               \n",
       "  [1 rows x 10 columns]                                                                                        \n",
       "                                                                                                               \n",
       "  \n",
       "  stderr  \n",
       "                                                                                                               \n",
       "    0%|          | 0/1 [00:00&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:05&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:10&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:15&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:20&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:25&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:30&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:35&lt;?, ?it/s]                                                                        \n",
       "  100%|| 1/1 [00:40&lt;00:00,  5.06s/it]                                                                \n",
       "  100%|| 1/1 [00:40&lt;00:00, 40.58s/it]                                                                \n",
       "                                                                                                               \n",
       "    0%|          | 0/1 [00:00&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:05&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:10&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:15&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:20&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:25&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:30&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:35&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:40&lt;?, ?it/s]                                                                        \n",
       "  100%|| 1/1 [00:45&lt;00:00,  5.06s/it]                                                                \n",
       "  100%|| 1/1 [00:45&lt;00:00, 45.66s/it]                                                                \n",
       "                                                                                                               \n",
       "  \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Example:                                                                                                        \n",
       "                                                                                                                 \n",
       "     # Importing necessary libraries                                                                             \n",
       "     from  airt.client import Client, DataBlob                                                                   \n",
       "                                                                                                                 \n",
       "     # Authenticate                                                                                              \n",
       "     Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")                              \n",
       "                                                                                                                 \n",
       "     # Create a datablob                                                                                         \n",
       "     # In this example, the datablob will be stored in an AWS S3 bucket. The                                     \n",
       "     # access_key and the secret_key are set in the AWS_ACCESS_KEY_ID and                                        \n",
       "     # AWS_SECRET_ACCESS_KEY environment variables, and the region is set to                                     \n",
       "     # eu-west-3; feel free to change the cloud provider and the region to                                       \n",
       "     # suit your needs.                                                                                          \n",
       "     db = DataBlob.from_s3(                                                                                      \n",
       "         uri=\"{fill in uri}\",                                                                                    \n",
       "         cloud_provider=\"aws\",                                                                                   \n",
       "         region=\"eu-west-3\"                                                                                      \n",
       "     )                                                                                                           \n",
       "                                                                                                                 \n",
       "     # Display the status in a progress bar                                                                      \n",
       "     # Call the wait method to wait for the progress to finish but                                               \n",
       "     # without displaying an interactive progress bar.                                                           \n",
       "     db.progress_bar()                                                                                           \n",
       "                                                                                                                 \n",
       "     # Display the ready status                                                                                  \n",
       "     # If the datablob is successfully uploaded, True will be returned.                                          \n",
       "     print(db.is_ready())                                                                                        \n",
       "                                                                                                                 \n",
       "     # Print the details of the newly created datablob                                                           \n",
       "     print(db.details())                                                                                         \n",
       "                                                                                                                 \n",
       "     # Display the details of all datablob created by the currently                                              \n",
       "     # logged-in user                                                                                            \n",
       "     print(DataBlob.as_df(DataBlob.ls()))                                                                        \n",
       "                                                                                                                 \n",
       "     # Create a datasource                                                                                       \n",
       "     ds = db.to_datasource(                                                                                      \n",
       "         file_type=\"{fill in file_type}\",                                                                        \n",
       "         index_column=\"{fill in index_column}\",                                                                  \n",
       "         sort_by=\"{fill in sort_by}\",                                                                            \n",
       "     )                                                                                                           \n",
       "                                                                                                                 \n",
       "     # Display the status in a progress bar                                                                      \n",
       "     ds.progress_bar()                                                                                           \n",
       "                                                                                                                 \n",
       "     # Display the head of the data to ensure everything is fine.                                                \n",
       "     print(ds.head())                                                                                            \n",
       "                                                                                                                 \n",
       "     # Tag the datablob                                                                                          \n",
       "     print(db.tag(name=\"{fill in tag_name}\"))                                                                    \n",
       "                                                                                                                 \n",
       "     # Delete the datablob                                                                                       \n",
       "     print(db.delete())                                                                                          \n",
       "                                                                                                                 \n",
       "  stdout  \n",
       "  True                                                                                                         \n",
       "                            datablob_uuid datasource_uuids  ... disabled ready                                 \n",
       "  0  2266a8b6-b242-4400-96e6-a3eda7157482           <none>  ...    False  True                                 \n",
       "                                                                                                               \n",
       "  [1 rows x 13 columns]                                                                                        \n",
       "                            datablob_uuid datasource_uuids  ... folder_size ready                              \n",
       "  0  2266a8b6-b242-4400-96e6-a3eda7157482           <none>  ...    10191763  True                              \n",
       "                                                                                                               \n",
       "  [1 rows x 10 columns]                                                                                        \n",
       "                           event_time  ...                          user_session                               \n",
       "  user_id                              ...                                                                     \n",
       "  253624608 2019-11-03 14:26:26+00:00  ...  6c1f98d8-064e-4688-a8db-d261d9f94979                               \n",
       "  253624608 2019-11-03 14:26:38+00:00  ...  6c1f98d8-064e-4688-a8db-d261d9f94979                               \n",
       "  253624608 2019-11-04 05:56:10+00:00  ...  6718074b-3058-41c2-a082-970cdeeb4a8e                               \n",
       "  275256741 2019-11-01 02:23:03+00:00  ...  48b5b9c0-3d1b-4380-94f8-dcadb9dd7b5c                               \n",
       "  280194708 2019-11-06 15:23:02+00:00  ...  4c51d9d1-8000-4050-a921-3b6fc29db8e9                               \n",
       "  280194708 2019-11-06 15:23:43+00:00  ...  4c51d9d1-8000-4050-a921-3b6fc29db8e9                               \n",
       "  280194708 2019-11-06 15:23:55+00:00  ...  4c51d9d1-8000-4050-a921-3b6fc29db8e9                               \n",
       "  301823874 2019-11-02 08:09:20+00:00  ...  4d2cb750-093f-413a-ba27-ba862507d22d                               \n",
       "  301823874 2019-11-02 08:10:59+00:00  ...  4d2cb750-093f-413a-ba27-ba862507d22d                               \n",
       "  301823874 2019-11-02 08:14:46+00:00  ...  4d2cb750-093f-413a-ba27-ba862507d22d                               \n",
       "                                                                                                               \n",
       "  [10 rows x 8 columns]                                                                                        \n",
       "                            datablob_uuid  ... ready                                                           \n",
       "  0  2266a8b6-b242-4400-96e6-a3eda7157482  ...  True                                                           \n",
       "                                                                                                               \n",
       "  [1 rows x 10 columns]                                                                                        \n",
       "                            datablob_uuid  ... ready                                                           \n",
       "  0  2266a8b6-b242-4400-96e6-a3eda7157482  ...  True                                                           \n",
       "                                                                                                               \n",
       "  [1 rows x 10 columns]                                                                                        \n",
       "                                                                                                               \n",
       "  \n",
       "  stderr  \n",
       "                                                                                                               \n",
       "    0%|          | 0/1 [00:00<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:05<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:10<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:15<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:20<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:25<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:30<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:35<?, ?it/s]                                                                        \n",
       "  100%|| 1/1 [00:40<00:00,  5.06s/it]                                                                \n",
       "  100%|| 1/1 [00:40<00:00, 40.58s/it]                                                                \n",
       "                                                                                                               \n",
       "    0%|          | 0/1 [00:00<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:05<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:10<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:15<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:20<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:25<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:30<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:35<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:40<?, ?it/s]                                                                        \n",
       "  100%|| 1/1 [00:45<00:00,  5.06s/it]                                                                \n",
       "  100%|| 1/1 [00:45<00:00, 45.66s/it]                                                                \n",
       "                                                                                                               \n",
       "  \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run example for _docstring_example\n",
    "username = os.environ[SERVICE_USERNAME]\n",
    "password = os.environ[SERVICE_PASSWORD]\n",
    "\n",
    "run_examples_from_docstring(\n",
    "    _docstring_example,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    uri=TEST_S3_URI,\n",
    "    file_type=\"parquet\",\n",
    "    index_column=\"user_id\",\n",
    "    sort_by=\"event_time\",\n",
    "    tag_name=\"v1.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c17882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "add_example_to_docs(DataBlob, _docstring_example.__doc__) # type: ignore\n",
    "add_example_to_docs(DataBlob.ls, _docstring_example.__doc__) # type: ignore\n",
    "add_example_to_docs(DataBlob.as_df, _docstring_example.__doc__) # type: ignore\n",
    "add_example_to_docs(DataBlob.wait, _docstring_example.__doc__) # type: ignore\n",
    "add_example_to_docs(DataBlob.is_ready, _docstring_example.__doc__) # type: ignore\n",
    "add_example_to_docs(DataBlob.progress_bar, _docstring_example.__doc__) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13607f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "@patch(cls_method=True)\n",
    "@contextmanager\n",
    "def set_default_cloud_provider(\n",
    "    cls: DataBlob, cloud_provider: str, region: Optional[str] = None\n",
    ") -> Iterator[None]:\n",
    "    \"\"\"Sets the default destination value for the cloud_provider and the region.\n",
    "    \n",
    "    Whenever you call the from_\\* methods of the `DataBlob` class inside this context manager, the destination cloud_provider and region set in this context \n",
    "    will be passed to the from_\\* methods, unless you explicitely override it in the parameter.\n",
    "\n",
    "    Args:\n",
    "        cloud_provider: The destination cloud storage provider's name to store the datablob. Currently, the API only supports **aws** and **azure** as cloud storage providers.\n",
    "        region: The destination cloud provider's region to store the datablob. The supported AWS regions are: ap-northeast-1, ap-northeast-2, ap-south-1, ap-southeast-1, \n",
    "            ap-southeast-2, ca-central-1, eu-central-1, eu-north-1, eu-west-1, eu-west-2, eu-west-3, sa-east-1, us-east-1, us-east-2, us-west-1, us-west-2. The supported \n",
    "            Azure Blob Storage regions are: australiacentral, australiacentral2, australiaeast, australiasoutheast, brazilsouth, canadacentral, canadaeast, centralindia, \n",
    "            centralus, eastasia, eastus, eastus2, francecentral, francesouth, germanynorth, germanywestcentral, japaneast, japanwest, koreacentral, koreasouth, \n",
    "            northcentralus, northeurope, norwayeast, norwaywest, southafricanorth, southafricawest, southcentralus, southeastasia, southindia, switzerlandnorth, \n",
    "            switzerlandwest, uaecentral, uaenorth, uksouth, ukwest, westcentralus, westeurope, westindia, westus, westus2.\n",
    "\n",
    "    Returns:\n",
    "        A context manager that specifies the cloud provider and region to use.\n",
    "\n",
    "    Here's an example of creating a datablob from Azure Blob Storage and storing it in AWS S3:\n",
    "    \n",
    "    Example:\n",
    "        ```python\n",
    "        # Importing necessary libraries\n",
    "        import os\n",
    "\n",
    "        from azure.identity import DefaultAzureCredential\n",
    "        from azure.mgmt.storage import StorageManagementClient\n",
    "\n",
    "        from  airt.client import Client, DataBlob\n",
    "\n",
    "        # Create a credential for accessing Azure Blob Storage\n",
    "        # Setting the required environment variables\n",
    "        os.environ[\"AZURE_SUBSCRIPTION_ID\"] = \"{fill in azure_subscription_id}\"\n",
    "        os.environ[\"AZURE_CLIENT_ID\"] = \"{fill in azure_client_id}\"\n",
    "        os.environ[\"AZURE_CLIENT_SECRET\"] = \"{fill in azure_client_secret}\"\n",
    "        os.environ[\"AZURE_TENANT_ID\"]= \"{fill in azure_tenant_id}\"\n",
    "\n",
    "        # Setting the resource group name and storage account name\n",
    "        azure_group_name = \"{fill in azure_group_name}\"\n",
    "        azure_storage_account_name = \"{fill in azure_storage_account_name}\"\n",
    "\n",
    "        # Retrieving the credential\n",
    "        azure_storage_client = StorageManagementClient(\n",
    "            DefaultAzureCredential(), os.environ[\"AZURE_SUBSCRIPTION_ID\"]\n",
    "        )\n",
    "        azure_storage_keys = azure_storage_client.storage_accounts.list_keys(\n",
    "            azure_group_name, azure_storage_account_name\n",
    "        )\n",
    "        azure_storage_keys = {v.key_name: v.value for v in azure_storage_keys.keys}\n",
    "        credential = azure_storage_keys['key1']\n",
    "\n",
    "\n",
    "        # Authenticate\n",
    "        Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")\n",
    "\n",
    "        # Create a datablob\n",
    "        # In this example, the datablobs created inside the context manager will be \n",
    "        # stored in an AWS S3 bucket with the region set to eu-west-3.\n",
    "        with DataBlob.set_default_cloud_provider(\n",
    "            cloud_provider=\"aws\",\n",
    "            region=\"eu-west-3\"\n",
    "        ):\n",
    "            db = DataBlob.from_azure_blob_storage(\n",
    "                uri=\"{fill in uri}\",\n",
    "                credential=credential\n",
    "            )\n",
    "        \n",
    "        # Display the status in a progress bar    \n",
    "        db.progress_bar()\n",
    "        \n",
    "        # Print the details of the newly created datablob\n",
    "        # If the upload is successful, the ready flag should be set to True\n",
    "        print(db.details())\n",
    "        ```\n",
    "    \"\"\"\n",
    "\n",
    "    cls._default_provider_and_regions.append((cloud_provider, region))  # type: ignore\n",
    "\n",
    "    yield\n",
    "\n",
    "    cls._default_provider_and_regions.pop()\n",
    "\n",
    "\n",
    "@patch(cls_method=True)\n",
    "def _get_default_provider_and_regions(\n",
    "    cls: DataBlob,\n",
    ") -> Tuple[Optional[str], Optional[str]]:\n",
    "    \n",
    "    if len(cls._default_provider_and_regions) == 0:\n",
    "        return None, None\n",
    "    \n",
    "    else:\n",
    "        return cls._default_provider_and_regions[-1]\n",
    "\n",
    "\n",
    "@patch(cls_method=True)\n",
    "def _get_cloud_provider_and_region(\n",
    "    cls: DataBlob,\n",
    "    cloud_provider: Optional[str] = None,\n",
    "    region: Optional[str] = None,\n",
    "    set_source_region: Optional[bool] = False,\n",
    "    default_cloud_provider: str = \"aws\",\n",
    ") -> Tuple[str, Optional[str]]:\n",
    "    \n",
    "    if (cloud_provider is None) and (region is not None):\n",
    "        raise ValueError(\"You must specify a cloud_provider if are specifying a region.\")\n",
    "\n",
    "    if (cloud_provider is None) and (region is None):\n",
    "        cloud_provider, region = cls._get_default_provider_and_regions() # type: ignore\n",
    "    \n",
    "    if cloud_provider is None:\n",
    "        ret_val_cloud_provider = default_cloud_provider\n",
    "    else:\n",
    "        ret_val_cloud_provider = cloud_provider\n",
    "    \n",
    "    if region is None:\n",
    "        if ret_val_cloud_provider == \"azure\":\n",
    "            region = DEFAULT_AZURE_BLOB_STORAGE_REGION\n",
    "        else:\n",
    "            region = None if set_source_region else DEFAULT_S3_REGION\n",
    "\n",
    "    return ret_val_cloud_provider, region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa69d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ValueError('You must specify a cloud_provider if are specifying a region.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'azure'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'westeurope'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'aws'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'eu-west-1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'aws'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'azure'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'westeurope'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'aws'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'eu-west-1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'azure'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'westeurope'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'aws'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'eu-west-1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'aws'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'eu-west-1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'azure'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'westeurope'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pytest.raises(ValueError) as e:\n",
    "    DataBlob._get_cloud_provider_and_region(cloud_provider=None, region=\"US\")\n",
    "display(e.value)\n",
    "\n",
    "_cloud_provider, _region = DataBlob._get_cloud_provider_and_region(cloud_provider=None, region=None, default_cloud_provider=\"azure\")\n",
    "display(_cloud_provider, _region)\n",
    "assert _cloud_provider == \"azure\"\n",
    "assert _region == DEFAULT_AZURE_BLOB_STORAGE_REGION, _region\n",
    "\n",
    "_cloud_provider, _region = DataBlob._get_cloud_provider_and_region(cloud_provider=None, region=None)\n",
    "display(_cloud_provider, _region)\n",
    "assert _cloud_provider == \"aws\"\n",
    "assert _region == DEFAULT_S3_REGION, _region\n",
    "\n",
    "_cloud_provider, _region = DataBlob._get_cloud_provider_and_region(cloud_provider=None, region=None, set_source_region=True)\n",
    "display(_cloud_provider, _region)\n",
    "assert _cloud_provider == \"aws\"\n",
    "assert _region == None, _region\n",
    "\n",
    "_cloud_provider, _region = DataBlob._get_cloud_provider_and_region(\"azure\")\n",
    "display(_cloud_provider, _region)\n",
    "assert _cloud_provider == \"azure\"\n",
    "assert _region == DEFAULT_AZURE_BLOB_STORAGE_REGION, _region\n",
    "\n",
    "_cloud_provider, _region = DataBlob._get_cloud_provider_and_region(\"aws\")\n",
    "display(_cloud_provider, _region)\n",
    "assert _cloud_provider == \"aws\"\n",
    "assert _region == DEFAULT_S3_REGION, _region\n",
    "\n",
    "with DataBlob.set_default_cloud_provider(\"azure\", \"US\"):\n",
    "    _cloud_provider, _region = DataBlob._get_cloud_provider_and_region(\"azure\")\n",
    "    display(_cloud_provider, _region)\n",
    "    assert _cloud_provider == \"azure\"\n",
    "    assert _region == \"westeurope\", _region\n",
    "    \n",
    "    with DataBlob.set_default_cloud_provider(\"aws\", \"US\"):\n",
    "        _cloud_provider, _region = DataBlob._get_cloud_provider_and_region(\"aws\")\n",
    "        display(_cloud_provider, _region)\n",
    "        assert _cloud_provider == \"aws\"\n",
    "        assert _region == \"eu-west-1\", _region\n",
    "        \n",
    "        with DataBlob.set_default_cloud_provider(\"aws\"):\n",
    "            _cloud_provider, _region = DataBlob._get_cloud_provider_and_region(\"aws\")\n",
    "            display(_cloud_provider, _region)\n",
    "            assert _cloud_provider == \"aws\"\n",
    "            assert _region == \"eu-west-1\", DEFAULT_S3_REGION\n",
    "                    \n",
    "        _cloud_provider, _region = DataBlob._get_cloud_provider_and_region(\"azure\")\n",
    "        display(_cloud_provider, _region)\n",
    "        assert _cloud_provider == \"azure\"\n",
    "        assert _region == \"westeurope\", _region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5d7fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<module>:6: No type or annotation for parameter 'cloud_provider'\n",
      "<module>:7: No type or annotation for parameter 'region'\n",
      "<module>:15: No type or annotation for returned value 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Example:                                                                                                        \n",
       "                                                                                                                 \n",
       "     # Importing necessary libraries                                                                             \n",
       "     import os                                                                                                   \n",
       "                                                                                                                 \n",
       "     from azure.identity import DefaultAzureCredential                                                           \n",
       "     from azure.mgmt.storage import StorageManagementClient                                                      \n",
       "                                                                                                                 \n",
       "     from  airt.client import Client, DataBlob                                                                   \n",
       "                                                                                                                 \n",
       "     # Create a credential for accessing Azure Blob Storage                                                      \n",
       "     # Setting the required environment variables                                                                \n",
       "     os.environ[\"AZURE_SUBSCRIPTION_ID\"] = \"{fill in azure_subscription_id}\"                                     \n",
       "     os.environ[\"AZURE_CLIENT_ID\"] = \"{fill in azure_client_id}\"                                                 \n",
       "     os.environ[\"AZURE_CLIENT_SECRET\"] = \"{fill in azure_client_secret}\"                                         \n",
       "     os.environ[\"AZURE_TENANT_ID\"]= \"{fill in azure_tenant_id}\"                                                  \n",
       "                                                                                                                 \n",
       "     # Setting the resource group name and storage account name                                                  \n",
       "     azure_group_name = \"{fill in azure_group_name}\"                                                             \n",
       "     azure_storage_account_name = \"{fill in azure_storage_account_name}\"                                         \n",
       "                                                                                                                 \n",
       "     # Retrieving the credential                                                                                 \n",
       "     azure_storage_client = StorageManagementClient(                                                             \n",
       "         DefaultAzureCredential(), os.environ[\"AZURE_SUBSCRIPTION_ID\"]                                           \n",
       "     )                                                                                                           \n",
       "     azure_storage_keys = azure_storage_client.storage_accounts.list_keys(                                       \n",
       "         azure_group_name, azure_storage_account_name                                                            \n",
       "     )                                                                                                           \n",
       "     azure_storage_keys = {v.key_name: v.value for v in azure_storage_keys.keys}                                 \n",
       "     credential = azure_storage_keys['key1']                                                                     \n",
       "                                                                                                                 \n",
       "                                                                                                                 \n",
       "     # Authenticate                                                                                              \n",
       "     Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")                              \n",
       "                                                                                                                 \n",
       "     # Create a datablob                                                                                         \n",
       "     # In this example, the datablobs created inside the context manager will be                                 \n",
       "     # stored in an AWS S3 bucket with the region set to eu-west-3.                                              \n",
       "     with DataBlob.set_default_cloud_provider(                                                                   \n",
       "         cloud_provider=\"aws\",                                                                                   \n",
       "         region=\"eu-west-3\"                                                                                      \n",
       "     ):                                                                                                          \n",
       "         db = DataBlob.from_azure_blob_storage(                                                                  \n",
       "             uri=\"{fill in uri}\",                                                                                \n",
       "             credential=credential                                                                               \n",
       "         )                                                                                                       \n",
       "                                                                                                                 \n",
       "     # Display the status in a progress bar                                                                      \n",
       "     db.progress_bar()                                                                                           \n",
       "                                                                                                                 \n",
       "     # Print the details of the newly created datablob                                                           \n",
       "     # If the upload is successful, the ready flag should be set to True                                         \n",
       "     print(db.details())                                                                                         \n",
       "                                                                                                                 \n",
       "  stdout  \n",
       "                            datablob_uuid datasource_uuids  ... disabled ready                                 \n",
       "  0  e73f421b-3a91-4a6b-a269-444a3c7d1c90           &lt;none&gt;  ...    False  True                                 \n",
       "                                                                                                               \n",
       "  [1 rows x 13 columns]                                                                                        \n",
       "                                                                                                               \n",
       "  \n",
       "  stderr  \n",
       "                                                                                                               \n",
       "    0%|          | 0/1 [00:00&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:05&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:10&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:15&lt;?, ?it/s]                                                                        \n",
       "  100%|| 1/1 [00:20&lt;00:00,  5.12s/it]                                                                \n",
       "  100%|| 1/1 [00:20&lt;00:00, 20.33s/it]                                                                \n",
       "                                                                                                               \n",
       "  \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Example:                                                                                                        \n",
       "                                                                                                                 \n",
       "     # Importing necessary libraries                                                                             \n",
       "     import os                                                                                                   \n",
       "                                                                                                                 \n",
       "     from azure.identity import DefaultAzureCredential                                                           \n",
       "     from azure.mgmt.storage import StorageManagementClient                                                      \n",
       "                                                                                                                 \n",
       "     from  airt.client import Client, DataBlob                                                                   \n",
       "                                                                                                                 \n",
       "     # Create a credential for accessing Azure Blob Storage                                                      \n",
       "     # Setting the required environment variables                                                                \n",
       "     os.environ[\"AZURE_SUBSCRIPTION_ID\"] = \"{fill in azure_subscription_id}\"                                     \n",
       "     os.environ[\"AZURE_CLIENT_ID\"] = \"{fill in azure_client_id}\"                                                 \n",
       "     os.environ[\"AZURE_CLIENT_SECRET\"] = \"{fill in azure_client_secret}\"                                         \n",
       "     os.environ[\"AZURE_TENANT_ID\"]= \"{fill in azure_tenant_id}\"                                                  \n",
       "                                                                                                                 \n",
       "     # Setting the resource group name and storage account name                                                  \n",
       "     azure_group_name = \"{fill in azure_group_name}\"                                                             \n",
       "     azure_storage_account_name = \"{fill in azure_storage_account_name}\"                                         \n",
       "                                                                                                                 \n",
       "     # Retrieving the credential                                                                                 \n",
       "     azure_storage_client = StorageManagementClient(                                                             \n",
       "         DefaultAzureCredential(), os.environ[\"AZURE_SUBSCRIPTION_ID\"]                                           \n",
       "     )                                                                                                           \n",
       "     azure_storage_keys = azure_storage_client.storage_accounts.list_keys(                                       \n",
       "         azure_group_name, azure_storage_account_name                                                            \n",
       "     )                                                                                                           \n",
       "     azure_storage_keys = {v.key_name: v.value for v in azure_storage_keys.keys}                                 \n",
       "     credential = azure_storage_keys['key1']                                                                     \n",
       "                                                                                                                 \n",
       "                                                                                                                 \n",
       "     # Authenticate                                                                                              \n",
       "     Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")                              \n",
       "                                                                                                                 \n",
       "     # Create a datablob                                                                                         \n",
       "     # In this example, the datablobs created inside the context manager will be                                 \n",
       "     # stored in an AWS S3 bucket with the region set to eu-west-3.                                              \n",
       "     with DataBlob.set_default_cloud_provider(                                                                   \n",
       "         cloud_provider=\"aws\",                                                                                   \n",
       "         region=\"eu-west-3\"                                                                                      \n",
       "     ):                                                                                                          \n",
       "         db = DataBlob.from_azure_blob_storage(                                                                  \n",
       "             uri=\"{fill in uri}\",                                                                                \n",
       "             credential=credential                                                                               \n",
       "         )                                                                                                       \n",
       "                                                                                                                 \n",
       "     # Display the status in a progress bar                                                                      \n",
       "     db.progress_bar()                                                                                           \n",
       "                                                                                                                 \n",
       "     # Print the details of the newly created datablob                                                           \n",
       "     # If the upload is successful, the ready flag should be set to True                                         \n",
       "     print(db.details())                                                                                         \n",
       "                                                                                                                 \n",
       "  stdout  \n",
       "                            datablob_uuid datasource_uuids  ... disabled ready                                 \n",
       "  0  e73f421b-3a91-4a6b-a269-444a3c7d1c90           <none>  ...    False  True                                 \n",
       "                                                                                                               \n",
       "  [1 rows x 13 columns]                                                                                        \n",
       "                                                                                                               \n",
       "  \n",
       "  stderr  \n",
       "                                                                                                               \n",
       "    0%|          | 0/1 [00:00<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:05<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:10<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:15<?, ?it/s]                                                                        \n",
       "  100%|| 1/1 [00:20<00:00,  5.12s/it]                                                                \n",
       "  100%|| 1/1 [00:20<00:00, 20.33s/it]                                                                \n",
       "                                                                                                               \n",
       "  \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run example for DataBlob.set_default_cloud_provider\n",
    "\n",
    "username = os.environ[SERVICE_USERNAME]\n",
    "password = os.environ[SERVICE_PASSWORD]\n",
    "\n",
    "run_examples_from_docstring(\n",
    "    DataBlob.set_default_cloud_provider,\n",
    "    azure_subscription_id=os.environ[\"AZURE_SUBSCRIPTION_ID\"],\n",
    "    azure_client_id=os.environ[\"AZURE_CLIENT_ID\"],\n",
    "    azure_client_secret=os.environ[\"AZURE_CLIENT_SECRET\"],\n",
    "    azure_tenant_id=os.environ[\"AZURE_TENANT_ID\"],\n",
    "    azure_group_name=\"test-airt-service\",\n",
    "    azure_storage_account_name=\"testairtservice\",\n",
    "    username=username,\n",
    "    password=password,\n",
    "    uri=\"https://testairtservice.blob.core.windows.net/test-container/ecommerce_behavior_notebooks\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a34d605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<module>:3: No type or annotation for parameter 'uri'\n",
      "<module>:4: No type or annotation for parameter 'access_key'\n",
      "<module>:6: No type or annotation for parameter 'secret_key'\n",
      "<module>:8: No type or annotation for parameter 'cloud_provider'\n",
      "<module>:10: No type or annotation for parameter 'region'\n",
      "<module>:17: No type or annotation for parameter 'tag'\n",
      "<module>:20: No type or annotation for returned value 1\n",
      "Failed to parse annotation from 'Name' node: 'NoneType' object has no attribute 'resolve'\n",
      "Failed to parse annotation from 'Name' node: 'NoneType' object has no attribute 'resolve'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Example:                                                                                                        \n",
       "                                                                                                                 \n",
       "     # Importing necessary libraries                                                                             \n",
       "     from  airt.client import Client, DataBlob                                                                   \n",
       "                                                                                                                 \n",
       "     # Authenticate                                                                                              \n",
       "     Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")                              \n",
       "                                                                                                                 \n",
       "     # Create a datablob                                                                                         \n",
       "     # In this example, the access_key and the secret_key are set in the                                         \n",
       "     # AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables. The region                             \n",
       "     # is set to eu-west-3, feel free to change the cloud provider and the region                                \n",
       "     # to suit your needs.                                                                                       \n",
       "     db = DataBlob.from_s3(                                                                                      \n",
       "         uri=\"{fill in uri}\",                                                                                    \n",
       "         cloud_provider=\"aws\",                                                                                   \n",
       "         region=\"eu-west-3\"                                                                                      \n",
       "     )                                                                                                           \n",
       "                                                                                                                 \n",
       "     # Display the status in a progress bar                                                                      \n",
       "     db.progress_bar()                                                                                           \n",
       "                                                                                                                 \n",
       "     # Print the details of the newly created datablob                                                           \n",
       "     # If the upload is successful, the ready flag should be set to True                                         \n",
       "     print(db.details())                                                                                         \n",
       "                                                                                                                 \n",
       "  stdout  \n",
       "                            datablob_uuid datasource_uuids  ... disabled ready                                 \n",
       "  0  92c9bcb5-8681-4c4d-a9d8-9317ffbaef08           &lt;none&gt;  ...    False  True                                 \n",
       "                                                                                                               \n",
       "  [1 rows x 13 columns]                                                                                        \n",
       "                                                                                                               \n",
       "  \n",
       "  stderr  \n",
       "                                                                                                               \n",
       "    0%|          | 0/1 [00:00&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:05&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:10&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:15&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:20&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:25&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:30&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:35&lt;?, ?it/s]                                                                        \n",
       "  100%|| 1/1 [00:40&lt;00:00,  5.07s/it]                                                                \n",
       "  100%|| 1/1 [00:40&lt;00:00, 40.57s/it]                                                                \n",
       "                                                                                                               \n",
       "  \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Example:                                                                                                        \n",
       "                                                                                                                 \n",
       "     # Importing necessary libraries                                                                             \n",
       "     from  airt.client import Client, DataBlob                                                                   \n",
       "                                                                                                                 \n",
       "     # Authenticate                                                                                              \n",
       "     Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")                              \n",
       "                                                                                                                 \n",
       "     # Create a datablob                                                                                         \n",
       "     # In this example, the access_key and the secret_key are set in the                                         \n",
       "     # AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables. The region                             \n",
       "     # is set to eu-west-3, feel free to change the cloud provider and the region                                \n",
       "     # to suit your needs.                                                                                       \n",
       "     db = DataBlob.from_s3(                                                                                      \n",
       "         uri=\"{fill in uri}\",                                                                                    \n",
       "         cloud_provider=\"aws\",                                                                                   \n",
       "         region=\"eu-west-3\"                                                                                      \n",
       "     )                                                                                                           \n",
       "                                                                                                                 \n",
       "     # Display the status in a progress bar                                                                      \n",
       "     db.progress_bar()                                                                                           \n",
       "                                                                                                                 \n",
       "     # Print the details of the newly created datablob                                                           \n",
       "     # If the upload is successful, the ready flag should be set to True                                         \n",
       "     print(db.details())                                                                                         \n",
       "                                                                                                                 \n",
       "  stdout  \n",
       "                            datablob_uuid datasource_uuids  ... disabled ready                                 \n",
       "  0  92c9bcb5-8681-4c4d-a9d8-9317ffbaef08           <none>  ...    False  True                                 \n",
       "                                                                                                               \n",
       "  [1 rows x 13 columns]                                                                                        \n",
       "                                                                                                               \n",
       "  \n",
       "  stderr  \n",
       "                                                                                                               \n",
       "    0%|          | 0/1 [00:00<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:05<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:10<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:15<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:20<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:25<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:30<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:35<?, ?it/s]                                                                        \n",
       "  100%|| 1/1 [00:40<00:00,  5.07s/it]                                                                \n",
       "  100%|| 1/1 [00:40<00:00, 40.57s/it]                                                                \n",
       "                                                                                                               \n",
       "  \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run example for DataBlob.from_s3\n",
    "\n",
    "username = os.environ[SERVICE_USERNAME]\n",
    "password = os.environ[SERVICE_PASSWORD]\n",
    "\n",
    "run_examples_from_docstring(\n",
    "    DataBlob.from_s3,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    uri=TEST_S3_URI\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adab16d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<module>:3: No type or annotation for parameter 'uri'\n",
      "<module>:4: No type or annotation for parameter 'credential'\n",
      "<module>:5: No type or annotation for parameter 'cloud_provider'\n",
      "<module>:7: No type or annotation for parameter 'region'\n",
      "<module>:14: No type or annotation for parameter 'tag'\n",
      "<module>:17: No type or annotation for returned value 1\n",
      "Failed to parse annotation from 'Name' node: 'NoneType' object has no attribute 'resolve'\n",
      "Failed to parse annotation from 'Name' node: 'NoneType' object has no attribute 'resolve'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Example:                                                                                                        \n",
       "                                                                                                                 \n",
       "     # Importing necessary libraries                                                                             \n",
       "     import os                                                                                                   \n",
       "                                                                                                                 \n",
       "     from azure.identity import DefaultAzureCredential                                                           \n",
       "     from azure.mgmt.storage import StorageManagementClient                                                      \n",
       "                                                                                                                 \n",
       "     from  airt.client import Client, DataBlob                                                                   \n",
       "                                                                                                                 \n",
       "     # Create a credential for accessing Azure Blob Storage                                                      \n",
       "     # Setting the required environment variables                                                                \n",
       "     os.environ[\"AZURE_SUBSCRIPTION_ID\"] = \"{fill in azure_subscription_id}\"                                     \n",
       "     os.environ[\"AZURE_CLIENT_ID\"] = \"{fill in azure_client_id}\"                                                 \n",
       "     os.environ[\"AZURE_CLIENT_SECRET\"] = \"{fill in azure_client_secret}\"                                         \n",
       "     os.environ[\"AZURE_TENANT_ID\"]= \"{fill in azure_tenant_id}\"                                                  \n",
       "                                                                                                                 \n",
       "     # Setting the resource group name and storage account name                                                  \n",
       "     azure_group_name = \"{fill in azure_group_name}\"                                                             \n",
       "     azure_storage_account_name = \"{fill in azure_storage_account_name}\"                                         \n",
       "                                                                                                                 \n",
       "     # Retrieving the credential                                                                                 \n",
       "     azure_storage_client = StorageManagementClient(                                                             \n",
       "         DefaultAzureCredential(), os.environ[\"AZURE_SUBSCRIPTION_ID\"]                                           \n",
       "     )                                                                                                           \n",
       "     azure_storage_keys = azure_storage_client.storage_accounts.list_keys(                                       \n",
       "         azure_group_name, azure_storage_account_name                                                            \n",
       "     )                                                                                                           \n",
       "     azure_storage_keys = {v.key_name: v.value for v in azure_storage_keys.keys}                                 \n",
       "     credential = azure_storage_keys['key1']                                                                     \n",
       "                                                                                                                 \n",
       "                                                                                                                 \n",
       "     # Authenticate                                                                                              \n",
       "     Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")                              \n",
       "                                                                                                                 \n",
       "     # Create a datablob                                                                                         \n",
       "     # In this example, the datablob will be stored in an AWS S3 bucket. The region                              \n",
       "     # is set to eu-west-1 (default), feel free to change the cloud provider and                                 \n",
       "     # the region to suit your needs.                                                                            \n",
       "     db = DataBlob.from_azure_blob_storage(                                                                      \n",
       "         uri=\"{fill in uri}\",                                                                                    \n",
       "         cloud_provider=\"aws\",                                                                                   \n",
       "         credential=credential                                                                                   \n",
       "     )                                                                                                           \n",
       "                                                                                                                 \n",
       "     # Display the status in a progress bar                                                                      \n",
       "     db.progress_bar()                                                                                           \n",
       "                                                                                                                 \n",
       "     # Print the details of the newly created datablob                                                           \n",
       "     # If the upload is successful, the ready flag should be set to True                                         \n",
       "     print(db.details())                                                                                         \n",
       "                                                                                                                 \n",
       "  stdout  \n",
       "                            datablob_uuid datasource_uuids  ... disabled ready                                 \n",
       "  0  56cb3306-27e3-4604-b4b0-59216fe996b3           &lt;none&gt;  ...    False  True                                 \n",
       "                                                                                                               \n",
       "  [1 rows x 13 columns]                                                                                        \n",
       "                                                                                                               \n",
       "  \n",
       "  stderr  \n",
       "                                                                                                               \n",
       "    0%|          | 0/1 [00:00&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:05&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:10&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:15&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:20&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:25&lt;?, ?it/s]                                                                        \n",
       "  100%|| 1/1 [00:30&lt;00:00,  5.07s/it]                                                                \n",
       "  100%|| 1/1 [00:30&lt;00:00, 30.47s/it]                                                                \n",
       "                                                                                                               \n",
       "  \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Example:                                                                                                        \n",
       "                                                                                                                 \n",
       "     # Importing necessary libraries                                                                             \n",
       "     import os                                                                                                   \n",
       "                                                                                                                 \n",
       "     from azure.identity import DefaultAzureCredential                                                           \n",
       "     from azure.mgmt.storage import StorageManagementClient                                                      \n",
       "                                                                                                                 \n",
       "     from  airt.client import Client, DataBlob                                                                   \n",
       "                                                                                                                 \n",
       "     # Create a credential for accessing Azure Blob Storage                                                      \n",
       "     # Setting the required environment variables                                                                \n",
       "     os.environ[\"AZURE_SUBSCRIPTION_ID\"] = \"{fill in azure_subscription_id}\"                                     \n",
       "     os.environ[\"AZURE_CLIENT_ID\"] = \"{fill in azure_client_id}\"                                                 \n",
       "     os.environ[\"AZURE_CLIENT_SECRET\"] = \"{fill in azure_client_secret}\"                                         \n",
       "     os.environ[\"AZURE_TENANT_ID\"]= \"{fill in azure_tenant_id}\"                                                  \n",
       "                                                                                                                 \n",
       "     # Setting the resource group name and storage account name                                                  \n",
       "     azure_group_name = \"{fill in azure_group_name}\"                                                             \n",
       "     azure_storage_account_name = \"{fill in azure_storage_account_name}\"                                         \n",
       "                                                                                                                 \n",
       "     # Retrieving the credential                                                                                 \n",
       "     azure_storage_client = StorageManagementClient(                                                             \n",
       "         DefaultAzureCredential(), os.environ[\"AZURE_SUBSCRIPTION_ID\"]                                           \n",
       "     )                                                                                                           \n",
       "     azure_storage_keys = azure_storage_client.storage_accounts.list_keys(                                       \n",
       "         azure_group_name, azure_storage_account_name                                                            \n",
       "     )                                                                                                           \n",
       "     azure_storage_keys = {v.key_name: v.value for v in azure_storage_keys.keys}                                 \n",
       "     credential = azure_storage_keys['key1']                                                                     \n",
       "                                                                                                                 \n",
       "                                                                                                                 \n",
       "     # Authenticate                                                                                              \n",
       "     Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")                              \n",
       "                                                                                                                 \n",
       "     # Create a datablob                                                                                         \n",
       "     # In this example, the datablob will be stored in an AWS S3 bucket. The region                              \n",
       "     # is set to eu-west-1 (default), feel free to change the cloud provider and                                 \n",
       "     # the region to suit your needs.                                                                            \n",
       "     db = DataBlob.from_azure_blob_storage(                                                                      \n",
       "         uri=\"{fill in uri}\",                                                                                    \n",
       "         cloud_provider=\"aws\",                                                                                   \n",
       "         credential=credential                                                                                   \n",
       "     )                                                                                                           \n",
       "                                                                                                                 \n",
       "     # Display the status in a progress bar                                                                      \n",
       "     db.progress_bar()                                                                                           \n",
       "                                                                                                                 \n",
       "     # Print the details of the newly created datablob                                                           \n",
       "     # If the upload is successful, the ready flag should be set to True                                         \n",
       "     print(db.details())                                                                                         \n",
       "                                                                                                                 \n",
       "  stdout  \n",
       "                            datablob_uuid datasource_uuids  ... disabled ready                                 \n",
       "  0  56cb3306-27e3-4604-b4b0-59216fe996b3           <none>  ...    False  True                                 \n",
       "                                                                                                               \n",
       "  [1 rows x 13 columns]                                                                                        \n",
       "                                                                                                               \n",
       "  \n",
       "  stderr  \n",
       "                                                                                                               \n",
       "    0%|          | 0/1 [00:00<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:05<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:10<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:15<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:20<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:25<?, ?it/s]                                                                        \n",
       "  100%|| 1/1 [00:30<00:00,  5.07s/it]                                                                \n",
       "  100%|| 1/1 [00:30<00:00, 30.47s/it]                                                                \n",
       "                                                                                                               \n",
       "  \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run example for DataBlob.from_azure_blob_storage\n",
    "\n",
    "username = os.environ[SERVICE_USERNAME]\n",
    "password = os.environ[SERVICE_PASSWORD]\n",
    "\n",
    "run_examples_from_docstring(\n",
    "    DataBlob.from_azure_blob_storage,\n",
    "    azure_subscription_id=os.environ[\"AZURE_SUBSCRIPTION_ID\"],\n",
    "    azure_client_id=os.environ[\"AZURE_CLIENT_ID\"],\n",
    "    azure_client_secret=os.environ[\"AZURE_CLIENT_SECRET\"],\n",
    "    azure_tenant_id=os.environ[\"AZURE_TENANT_ID\"],\n",
    "    azure_group_name=\"test-airt-service\",\n",
    "    azure_storage_account_name=\"testairtservice\",\n",
    "    username=username,\n",
    "    password=password,\n",
    "    uri=\"https://testairtservice.blob.core.windows.net/test-container/ecommerce_behavior_notebooks\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1fe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/_common_metadata to ../../../tmp/test_s3_download_br6k91fp/_common_metadata\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/_metadata to ../../../tmp/test_s3_download_br6k91fp/_metadata\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.15.parquet to ../../../tmp/test_s3_download_br6k91fp/part.15.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.1.parquet to ../../../tmp/test_s3_download_br6k91fp/part.1.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.0.parquet to ../../../tmp/test_s3_download_br6k91fp/part.0.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.11.parquet to ../../../tmp/test_s3_download_br6k91fp/part.11.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.12.parquet to ../../../tmp/test_s3_download_br6k91fp/part.12.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.10.parquet to ../../../tmp/test_s3_download_br6k91fp/part.10.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.14.parquet to ../../../tmp/test_s3_download_br6k91fp/part.14.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.13.parquet to ../../../tmp/test_s3_download_br6k91fp/part.13.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.17.parquet to ../../../tmp/test_s3_download_br6k91fp/part.17.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.16.parquet to ../../../tmp/test_s3_download_br6k91fp/part.16.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.7.parquet to ../../../tmp/test_s3_download_br6k91fp/part.7.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.18.parquet to ../../../tmp/test_s3_download_br6k91fp/part.18.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.19.parquet to ../../../tmp/test_s3_download_br6k91fp/part.19.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.3.parquet to ../../../tmp/test_s3_download_br6k91fp/part.3.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.2.parquet to ../../../tmp/test_s3_download_br6k91fp/part.2.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.4.parquet to ../../../tmp/test_s3_download_br6k91fp/part.4.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.6.parquet to ../../../tmp/test_s3_download_br6k91fp/part.6.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.9.parquet to ../../../tmp/test_s3_download_br6k91fp/part.9.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.5.parquet to ../../../tmp/test_s3_download_br6k91fp/part.5.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.8.parquet to ../../../tmp/test_s3_download_br6k91fp/part.8.parquet\n",
      "_common_metadata  part.12.parquet  part.18.parquet  part.6.parquet\n",
      "_metadata\t  part.13.parquet  part.19.parquet  part.7.parquet\n",
      "part.0.parquet\t  part.14.parquet  part.2.parquet   part.8.parquet\n",
      "part.1.parquet\t  part.15.parquet  part.3.parquet   part.9.parquet\n",
      "part.10.parquet   part.16.parquet  part.4.parquet\n",
      "part.11.parquet   part.17.parquet  part.5.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<module>:6: No type or annotation for parameter 'host'\n",
      "<module>:7: No type or annotation for parameter 'database'\n",
      "<module>:8: No type or annotation for parameter 'table'\n",
      "<module>:9: No type or annotation for parameter 'port'\n",
      "<module>:10: No type or annotation for parameter 'cloud_provider'\n",
      "<module>:12: No type or annotation for parameter 'region'\n",
      "<module>:19: No type or annotation for parameter 'username'\n",
      "<module>:21: No type or annotation for parameter 'password'\n",
      "<module>:23: No type or annotation for parameter 'tag'\n",
      "<module>:26: No type or annotation for returned value 1\n",
      "Failed to parse annotation from 'Name' node: 'NoneType' object has no attribute 'resolve'\n",
      "Failed to parse annotation from 'Name' node: 'NoneType' object has no attribute 'resolve'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Example:                                                                                                        \n",
       "                                                                                                                 \n",
       "     # Importing necessary libraries                                                                             \n",
       "     from  airt.client import Client, DataBlob                                                                   \n",
       "                                                                                                                 \n",
       "     # Authenticate                                                                                              \n",
       "     Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")                              \n",
       "                                                                                                                 \n",
       "     # Create a datablob                                                                                         \n",
       "     # In this example, the datablob will be stored in an AWS S3 bucket. The region                              \n",
       "     # is set to eu-west-3, feel free to change the cloud provider and the region                                \n",
       "     # to suit your needs.                                                                                       \n",
       "     db = DataBlob.from_mysql(                                                                                   \n",
       "         username=\"{fill in database_username}\",                                                                 \n",
       "         password=\"{fill in database_password}\",                                                                 \n",
       "         host=\"{fill in host}\",                                                                                  \n",
       "         database=\"{fill in database}\",                                                                          \n",
       "         table=\"{fill in table}\",                                                                                \n",
       "         port=\"{fill in port}\",                                                                                  \n",
       "         cloud_provider=\"aws\",                                                                                   \n",
       "         region=\"eu-west-3\"                                                                                      \n",
       "     )                                                                                                           \n",
       "                                                                                                                 \n",
       "     # Display the status in a progress bar                                                                      \n",
       "     db.progress_bar()                                                                                           \n",
       "                                                                                                                 \n",
       "     # Print the details of the newly created datablob                                                           \n",
       "     # If the upload is successful, the ready flag should be set to True                                         \n",
       "     print(db.details())                                                                                         \n",
       "                                                                                                                 \n",
       "  stdout  \n",
       "                            datablob_uuid datasource_uuids  ... disabled ready                                 \n",
       "  0  0cc90f14-b0bd-4976-a090-48b4996b74d4           &lt;none&gt;  ...    False  True                                 \n",
       "                                                                                                               \n",
       "  [1 rows x 13 columns]                                                                                        \n",
       "                                                                                                               \n",
       "  \n",
       "  stderr  \n",
       "                                                                                                               \n",
       "    0%|          | 0/1 [00:00&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:05&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:10&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:15&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:20&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:25&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:30&lt;?, ?it/s]                                                                        \n",
       "  100%|| 1/1 [00:35&lt;00:00,  5.07s/it]                                                                \n",
       "  100%|| 1/1 [00:35&lt;00:00, 35.53s/it]                                                                \n",
       "                                                                                                               \n",
       "  \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Example:                                                                                                        \n",
       "                                                                                                                 \n",
       "     # Importing necessary libraries                                                                             \n",
       "     from  airt.client import Client, DataBlob                                                                   \n",
       "                                                                                                                 \n",
       "     # Authenticate                                                                                              \n",
       "     Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")                              \n",
       "                                                                                                                 \n",
       "     # Create a datablob                                                                                         \n",
       "     # In this example, the datablob will be stored in an AWS S3 bucket. The region                              \n",
       "     # is set to eu-west-3, feel free to change the cloud provider and the region                                \n",
       "     # to suit your needs.                                                                                       \n",
       "     db = DataBlob.from_mysql(                                                                                   \n",
       "         username=\"{fill in database_username}\",                                                                 \n",
       "         password=\"{fill in database_password}\",                                                                 \n",
       "         host=\"{fill in host}\",                                                                                  \n",
       "         database=\"{fill in database}\",                                                                          \n",
       "         table=\"{fill in table}\",                                                                                \n",
       "         port=\"{fill in port}\",                                                                                  \n",
       "         cloud_provider=\"aws\",                                                                                   \n",
       "         region=\"eu-west-3\"                                                                                      \n",
       "     )                                                                                                           \n",
       "                                                                                                                 \n",
       "     # Display the status in a progress bar                                                                      \n",
       "     db.progress_bar()                                                                                           \n",
       "                                                                                                                 \n",
       "     # Print the details of the newly created datablob                                                           \n",
       "     # If the upload is successful, the ready flag should be set to True                                         \n",
       "     print(db.details())                                                                                         \n",
       "                                                                                                                 \n",
       "  stdout  \n",
       "                            datablob_uuid datasource_uuids  ... disabled ready                                 \n",
       "  0  0cc90f14-b0bd-4976-a090-48b4996b74d4           <none>  ...    False  True                                 \n",
       "                                                                                                               \n",
       "  [1 rows x 13 columns]                                                                                        \n",
       "                                                                                                               \n",
       "  \n",
       "  stderr  \n",
       "                                                                                                               \n",
       "    0%|          | 0/1 [00:00<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:05<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:10<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:15<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:20<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:25<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:30<?, ?it/s]                                                                        \n",
       "  100%|| 1/1 [00:35<00:00,  5.07s/it]                                                                \n",
       "  100%|| 1/1 [00:35<00:00, 35.53s/it]                                                                \n",
       "                                                                                                               \n",
       "  \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run example for DataBlob.from_mysql\n",
    "# Creating a test_table\n",
    "database_username=os.environ[\"DB_USERNAME\"]\n",
    "database_password=os.environ[\"DB_PASSWORD\"]\n",
    "host=os.environ[\"DB_HOST\"]\n",
    "port=os.environ[\"DB_PORT\"]\n",
    "database=os.environ[\"DB_DATABASE\"]\n",
    "database_server=os.environ[\"DB_DATABASE_SERVER\"]\n",
    "table=\"test_db_pull\"\n",
    "\n",
    "def get_db_engine():    \n",
    "    quoted_password = urlquote(database_password)\n",
    "    conn_str = f\"{database_server}://{database_username}:{quoted_password}@{host}:{port}/{database}\"\n",
    "    engine = create_engine(conn_str)\n",
    "    return engine\n",
    "\n",
    "with tempfile.TemporaryDirectory(prefix=\"test_s3_download_\") as d:\n",
    "    !aws s3 sync {TEST_S3_URI} {d}\n",
    "    !ls {d}\n",
    "    \n",
    "    engine = get_db_engine()\n",
    "    \n",
    "    df = pd.read_parquet(d)\n",
    "    try:\n",
    "        df.to_sql(\"test_db_pull\", con=engine, if_exists=\"fail\")\n",
    "    except ValueError as e:\n",
    "        display(e)\n",
    "\n",
    "run_examples_from_docstring(\n",
    "    DataBlob.from_mysql,\n",
    "    username=os.environ[SERVICE_USERNAME],\n",
    "    password=os.environ[SERVICE_PASSWORD],\n",
    "    database_username=database_username,\n",
    "    database_password=database_password,\n",
    "    host=host,\n",
    "    database=database,\n",
    "    table=table,\n",
    "    port=port,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd75325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<module>:6: No type or annotation for parameter 'host'\n",
      "<module>:7: No type or annotation for parameter 'database'\n",
      "<module>:8: No type or annotation for parameter 'table'\n",
      "<module>:9: No type or annotation for parameter 'protocol'\n",
      "<module>:10: No type or annotation for parameter 'index_column'\n",
      "<module>:11: No type or annotation for parameter 'timestamp_column'\n",
      "<module>:12: No type or annotation for parameter 'port'\n",
      "<module>:13: No type or annotation for parameter 'cloud_provider'\n",
      "<module>:15: No type or annotation for parameter 'region'\n",
      "<module>:22: No type or annotation for parameter 'username'\n",
      "<module>:24: No type or annotation for parameter 'password'\n",
      "<module>:26: No type or annotation for parameter 'filters'\n",
      "<module>:27: No type or annotation for parameter 'tag'\n",
      "<module>:30: No type or annotation for returned value 1\n",
      "Failed to parse annotation from 'Name' node: 'NoneType' object has no attribute 'resolve'\n",
      "Failed to parse annotation from 'Name' node: 'NoneType' object has no attribute 'resolve'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Example:                                                                                                        \n",
       "                                                                                                                 \n",
       "     # Importing necessary libraries                                                                             \n",
       "     from  airt.client import Client, DataBlob                                                                   \n",
       "                                                                                                                 \n",
       "     # Authenticate                                                                                              \n",
       "     Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")                              \n",
       "                                                                                                                 \n",
       "     # Create a datablob                                                                                         \n",
       "     # In this example, the datablob will be stored in an AWS S3 bucket. The region                              \n",
       "     # is set to eu-west-3, feel free to change the cloud provider and the region                                \n",
       "     # to suit your needs.                                                                                       \n",
       "     db = DataBlob.from_clickhouse(                                                                              \n",
       "         username=\"{fill in database_username}\",                                                                 \n",
       "         password=\"{fill in database_password}\",                                                                 \n",
       "         host=\"{fill in host}\",                                                                                  \n",
       "         database=\"{fill in database}\",                                                                          \n",
       "         table=\"{fill in table}\",                                                                                \n",
       "         index_column=\"{fill in index_column}\",                                                                  \n",
       "         timestamp_column=\"{fill in timestamp_column}\",                                                          \n",
       "         port=\"{fill in port}\",                                                                                  \n",
       "         filters={fill in filters},                                                                              \n",
       "         protocol=\"native\",                                                                                      \n",
       "         cloud_provider=\"aws\",                                                                                   \n",
       "         region=\"eu-west-3\"                                                                                      \n",
       "     )                                                                                                           \n",
       "                                                                                                                 \n",
       "     # Display the status in a progress bar                                                                      \n",
       "     db.progress_bar()                                                                                           \n",
       "                                                                                                                 \n",
       "     # Print the details of the newly created datablob                                                           \n",
       "     # If the upload is successful, the ready flag should be set to True                                         \n",
       "     print(db.details())                                                                                         \n",
       "                                                                                                                 \n",
       "  stdout  \n",
       "                            datablob_uuid datasource_uuids  ... disabled ready                                 \n",
       "  0  cd976ec5-54b7-4462-ad00-b9517ccc6b67           &lt;none&gt;  ...    False  True                                 \n",
       "                                                                                                               \n",
       "  [1 rows x 13 columns]                                                                                        \n",
       "                                                                                                               \n",
       "  \n",
       "  stderr  \n",
       "                                                                                                               \n",
       "    0%|          | 0/1 [00:00&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:05&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:10&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:15&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:20&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:25&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:30&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:35&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:40&lt;?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:45&lt;?, ?it/s]                                                                        \n",
       "  100%|| 1/1 [00:50&lt;00:00,  5.08s/it]                                                                \n",
       "  100%|| 1/1 [00:50&lt;00:00, 50.80s/it]                                                                \n",
       "                                                                                                               \n",
       "  \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Example:                                                                                                        \n",
       "                                                                                                                 \n",
       "     # Importing necessary libraries                                                                             \n",
       "     from  airt.client import Client, DataBlob                                                                   \n",
       "                                                                                                                 \n",
       "     # Authenticate                                                                                              \n",
       "     Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")                              \n",
       "                                                                                                                 \n",
       "     # Create a datablob                                                                                         \n",
       "     # In this example, the datablob will be stored in an AWS S3 bucket. The region                              \n",
       "     # is set to eu-west-3, feel free to change the cloud provider and the region                                \n",
       "     # to suit your needs.                                                                                       \n",
       "     db = DataBlob.from_clickhouse(                                                                              \n",
       "         username=\"{fill in database_username}\",                                                                 \n",
       "         password=\"{fill in database_password}\",                                                                 \n",
       "         host=\"{fill in host}\",                                                                                  \n",
       "         database=\"{fill in database}\",                                                                          \n",
       "         table=\"{fill in table}\",                                                                                \n",
       "         index_column=\"{fill in index_column}\",                                                                  \n",
       "         timestamp_column=\"{fill in timestamp_column}\",                                                          \n",
       "         port=\"{fill in port}\",                                                                                  \n",
       "         filters={fill in filters},                                                                              \n",
       "         protocol=\"native\",                                                                                      \n",
       "         cloud_provider=\"aws\",                                                                                   \n",
       "         region=\"eu-west-3\"                                                                                      \n",
       "     )                                                                                                           \n",
       "                                                                                                                 \n",
       "     # Display the status in a progress bar                                                                      \n",
       "     db.progress_bar()                                                                                           \n",
       "                                                                                                                 \n",
       "     # Print the details of the newly created datablob                                                           \n",
       "     # If the upload is successful, the ready flag should be set to True                                         \n",
       "     print(db.details())                                                                                         \n",
       "                                                                                                                 \n",
       "  stdout  \n",
       "                            datablob_uuid datasource_uuids  ... disabled ready                                 \n",
       "  0  cd976ec5-54b7-4462-ad00-b9517ccc6b67           <none>  ...    False  True                                 \n",
       "                                                                                                               \n",
       "  [1 rows x 13 columns]                                                                                        \n",
       "                                                                                                               \n",
       "  \n",
       "  stderr  \n",
       "                                                                                                               \n",
       "    0%|          | 0/1 [00:00<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:05<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:10<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:15<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:20<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:25<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:30<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:35<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:40<?, ?it/s]                                                                        \n",
       "    0%|          | 0/1 [00:45<?, ?it/s]                                                                        \n",
       "  100%|| 1/1 [00:50<00:00,  5.08s/it]                                                                \n",
       "  100%|| 1/1 [00:50<00:00, 50.80s/it]                                                                \n",
       "                                                                                                               \n",
       "  \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run example for DataBlob.from_clickhouse\n",
    "\n",
    "\n",
    "run_examples_from_docstring(\n",
    "    DataBlob.from_clickhouse,\n",
    "    username=os.environ[SERVICE_USERNAME],\n",
    "    password=os.environ[SERVICE_PASSWORD],\n",
    "    database_username=os.environ.get(\"CLICKHOUSE_USERNAME\"),\n",
    "    database_password=os.environ.get(\"CLICKHOUSE_PASSWORD\"),\n",
    "    host=os.environ.get(\"CLICKHOUSE_HOST\"),\n",
    "    database=os.environ.get(\"CLICKHOUSE_DATABASE\"),\n",
    "    table=os.environ.get(\"CLICKHOUSE_EVENTS_TABLE\"),\n",
    "    index_column = \"PersonId\",\n",
    "    timestamp_column = \"OccurredTimeTicks\",\n",
    "    filters = \"{'AccountId': 312571}\",\n",
    "    port=\"0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600a2d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/_common_metadata to ../../../tmp/test_s3_download_3mlmcv5d/parquet/_common_metadata\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/_metadata to ../../../tmp/test_s3_download_3mlmcv5d/parquet/_metadata\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.10.parquet to ../../../tmp/test_s3_download_3mlmcv5d/parquet/part.10.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.11.parquet to ../../../tmp/test_s3_download_3mlmcv5d/parquet/part.11.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.15.parquet to ../../../tmp/test_s3_download_3mlmcv5d/parquet/part.15.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.14.parquet to ../../../tmp/test_s3_download_3mlmcv5d/parquet/part.14.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.13.parquet to ../../../tmp/test_s3_download_3mlmcv5d/parquet/part.13.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.1.parquet to ../../../tmp/test_s3_download_3mlmcv5d/parquet/part.1.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.17.parquet to ../../../tmp/test_s3_download_3mlmcv5d/parquet/part.17.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.19.parquet to ../../../tmp/test_s3_download_3mlmcv5d/parquet/part.19.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.0.parquet to ../../../tmp/test_s3_download_3mlmcv5d/parquet/part.0.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.16.parquet to ../../../tmp/test_s3_download_3mlmcv5d/parquet/part.16.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.4.parquet to ../../../tmp/test_s3_download_3mlmcv5d/parquet/part.4.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.2.parquet to ../../../tmp/test_s3_download_3mlmcv5d/parquet/part.2.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.18.parquet to ../../../tmp/test_s3_download_3mlmcv5d/parquet/part.18.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.7.parquet to ../../../tmp/test_s3_download_3mlmcv5d/parquet/part.7.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.5.parquet to ../../../tmp/test_s3_download_3mlmcv5d/parquet/part.5.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.3.parquet to ../../../tmp/test_s3_download_3mlmcv5d/parquet/part.3.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.9.parquet to ../../../tmp/test_s3_download_3mlmcv5d/parquet/part.9.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.6.parquet to ../../../tmp/test_s3_download_3mlmcv5d/parquet/part.6.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.8.parquet to ../../../tmp/test_s3_download_3mlmcv5d/parquet/part.8.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.12.parquet to ../../../tmp/test_s3_download_3mlmcv5d/parquet/part.12.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Path('/tmp/test_s3_download_3mlmcv5d/csv/file-15.csv'),\n",
       " Path('/tmp/test_s3_download_3mlmcv5d/csv/file-13.csv'),\n",
       " Path('/tmp/test_s3_download_3mlmcv5d/csv/file-17.csv'),\n",
       " Path('/tmp/test_s3_download_3mlmcv5d/csv/file-4.csv'),\n",
       " Path('/tmp/test_s3_download_3mlmcv5d/csv/file-19.csv'),\n",
       " Path('/tmp/test_s3_download_3mlmcv5d/csv/file-3.csv'),\n",
       " Path('/tmp/test_s3_download_3mlmcv5d/csv/file-18.csv'),\n",
       " Path('/tmp/test_s3_download_3mlmcv5d/csv/file-2.csv'),\n",
       " Path('/tmp/test_s3_download_3mlmcv5d/csv/file-11.csv'),\n",
       " Path('/tmp/test_s3_download_3mlmcv5d/csv/file-9.csv'),\n",
       " Path('/tmp/test_s3_download_3mlmcv5d/csv/file-0.csv'),\n",
       " Path('/tmp/test_s3_download_3mlmcv5d/csv/file-7.csv'),\n",
       " Path('/tmp/test_s3_download_3mlmcv5d/csv/file-5.csv'),\n",
       " Path('/tmp/test_s3_download_3mlmcv5d/csv/file-1.csv'),\n",
       " Path('/tmp/test_s3_download_3mlmcv5d/csv/file-16.csv'),\n",
       " Path('/tmp/test_s3_download_3mlmcv5d/csv/file-6.csv'),\n",
       " Path('/tmp/test_s3_download_3mlmcv5d/csv/file-8.csv'),\n",
       " Path('/tmp/test_s3_download_3mlmcv5d/csv/file-14.csv'),\n",
       " Path('/tmp/test_s3_download_3mlmcv5d/csv/file-12.csv'),\n",
       " Path('/tmp/test_s3_download_3mlmcv5d/csv/file-10.csv')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<module>:5: No type or annotation for parameter 'path'\n",
      "<module>:6: No type or annotation for parameter 'cloud_provider'\n",
      "<module>:8: No type or annotation for parameter 'region'\n",
      "<module>:15: No type or annotation for parameter 'tag'\n",
      "<module>:16: No type or annotation for parameter 'show_progress'\n",
      "<module>:19: No type or annotation for returned value 1\n",
      "Failed to parse annotation from 'Name' node: 'NoneType' object has no attribute 'resolve'\n",
      "Failed to parse annotation from 'Name' node: 'NoneType' object has no attribute 'resolve'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Example:                                                                                                        \n",
       "                                                                                                                 \n",
       "     # Importing necessary libraries                                                                             \n",
       "     from  airt.client import Client, DataBlob                                                                   \n",
       "                                                                                                                 \n",
       "     # Authenticate                                                                                              \n",
       "     Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")                              \n",
       "                                                                                                                 \n",
       "     # Create a datablob                                                                                         \n",
       "     # In this example, the datablob will be stored in an AWS S3 bucket. The region                              \n",
       "     # is set to eu-west-3, feel free to change the cloud provider and the region                                \n",
       "     # to suit your needs.                                                                                       \n",
       "     db = DataBlob.from_local(                                                                                   \n",
       "         path=\"{fill in path}\",                                                                                  \n",
       "         cloud_provider=\"aws\",                                                                                   \n",
       "         region=\"eu-west-3\"                                                                                      \n",
       "     )                                                                                                           \n",
       "                                                                                                                 \n",
       "     # Display the status in a progress bar                                                                      \n",
       "     db.progress_bar()                                                                                           \n",
       "                                                                                                                 \n",
       "     # Print the details of the newly created datablob                                                           \n",
       "     # If the upload is successful, the ready flag should be set to True                                         \n",
       "     print(db.details())                                                                                         \n",
       "                                                                                                                 \n",
       "                                                                                                                 \n",
       "  stdout  \n",
       "                            datablob_uuid datasource_uuids  ... disabled  ready                                \n",
       "  0  0fe1ff4c-f176-4965-9b38-1650b0ae850b           &lt;none&gt;  ...    False  False                                \n",
       "                                                                                                               \n",
       "  [1 rows x 13 columns]                                                                                        \n",
       "                                                                                                               \n",
       "  \n",
       "  stderr  \n",
       "                                                                                                               \n",
       "    0%|          | 0/20 [00:00&lt;?, ?it/s]                                                                       \n",
       "    5%|         | 1/20 [00:02&lt;00:43,  2.30s/it]                                                               \n",
       "   10%|         | 2/20 [00:04&lt;00:37,  2.08s/it]                                                               \n",
       "   15%|        | 3/20 [00:06&lt;00:40,  2.38s/it]                                                               \n",
       "   20%|        | 4/20 [00:11&lt;00:53,  3.35s/it]                                                               \n",
       "   25%|       | 5/20 [00:15&lt;00:52,  3.51s/it]                                                               \n",
       "   30%|       | 6/20 [00:17&lt;00:40,  2.93s/it]                                                               \n",
       "   35%|      | 7/20 [00:19&lt;00:33,  2.55s/it]                                                               \n",
       "   40%|      | 8/20 [00:21&lt;00:31,  2.64s/it]                                                               \n",
       "   45%|     | 9/20 [00:25&lt;00:31,  2.82s/it]                                                               \n",
       "   50%|     | 10/20 [00:27&lt;00:27,  2.70s/it]                                                              \n",
       "   55%|    | 11/20 [00:30&lt;00:24,  2.71s/it]                                                              \n",
       "   60%|    | 12/20 [00:34&lt;00:25,  3.14s/it]                                                              \n",
       "   65%|   | 13/20 [00:36&lt;00:19,  2.78s/it]                                                              \n",
       "   70%|   | 14/20 [00:38&lt;00:15,  2.55s/it]                                                              \n",
       "   75%|  | 15/20 [00:41&lt;00:14,  2.82s/it]                                                              \n",
       "   80%|  | 16/20 [00:45&lt;00:12,  3.02s/it]                                                              \n",
       "   85%| | 17/20 [00:47&lt;00:08,  2.84s/it]                                                              \n",
       "   90%| | 18/20 [00:50&lt;00:05,  2.86s/it]                                                              \n",
       "   95%|| 19/20 [00:55&lt;00:03,  3.32s/it]                                                              \n",
       "  100%|| 20/20 [00:59&lt;00:00,  3.62s/it]                                                              \n",
       "  100%|| 20/20 [00:59&lt;00:00,  2.97s/it]                                                              \n",
       "                                                                                                               \n",
       "  \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Example:                                                                                                        \n",
       "                                                                                                                 \n",
       "     # Importing necessary libraries                                                                             \n",
       "     from  airt.client import Client, DataBlob                                                                   \n",
       "                                                                                                                 \n",
       "     # Authenticate                                                                                              \n",
       "     Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")                              \n",
       "                                                                                                                 \n",
       "     # Create a datablob                                                                                         \n",
       "     # In this example, the datablob will be stored in an AWS S3 bucket. The region                              \n",
       "     # is set to eu-west-3, feel free to change the cloud provider and the region                                \n",
       "     # to suit your needs.                                                                                       \n",
       "     db = DataBlob.from_local(                                                                                   \n",
       "         path=\"{fill in path}\",                                                                                  \n",
       "         cloud_provider=\"aws\",                                                                                   \n",
       "         region=\"eu-west-3\"                                                                                      \n",
       "     )                                                                                                           \n",
       "                                                                                                                 \n",
       "     # Display the status in a progress bar                                                                      \n",
       "     db.progress_bar()                                                                                           \n",
       "                                                                                                                 \n",
       "     # Print the details of the newly created datablob                                                           \n",
       "     # If the upload is successful, the ready flag should be set to True                                         \n",
       "     print(db.details())                                                                                         \n",
       "                                                                                                                 \n",
       "                                                                                                                 \n",
       "  stdout  \n",
       "                            datablob_uuid datasource_uuids  ... disabled  ready                                \n",
       "  0  0fe1ff4c-f176-4965-9b38-1650b0ae850b           <none>  ...    False  False                                \n",
       "                                                                                                               \n",
       "  [1 rows x 13 columns]                                                                                        \n",
       "                                                                                                               \n",
       "  \n",
       "  stderr  \n",
       "                                                                                                               \n",
       "    0%|          | 0/20 [00:00<?, ?it/s]                                                                       \n",
       "    5%|         | 1/20 [00:02<00:43,  2.30s/it]                                                               \n",
       "   10%|         | 2/20 [00:04<00:37,  2.08s/it]                                                               \n",
       "   15%|        | 3/20 [00:06<00:40,  2.38s/it]                                                               \n",
       "   20%|        | 4/20 [00:11<00:53,  3.35s/it]                                                               \n",
       "   25%|       | 5/20 [00:15<00:52,  3.51s/it]                                                               \n",
       "   30%|       | 6/20 [00:17<00:40,  2.93s/it]                                                               \n",
       "   35%|      | 7/20 [00:19<00:33,  2.55s/it]                                                               \n",
       "   40%|      | 8/20 [00:21<00:31,  2.64s/it]                                                               \n",
       "   45%|     | 9/20 [00:25<00:31,  2.82s/it]                                                               \n",
       "   50%|     | 10/20 [00:27<00:27,  2.70s/it]                                                              \n",
       "   55%|    | 11/20 [00:30<00:24,  2.71s/it]                                                              \n",
       "   60%|    | 12/20 [00:34<00:25,  3.14s/it]                                                              \n",
       "   65%|   | 13/20 [00:36<00:19,  2.78s/it]                                                              \n",
       "   70%|   | 14/20 [00:38<00:15,  2.55s/it]                                                              \n",
       "   75%|  | 15/20 [00:41<00:14,  2.82s/it]                                                              \n",
       "   80%|  | 16/20 [00:45<00:12,  3.02s/it]                                                              \n",
       "   85%| | 17/20 [00:47<00:08,  2.84s/it]                                                              \n",
       "   90%| | 18/20 [00:50<00:05,  2.86s/it]                                                              \n",
       "   95%|| 19/20 [00:55<00:03,  3.32s/it]                                                              \n",
       "  100%|| 20/20 [00:59<00:00,  3.62s/it]                                                              \n",
       "  100%|| 20/20 [00:59<00:00,  2.97s/it]                                                              \n",
       "                                                                                                               \n",
       "  \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run example for DataBlob.from_local\n",
    "# Helper function to download a sample csv file into the temp directory for DataBlob.from_local\n",
    "\n",
    "def get_test_csv_path() -> Path:\n",
    "    \"\"\"Downloads the account_312571_events from the s3 bucket and stores it in temp folder. \n",
    "    Finally converts the downloaded account_312571_events files to a csv file and returns the\n",
    "    path of the temp folder and the temp csv file.\n",
    "    \"\"\"\n",
    "    temp_dirpath = Path(tempfile.mkdtemp(prefix=\"test_s3_download_\"))\n",
    "\n",
    "    !aws s3 sync {TEST_S3_URI} {temp_dirpath / \"parquet\"}\n",
    "\n",
    "    parquet_path = Path(temp_dirpath / \"parquet\")\n",
    "    csv_dirpath = Path(temp_dirpath / \"csv\")\n",
    "    os.mkdir(csv_dirpath) \n",
    "    \n",
    "    for i, f in enumerate(list(parquet_path.glob(\"*.parquet\"))):\n",
    "        df = pd.read_parquet(f)\n",
    "        df.to_csv(csv_dirpath / f\"file-{i}.csv\", index=False)\n",
    "\n",
    "    display(list(csv_dirpath.glob(\"*\")))\n",
    "\n",
    "    return temp_dirpath, csv_dirpath, parquet_path\n",
    "\n",
    "# Create temp directory\n",
    "temp_dir, csv_dirpath, parquet_path = get_test_csv_path()\n",
    "\n",
    "run_examples_from_docstring(\n",
    "    DataBlob.from_local,\n",
    "    username=os.environ[SERVICE_USERNAME],\n",
    "    password=os.environ[SERVICE_PASSWORD],\n",
    "    path=str(csv_dirpath)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08585cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"actual={'id': '00000000-0000-0000-0000-000000000000', 'datasources': '<none>', 'tags': 'latest'}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for DataBlob._get_tag_name_and_datasource_id:\n",
    "RANDOM_UUID_FOR_TESTING = \"00000000-0000-0000-0000-000000000000\"\n",
    "\n",
    "res = {\n",
    "    \"id\": RANDOM_UUID_FOR_TESTING,\n",
    "    \"datasources\": [],\n",
    "    \"tags\": [{\"id\": 1, \"name\": \"latest\", \"created\": \"2022-03-25T07:22:07\"}],\n",
    "}\n",
    "\n",
    "expected = {\"id\": RANDOM_UUID_FOR_TESTING, \"datasources\": \"<none>\", \"tags\": \"latest\"}\n",
    "\n",
    "actual = DataBlob._get_tag_name_and_datasource_id(res)\n",
    "display(f\"{actual=}\")\n",
    "assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c4ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"actual={'id': '00000000-0000-0000-0000-000000000000', 'datasources': '00000000-0000-0000-0000-000000000000, 00000000-0000-0000-0000-000000000000, 00000000-0000-0000-0000-000000000000', 'tags': 'latest'}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for DataBlob._get_tag_name_and_datasource_id:\n",
    "\n",
    "res = {\n",
    "    \"id\": RANDOM_UUID_FOR_TESTING,\n",
    "    \"datasources\": [ RANDOM_UUID_FOR_TESTING, RANDOM_UUID_FOR_TESTING, RANDOM_UUID_FOR_TESTING],\n",
    "    \"tags\": [{\"id\": 1, \"name\": \"latest\", \"created\": \"2022-03-25T07:22:07\"}],\n",
    "}\n",
    "\n",
    "expected = {\"id\": RANDOM_UUID_FOR_TESTING, \"datasources\": f\"{RANDOM_UUID_FOR_TESTING}, {RANDOM_UUID_FOR_TESTING}, {RANDOM_UUID_FOR_TESTING}\", \"tags\": \"latest\"}\n",
    "\n",
    "actual = DataBlob._get_tag_name_and_datasource_id(res)\n",
    "\n",
    "display(f\"{actual=}\")\n",
    "assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6896d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hypens_from_id(id:str) -> str:\n",
    "    return \"\".join((id).split(\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a374adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00000000000000000000000000000000'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = remove_hypens_from_id(RANDOM_UUID_FOR_TESTING)\n",
    "assert len(actual) == 32\n",
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7096bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "@patch\n",
    "def details(self: DataBlob) -> pd.DataFrame:\n",
    "    \"\"\"Return details of a datablob.\n",
    "\n",
    "    Returns:\n",
    "        The datablob details as a pandas dataframe.\n",
    "\n",
    "    Raises:\n",
    "        ConnectionError: If the server address is invalid or not reachable.\n",
    "    \"\"\"\n",
    "\n",
    "    details = Client._get_data(relative_url=f\"/datablob/{self.uuid}\")\n",
    "    \n",
    "    details = DataBlob._get_tag_name_and_datasource_id(details)\n",
    "\n",
    "    details_df = pd.DataFrame([details])[DataBlob.ALL_DB_COLS]\n",
    "    \n",
    "    details_df = details_df.rename(columns=DataBlob.COLS_TO_RENAME)\n",
    "\n",
    "    return add_ready_column(details_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fb69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "add_example_to_docs(DataBlob.details, _docstring_example.__doc__) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e9ce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "\n",
    "DataBlob.details.__doc__ = DataBlob.details.__doc__ + f\"\\n    Columns in the resulting dataframe are: {', '.join(DataBlob.ALL_DB_COLS)}.\" # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3241e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return details of a datablob.\\n\\nReturns:\\n    The datablob details as a pandas dataframe.\\n\\nRaises:\\n    ConnectionError: If the server address is invalid or not reachable.\\n\\n\\nExample:\\n    ```python\\n    # Importing necessary libraries\\n    from  airt.client import Client, DataBlob\\n\\n    # Authenticate\\n    Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")\\n\\n    # Create a datablob\\n    # In this example, the datablob will be stored in an AWS S3 bucket. The \\n    # access_key and the secret_key are set in the AWS_ACCESS_KEY_ID and \\n    # AWS_SECRET_ACCESS_KEY environment variables, and the region is set to \\n    # eu-west-3; feel free to change the cloud provider and the region to \\n    # suit your needs.\\n    db = DataBlob.from_s3(\\n        uri=\"{fill in uri}\",\\n        cloud_provider=\"aws\",\\n        region=\"eu-west-3\"\\n    )\\n\\n    # Display the status in a progress bar\\n    # Call the wait method to wait for the progress to finish but\\n    # without displaying an interactive progress bar.\\n    db.progress_bar()\\n\\n    # Display the ready status\\n    # If the datablob is successfully uploaded, True will be returned.\\n    print(db.is_ready())\\n\\n    # Print the details of the newly created datablob\\n    print(db.details())\\n\\n    # Display the details of all datablob created by the currently\\n    # logged-in user\\n    print(DataBlob.as_df(DataBlob.ls()))\\n\\n    # Create a datasource\\n    ds = db.to_datasource(\\n        file_type=\"{fill in file_type}\",\\n        index_column=\"{fill in index_column}\",\\n        sort_by=\"{fill in sort_by}\",\\n    )\\n\\n    # Display the status in a progress bar\\n    ds.progress_bar()\\n\\n    # Display the head of the data to ensure everything is fine.\\n    print(ds.head())\\n\\n    # Tag the datablob\\n    print(db.tag(name=\"{fill in tag_name}\"))\\n\\n    # Delete the datablob\\n    print(db.delete())\\n    ```\\n\\n    Columns in the resulting dataframe are: uuid, datasources, type, source, region, cloud_provider, tags, pulled_on, completed_steps, total_steps, folder_size, user, error, disabled.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "details_doc = DataBlob.details.__doc__\n",
    "\n",
    "display(details_doc)\n",
    "assert ', '.join(DataBlob.ALL_DB_COLS) in details_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93372ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create a s3 datablob\n",
    "\n",
    "# Authenticate\n",
    "Client.get_token()\n",
    "\n",
    "_db = None\n",
    "@contextmanager\n",
    "def generate_db(cloud_provider: Optional[str] = \"aws\", region: Optional[str] = None, force_create: bool = False):\n",
    "    global _db\n",
    "    \n",
    "    if _db is None or force_create:\n",
    "        with DataBlob.set_default_cloud_provider(cloud_provider=cloud_provider, region=region):\n",
    "            _db = DataBlob.from_s3(\n",
    "                uri=TEST_S3_URI,\n",
    "                access_key=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "                secret_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "            )\n",
    "            _db.progress_bar()\n",
    "    yield _db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41f102f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:45<00:00, 45.65s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"df['tags'].item()='latest'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datablob_uuid</th>\n",
       "      <th>datasource_uuids</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "      <th>region</th>\n",
       "      <th>cloud_provider</th>\n",
       "      <th>tags</th>\n",
       "      <th>pulled_on</th>\n",
       "      <th>folder_size</th>\n",
       "      <th>user_uuid</th>\n",
       "      <th>error</th>\n",
       "      <th>disabled</th>\n",
       "      <th>ready</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a67d7ceb-b5f3-4cfd-bc08-043442cc8973</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>s3</td>\n",
       "      <td>s3://test-airt-service/ecommerce_behavior_note...</td>\n",
       "      <td>eu-west-3</td>\n",
       "      <td>aws</td>\n",
       "      <td>latest</td>\n",
       "      <td>2023-02-23T09:50:51</td>\n",
       "      <td>10191763</td>\n",
       "      <td>d78ee2d4-9135-4dcd-8e96-21e127ba32c6</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          datablob_uuid datasource_uuids type  \\\n",
       "0  a67d7ceb-b5f3-4cfd-bc08-043442cc8973           <none>   s3   \n",
       "\n",
       "                                              source     region  \\\n",
       "0  s3://test-airt-service/ecommerce_behavior_note...  eu-west-3   \n",
       "\n",
       "  cloud_provider    tags            pulled_on  folder_size  \\\n",
       "0            aws  latest  2023-02-23T09:50:51     10191763   \n",
       "\n",
       "                              user_uuid error  disabled  ready  \n",
       "0  d78ee2d4-9135-4dcd-8e96-21e127ba32c6  None     False   True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:40<00:00, 40.59s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"df['tags'].item()='latest'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datablob_uuid</th>\n",
       "      <th>datasource_uuids</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "      <th>region</th>\n",
       "      <th>cloud_provider</th>\n",
       "      <th>tags</th>\n",
       "      <th>pulled_on</th>\n",
       "      <th>folder_size</th>\n",
       "      <th>user_uuid</th>\n",
       "      <th>error</th>\n",
       "      <th>disabled</th>\n",
       "      <th>ready</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28d97722-fbdc-4c8b-a6c4-65672407bce9</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>s3</td>\n",
       "      <td>s3://test-airt-service/ecommerce_behavior_note...</td>\n",
       "      <td>eu-west-1</td>\n",
       "      <td>aws</td>\n",
       "      <td>latest</td>\n",
       "      <td>2023-02-23T09:51:48</td>\n",
       "      <td>10191763</td>\n",
       "      <td>d78ee2d4-9135-4dcd-8e96-21e127ba32c6</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          datablob_uuid datasource_uuids type  \\\n",
       "0  28d97722-fbdc-4c8b-a6c4-65672407bce9           <none>   s3   \n",
       "\n",
       "                                              source     region  \\\n",
       "0  s3://test-airt-service/ecommerce_behavior_note...  eu-west-1   \n",
       "\n",
       "  cloud_provider    tags            pulled_on  folder_size  \\\n",
       "0            aws  latest  2023-02-23T09:51:48     10191763   \n",
       "\n",
       "                              user_uuid error  disabled  ready  \n",
       "0  d78ee2d4-9135-4dcd-8e96-21e127ba32c6  None     False   True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for Datablob.details\n",
    "\n",
    "for region in [None, \"eu-west-1\"]:\n",
    "    \n",
    "    with generate_db(region=region, force_create=True) as db:\n",
    "        df = db.details()\n",
    "        assert df.datablob_uuid[0] == db.uuid\n",
    "        assert len(remove_hypens_from_id(df.datablob_uuid[0])) == 32\n",
    "        assert df.shape == (1, len(DataBlob.ALL_DB_COLS) -1 ), df.shape\n",
    "\n",
    "        display(f\"{df['tags'].item()=}\")\n",
    "        display(df)\n",
    "        assert df[\"source\"][0] == TEST_S3_URI\n",
    "        if region is not None:\n",
    "            assert df[\"region\"][0] == region\n",
    "        else:\n",
    "            assert len(df[\"region\"][0]) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7395d067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [01:41<00:00, 101.39s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"db.uuid='a146f37d-44f9-4763-8cd6-f9a76414eef6'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'db.is_ready()=True'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for DataBlob.from_s3: Setting the cloud_provider to azure\n",
    "\n",
    "with generate_db(cloud_provider=\"azure\", region=\"westeurope\", force_create=True) as db:\n",
    "\n",
    "    display(f\"{db.uuid=}\")\n",
    "    assert len(remove_hypens_from_id(db.uuid)) == 32\n",
    "\n",
    "    display(f\"{db.is_ready()=}\")\n",
    "    assert db.is_ready()\n",
    "    assert db.source == TEST_S3_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1404ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"db.uuid='98d15c9f-17e1-4ba5-bae5-80ee3a5c482c'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'An error occurred (NoSuchBucket) when calling the ListObjects operation: The specified bucket does not exist'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for DataBlob.from_s3\n",
    "# Testing negative scenario. Passing invalid s3 url\n",
    "\n",
    "fake_uri = \"s3://fake-bucket-not-existing/fake-object-not-existing\"\n",
    "with DataBlob.set_default_cloud_provider(cloud_provider = \"aws\", region=\"eu-west-1\"):\n",
    "    db = DataBlob.from_s3(uri=fake_uri)\n",
    "\n",
    "display(f\"{db.uuid=}\")\n",
    "assert len(remove_hypens_from_id(db.uuid)) == 32\n",
    "assert db.source == fake_uri\n",
    "\n",
    "with pytest.raises(ValueError) as e:\n",
    "    db.progress_bar()\n",
    "    \n",
    "display(f\"{str(e.value)}\")\n",
    "\n",
    "assert \"An error occurred (NoSuchBucket) when calling the ListObjects operation\" in str(e.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50bdd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"db.uuid='a64cb073-eff9-4725-8bba-95896776eb07'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'db.is_ready()=False'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:50<00:00, 50.75s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'db.is_ready()=True'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datablob_uuid</th>\n",
       "      <th>datasource_uuids</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "      <th>region</th>\n",
       "      <th>cloud_provider</th>\n",
       "      <th>tags</th>\n",
       "      <th>pulled_on</th>\n",
       "      <th>folder_size</th>\n",
       "      <th>user_uuid</th>\n",
       "      <th>error</th>\n",
       "      <th>disabled</th>\n",
       "      <th>ready</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a64cb073-eff9-4725-8bba-95896776eb07</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>azure_blob_storage</td>\n",
       "      <td>https://testairtservice.blob.core.windows.net/...</td>\n",
       "      <td>westeurope</td>\n",
       "      <td>azure</td>\n",
       "      <td>latest</td>\n",
       "      <td>2023-02-23T09:54:40</td>\n",
       "      <td>10191763</td>\n",
       "      <td>d78ee2d4-9135-4dcd-8e96-21e127ba32c6</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          datablob_uuid datasource_uuids                type  \\\n",
       "0  a64cb073-eff9-4725-8bba-95896776eb07           <none>  azure_blob_storage   \n",
       "\n",
       "                                              source      region  \\\n",
       "0  https://testairtservice.blob.core.windows.net/...  westeurope   \n",
       "\n",
       "  cloud_provider    tags            pulled_on  folder_size  \\\n",
       "0          azure  latest  2023-02-23T09:54:40     10191763   \n",
       "\n",
       "                              user_uuid error  disabled  ready  \n",
       "0  d78ee2d4-9135-4dcd-8e96-21e127ba32c6  None     False   True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"db.uuid='290a0e04-0f66-4ffe-b51d-a9fd7cda6c25'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'db.is_ready()=False'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [01:05<00:00, 65.88s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'db.is_ready()=True'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datablob_uuid</th>\n",
       "      <th>datasource_uuids</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "      <th>region</th>\n",
       "      <th>cloud_provider</th>\n",
       "      <th>tags</th>\n",
       "      <th>pulled_on</th>\n",
       "      <th>folder_size</th>\n",
       "      <th>user_uuid</th>\n",
       "      <th>error</th>\n",
       "      <th>disabled</th>\n",
       "      <th>ready</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>290a0e04-0f66-4ffe-b51d-a9fd7cda6c25</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>azure_blob_storage</td>\n",
       "      <td>https://testairtservice.blob.core.windows.net/...</td>\n",
       "      <td>northeurope</td>\n",
       "      <td>azure</td>\n",
       "      <td>latest</td>\n",
       "      <td>2023-02-23T09:55:58</td>\n",
       "      <td>10191763</td>\n",
       "      <td>d78ee2d4-9135-4dcd-8e96-21e127ba32c6</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          datablob_uuid datasource_uuids                type  \\\n",
       "0  290a0e04-0f66-4ffe-b51d-a9fd7cda6c25           <none>  azure_blob_storage   \n",
       "\n",
       "                                              source       region  \\\n",
       "0  https://testairtservice.blob.core.windows.net/...  northeurope   \n",
       "\n",
       "  cloud_provider    tags            pulled_on  folder_size  \\\n",
       "0          azure  latest  2023-02-23T09:55:58     10191763   \n",
       "\n",
       "                              user_uuid error  disabled  ready  \n",
       "0  d78ee2d4-9135-4dcd-8e96-21e127ba32c6  None     False   True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for DataBlob.from_azure_blob_storage: Positive scenario: Passing the credential in the parameter\n",
    "\n",
    "storage_client = StorageManagementClient(\n",
    "    DefaultAzureCredential(), os.environ[\"AZURE_SUBSCRIPTION_ID\"]\n",
    ")\n",
    "keys = storage_client.storage_accounts.list_keys(\n",
    "    \"test-airt-service\", \"testairtservice\"\n",
    ")\n",
    "credential = keys.keys[0].value\n",
    "\n",
    "for region in [\"westeurope\", \"northeurope\"]:\n",
    "#     with DataBlob.set_default_azure_blob_storage_region(region):\n",
    "    with DataBlob.set_default_cloud_provider(cloud_provider=\"azure\", region=region):\n",
    "        db = DataBlob.from_azure_blob_storage(uri=TEST_AZURE_URI, credential=credential)\n",
    "\n",
    "        display(f\"{db.uuid=}\")\n",
    "        assert len(remove_hypens_from_id(db.uuid)) == 32\n",
    "\n",
    "        display(f\"{db.is_ready()=}\")\n",
    "        assert not db.is_ready()\n",
    "        db.progress_bar()\n",
    "\n",
    "        display(f\"{db.is_ready()=}\")\n",
    "        assert db.is_ready()\n",
    "        assert db.source == TEST_AZURE_URI\n",
    "        \n",
    "        df = db.details()\n",
    "        display(df)\n",
    "        assert df[\"region\"][0] == region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f323f16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"db.uuid='cfbe8a09-b93e-4e1c-bc1a-2ff02c94fbc4'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'db.is_ready()=False'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:35<00:00, 35.51s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'db.is_ready()=True'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for DataBlob.from_azure_blob_storage: Positive scenario: Setting the cloud_provider to aws\n",
    "\n",
    "\n",
    "db = DataBlob.from_azure_blob_storage(uri=TEST_AZURE_URI, credential=credential, cloud_provider=\"aws\", region=\"eu-west-1\")\n",
    "\n",
    "display(f\"{db.uuid=}\")\n",
    "assert len(remove_hypens_from_id(db.uuid)) == 32\n",
    "\n",
    "display(f\"{db.is_ready()=}\")\n",
    "assert not db.is_ready()\n",
    "db.progress_bar()\n",
    "\n",
    "display(f\"{db.is_ready()=}\")\n",
    "assert db.is_ready()\n",
    "assert db.source == TEST_AZURE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a178f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:15<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"remote_url='https://invalid_url', subclasses=[<class 'airt.remote_path.LocalPath'>, <class 'airt.remote_path.S3Path'>, <class 'airt.remote_path.AzureBlobPath'>]\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for DataBlob.from_azure_blob_storage: Negative scenario: Passing invalid url and different region\n",
    "\n",
    "invalid_url = \"https://invalid_url\"\n",
    "region = \"northeurope\"\n",
    "cloud_provider=\"azure\"\n",
    "\n",
    "db = DataBlob.from_azure_blob_storage(uri=invalid_url, credential=credential, cloud_provider=cloud_provider, region=region)\n",
    "df = db.details()\n",
    "assert df['region'][0] == region\n",
    "\n",
    "with pytest.raises(ValueError) as e:\n",
    "    db.progress_bar()\n",
    "\n",
    "display(f\"{str(e.value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7646931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:35<00:00, 35.56s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"data_blob_clickhouse.uuid='792b2cfe-a80a-4a26-89eb-471f018427b3'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for DataBlob.from_clickhouse:\n",
    "\n",
    "# Testing positive scenario.\n",
    "\n",
    "host = os.environ.get(\"CLICKHOUSE_HOST\")\n",
    "database = os.environ.get(\"CLICKHOUSE_DATABASE\")\n",
    "table = os.environ.get(\"CLICKHOUSE_EVENTS_TABLE\")\n",
    "protocol = \"native\"\n",
    "index_column = \"PersonId\"\n",
    "timestamp_column = \"OccurredTimeTicks\"\n",
    "filters = {\"AccountId\": 312571}\n",
    "\n",
    "\n",
    "region = \"eu-west-1\"\n",
    "\n",
    "# with DataBlob.set_default_s3_region(region=region):\n",
    "with DataBlob.set_default_cloud_provider(cloud_provider=\"aws\", region=region):\n",
    "    data_blob_clickhouse = DataBlob.from_clickhouse(\n",
    "        host=host,\n",
    "        database=database,\n",
    "        table=table,\n",
    "        protocol=protocol,\n",
    "        index_column=index_column,\n",
    "        timestamp_column=timestamp_column,\n",
    "        filters=filters\n",
    "    )\n",
    "\n",
    "    data_blob_clickhouse.progress_bar()\n",
    "\n",
    "display(f\"{data_blob_clickhouse.uuid=}\")\n",
    "assert len(remove_hypens_from_id(data_blob_clickhouse.uuid)) == 32\n",
    "assert data_blob_clickhouse.source == f\"clickhouse+{protocol}://{host}:0/{database}/{table}\"\n",
    "\n",
    "df = data_blob_clickhouse.details()\n",
    "assert df[\"region\"][0] == region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024c77eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"str(e.value)='Orig exception: Code: 516.\\\\nDB::Exception: fake-username: Authentication failed: password is incorrect, or there is no user with such name.. Stack trace:\\\\n\\\\n0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0xddb0df5 in /usr/bin/clickh'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for DataBlob.from_clickhouse:\n",
    "\n",
    "# Testing negative scenario. Passing wrong username and password\n",
    "\n",
    "username = \"fake-username\"\n",
    "password = \"fake-password\"\n",
    "\n",
    "\n",
    "data_blob_clickhouse = DataBlob.from_clickhouse(\n",
    "    host=host,\n",
    "    database=database,\n",
    "    table=table,\n",
    "    protocol=protocol,\n",
    "    index_column=index_column,\n",
    "    timestamp_column=timestamp_column,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    filters=filters,\n",
    ")\n",
    "\n",
    "with pytest.raises(ValueError) as e:\n",
    "    data_blob_clickhouse.progress_bar()\n",
    "\n",
    "display(f\"{str(e.value)=}\")\n",
    "assert (\n",
    "    \"Exception: fake-username: Authentication failed: password is incorrect, or there is no user with such name.\"\n",
    "    in str(e.value)\n",
    ")\n",
    "assert data_blob_clickhouse.source == f\"clickhouse+{protocol}://{host}:0/{database}/{table}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d3370e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_blob_db.is_ready()=False'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:15<00:00, 15.28s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data_blob_db.is_ready()=True'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for DataBlob.from_mysql\n",
    "# Testing positive scenario.\n",
    "\n",
    "username=os.environ[\"DB_USERNAME\"]\n",
    "password=os.environ[\"DB_PASSWORD\"]\n",
    "host=os.environ[\"DB_HOST\"]\n",
    "port=int(os.environ[\"DB_PORT\"])\n",
    "database=os.environ[\"DB_DATABASE\"]\n",
    "database_server=os.environ[\"DB_DATABASE_SERVER\"]\n",
    "table=\"test_db_pull\"\n",
    "\n",
    "# Creating a new db data source\n",
    "\n",
    "data_blob_db = DataBlob.from_mysql(\n",
    "    host=host,\n",
    "    database=database,\n",
    "    table=table,\n",
    "    port=port,\n",
    "    username=username,\n",
    "    password=password,\n",
    ")\n",
    "\n",
    "display(f\"{data_blob_db.is_ready()=}\")\n",
    "assert not data_blob_db.is_ready()\n",
    "\n",
    "data_blob_db.progress_bar()\n",
    "\n",
    "display(f\"{data_blob_db.is_ready()=}\")\n",
    "assert data_blob_db.is_ready()\n",
    "assert data_blob_db.source == f\"{database_server}://{host}:{port}/{database}/{table}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce07111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'str(e.value)=\\'(MySQLdb.OperationalError) (2005, \"Unknown MySQL server host \\\\\\'fake-host-name\\\\\\' (-3)\")\\\\n(Background on this error at: https://sqlalche.me/e/14/e3q8)\\''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for DataBlob.from_mysql:\n",
    "# Testing negative scenario. Passing wrong host values\n",
    "\n",
    "data_blob_db = DataBlob.from_mysql(host=\"fake-host-name\", database=\"fake-host-database\", table=\"fake-host-table\")\n",
    "\n",
    "with pytest.raises(ValueError) as e:\n",
    "    data_blob_db.progress_bar()\n",
    "\n",
    "display(f\"{str(e.value)=}\")\n",
    "assert \"Unknown MySQL server host 'fake-host-name'\" in str(e.value)\n",
    "assert data_blob_db.source == f\"{database_server}://fake-host-name:{port}/fake-host-database/fake-host-table\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23da352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'str(e.value)=\\'(MySQLdb.OperationalError) (1045, \"Access denied for user \\\\\\'root\\\\\\'@\\\\\\'172.23.0.6\\\\\\' (using password: NO)\")\\\\n(Background on this error at: https://sqlalche.me/e/14/e3q8)\\''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for DataBlob.from_mysql:\n",
    "\n",
    "# Checking negative scenario. The username and password not passed in params nor set in the env variables\n",
    "\n",
    "# Clearing previously set env variables\n",
    "if os.environ.get(CLIENT_DB_USERNAME):\n",
    "    del os.environ[CLIENT_DB_USERNAME]\n",
    "\n",
    "if os.environ.get(CLIENT_DB_PASSWORD):\n",
    "    del os.environ[CLIENT_DB_PASSWORD]\n",
    "\n",
    "data_blob_db = DataBlob.from_mysql(\n",
    "    host=os.environ[\"DB_HOST\"],\n",
    "    database=os.environ[\"DB_DATABASE\"],\n",
    "    table=\"test_db_pull\",\n",
    "    port=int(os.environ[\"DB_PORT\"]),\n",
    ")\n",
    "\n",
    "with pytest.raises(ValueError) as e:\n",
    "    data_blob_db.progress_bar()\n",
    "\n",
    "display(f\"{str(e.value)=}\")\n",
    "assert \"Access denied for user\" in str(e.value)\n",
    "\n",
    "# setting back the environment variable\n",
    "os.environ[CLIENT_DB_USERNAME] = os.environ[\"DB_USERNAME\"]\n",
    "os.environ[CLIENT_DB_PASSWORD] = os.environ[\"DB_PASSWORD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af2fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:15<00:00, 15.25s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"data_blob_db.uuid='5cb2a542-b368-45e8-ba24-429c6d7222ae'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for DataBlob.from_mysql:\n",
    "\n",
    "# Checking positive scenario: Storing the database username and password in the environment variables\n",
    "data_blob_db = DataBlob.from_mysql(\n",
    "    host=os.environ[\"DB_HOST\"],\n",
    "    database=os.environ[\"DB_DATABASE\"],\n",
    "    table=\"test_db_pull\",\n",
    "    port=int(os.environ[\"DB_PORT\"]),\n",
    ")\n",
    "\n",
    "\n",
    "data_blob_db.progress_bar()\n",
    "\n",
    "display(f\"{data_blob_db.uuid=}\")\n",
    "assert len(remove_hypens_from_id(data_blob_db.uuid)) == 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33099288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/_common_metadata to ../../../tmp/test_s3_download_wk0ykm9e/parquet/_common_metadata\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/_metadata to ../../../tmp/test_s3_download_wk0ykm9e/parquet/_metadata\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.10.parquet to ../../../tmp/test_s3_download_wk0ykm9e/parquet/part.10.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.0.parquet to ../../../tmp/test_s3_download_wk0ykm9e/parquet/part.0.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.11.parquet to ../../../tmp/test_s3_download_wk0ykm9e/parquet/part.11.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.13.parquet to ../../../tmp/test_s3_download_wk0ykm9e/parquet/part.13.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.12.parquet to ../../../tmp/test_s3_download_wk0ykm9e/parquet/part.12.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.14.parquet to ../../../tmp/test_s3_download_wk0ykm9e/parquet/part.14.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.17.parquet to ../../../tmp/test_s3_download_wk0ykm9e/parquet/part.17.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.1.parquet to ../../../tmp/test_s3_download_wk0ykm9e/parquet/part.1.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.16.parquet to ../../../tmp/test_s3_download_wk0ykm9e/parquet/part.16.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.15.parquet to ../../../tmp/test_s3_download_wk0ykm9e/parquet/part.15.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.4.parquet to ../../../tmp/test_s3_download_wk0ykm9e/parquet/part.4.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.19.parquet to ../../../tmp/test_s3_download_wk0ykm9e/parquet/part.19.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.3.parquet to ../../../tmp/test_s3_download_wk0ykm9e/parquet/part.3.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.18.parquet to ../../../tmp/test_s3_download_wk0ykm9e/parquet/part.18.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.5.parquet to ../../../tmp/test_s3_download_wk0ykm9e/parquet/part.5.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.8.parquet to ../../../tmp/test_s3_download_wk0ykm9e/parquet/part.8.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.2.parquet to ../../../tmp/test_s3_download_wk0ykm9e/parquet/part.2.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.9.parquet to ../../../tmp/test_s3_download_wk0ykm9e/parquet/part.9.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.7.parquet to ../../../tmp/test_s3_download_wk0ykm9e/parquet/part.7.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.6.parquet to ../../../tmp/test_s3_download_wk0ykm9e/parquet/part.6.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Path('/tmp/test_s3_download_wk0ykm9e/csv/file-15.csv'),\n",
       " Path('/tmp/test_s3_download_wk0ykm9e/csv/file-13.csv'),\n",
       " Path('/tmp/test_s3_download_wk0ykm9e/csv/file-17.csv'),\n",
       " Path('/tmp/test_s3_download_wk0ykm9e/csv/file-4.csv'),\n",
       " Path('/tmp/test_s3_download_wk0ykm9e/csv/file-19.csv'),\n",
       " Path('/tmp/test_s3_download_wk0ykm9e/csv/file-3.csv'),\n",
       " Path('/tmp/test_s3_download_wk0ykm9e/csv/file-18.csv'),\n",
       " Path('/tmp/test_s3_download_wk0ykm9e/csv/file-2.csv'),\n",
       " Path('/tmp/test_s3_download_wk0ykm9e/csv/file-11.csv'),\n",
       " Path('/tmp/test_s3_download_wk0ykm9e/csv/file-9.csv'),\n",
       " Path('/tmp/test_s3_download_wk0ykm9e/csv/file-0.csv'),\n",
       " Path('/tmp/test_s3_download_wk0ykm9e/csv/file-7.csv'),\n",
       " Path('/tmp/test_s3_download_wk0ykm9e/csv/file-5.csv'),\n",
       " Path('/tmp/test_s3_download_wk0ykm9e/csv/file-1.csv'),\n",
       " Path('/tmp/test_s3_download_wk0ykm9e/csv/file-16.csv'),\n",
       " Path('/tmp/test_s3_download_wk0ykm9e/csv/file-6.csv'),\n",
       " Path('/tmp/test_s3_download_wk0ykm9e/csv/file-8.csv'),\n",
       " Path('/tmp/test_s3_download_wk0ykm9e/csv/file-14.csv'),\n",
       " Path('/tmp/test_s3_download_wk0ykm9e/csv/file-12.csv'),\n",
       " Path('/tmp/test_s3_download_wk0ykm9e/csv/file-10.csv')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Uploading CSV files with show_progress=True:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [01:11<00:00,  3.56s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"db_local_csv.uuid='4911c647-dae1-469e-8768-a7c45c105c5c'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for DataBlob.from_local:\n",
    "\n",
    "# Testing positive scenario. Multiple file upload.\n",
    "\n",
    "# Create temp directory\n",
    "temp_dir, csv_dirpath, parquet_path = get_test_csv_path()\n",
    "\n",
    "\n",
    "display(\"Uploading CSV files with show_progress=True:\")\n",
    "db_local_csv = DataBlob.from_local(\n",
    "    path=csv_dirpath\n",
    ")\n",
    "\n",
    "display(f\"{db_local_csv.uuid=}\")\n",
    "assert len(remove_hypens_from_id(db_local_csv.uuid)) == 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa70f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nUploading Parquet files with with show_progress=False:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"db_local_parquet.uuid='096063b8-16da-453f-863f-61567b25a904'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"db_details['source'][0]='local:/tmp/test_s3_download_wk0ykm9e/parquet'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uploading Parquet files with with show_progress=False\n",
    "\n",
    "display(\"\\n\\nUploading Parquet files with with show_progress=False:\")\n",
    "db_local_parquet = DataBlob.from_local(\n",
    "    path=parquet_path,\n",
    "    show_progress=False\n",
    ")\n",
    "\n",
    "display(f\"{db_local_parquet.uuid=}\")\n",
    "assert len(remove_hypens_from_id(db_local_parquet.uuid)) == 32\n",
    "\n",
    "db_details = db_local_parquet.details()\n",
    "\n",
    "display(f\"{db_details['source'][0]=}\")\n",
    "assert db_details[\"source\"][0] == f\"local:{str(parquet_path)}\"\n",
    "assert db_details[\"region\"][0] == DEFAULT_S3_REGION\n",
    "\n",
    "# Deleting the temp directory\n",
    "# shutil.rmtree(temp_dir)\n",
    "# display(f\"{temp_dir.exists()=}\")\n",
    "# assert not temp_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b41358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Uploading CSV file with show_progress=True:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:04<00:00,  4.07s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"db_local_csv.uuid='e5a7e776-3ccf-4ae7-b21c-3af178daa251'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nUploading CSV file with with show_progress=False:\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"db_local_csv.uuid='9b69af4f-5c45-4492-9eaf-318ca768571b'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"db_local_csv_details['source'][0]='local:/tmp/test_s3_download_wk0ykm9e/csv/file-1.csv'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'temp_dir.exists()=False'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for DataBlob.from_local:\n",
    "\n",
    "# Testing positive scenario. Single file upload.\n",
    "\n",
    "# Create temp directory\n",
    "# temp_dir, csv_dirpath, parquet_path = get_test_csv_path()\n",
    "\n",
    "display(\"Uploading CSV file with show_progress=True:\")\n",
    "\n",
    "csv_file_path = csv_dirpath / \"file-1.csv\"\n",
    "db_local_csv = DataBlob.from_local(\n",
    "    path=csv_file_path\n",
    ")\n",
    "\n",
    "display(f\"{db_local_csv.uuid=}\")\n",
    "assert len(remove_hypens_from_id(db_local_csv.uuid)) == 32\n",
    "\n",
    "display(\"\\n\\nUploading CSV file with with show_progress=False:\\n\")\n",
    "db_local_csv = DataBlob.from_local(\n",
    "    path=csv_file_path,\n",
    "    show_progress=False\n",
    ")\n",
    "\n",
    "display(f\"{db_local_csv.uuid=}\")\n",
    "assert len(remove_hypens_from_id(db_local_csv.uuid)) == 32\n",
    "\n",
    "db_local_csv_details = db_local_csv.details()\n",
    "\n",
    "display(f\"{db_local_csv_details['source'][0]=}\")\n",
    "assert db_local_csv_details[\"source\"][0] == f\"local:{str(csv_file_path)}\"\n",
    "\n",
    "\n",
    "# Deleting the temp directory\n",
    "shutil.rmtree(temp_dir)\n",
    "display(f\"{temp_dir.exists()=}\")\n",
    "assert not temp_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d14837e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'len(dbx)=25'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'len(dbx)=3'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'len(dbx)=0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for DataBlob.ls:\n",
    "# Tests for the offset and limit parameters\n",
    "\n",
    "dbx = DataBlob.ls()\n",
    "\n",
    "display(f\"{len(dbx)=}\")\n",
    "assert len(dbx) >= 0\n",
    "\n",
    "# Testing list with offset and limit\n",
    "offset = 1\n",
    "limit = 3\n",
    "\n",
    "dbx = DataBlob.ls(offset=offset, limit=limit)\n",
    "\n",
    "display(f\"{len(dbx)=}\")\n",
    "assert 0 <= len(dbx) <= limit\n",
    "\n",
    "# Testing list with invalid offset and limit\n",
    "offset = 1_000_000_000\n",
    "limit = 3\n",
    "\n",
    "dbx = DataBlob.ls(offset=offset, limit=limit)\n",
    "\n",
    "display(f\"{len(dbx)=}\")\n",
    "assert dbx == []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361c2af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"db_id_list=['e73f421b-3a91-4a6b-a269-444a3c7d1c90', '92c9bcb5-8681-4c4d-a9d8-9317ffbaef08', '56cb3306-27e3-4604-b4b0-59216fe996b3', '0cc90f14-b0bd-4976-a090-48b4996b74d4', 'cd976ec5-54b7-4462-ad00-b9517ccc6b67', '0fe1ff4c-f176-4965-9b38-1650b0ae850b', 'a67d7ceb-b5f3-4cfd-bc08-043442cc8973', '28d97722-fbdc-4c8b-a6c4-65672407bce9', 'a146f37d-44f9-4763-8cd6-f9a76414eef6', '98d15c9f-17e1-4ba5-bae5-80ee3a5c482c', 'a64cb073-eff9-4725-8bba-95896776eb07', '290a0e04-0f66-4ffe-b51d-a9fd7cda6c25', 'cfbe8a09-b93e-4e1c-bc1a-2ff02c94fbc4', 'c4c969e4-3e27-4375-b6c4-1ff536354d9b', '792b2cfe-a80a-4a26-89eb-471f018427b3', '3e2d89f8-88e3-40cd-a4a6-e589c116377b', '0f1ecfc4-85ed-409d-b027-1bd211c2cced', '3a928206-0868-4ae8-aa22-80f2301313d2', '35955244-47bb-434d-9afd-0271b78e30e8', '863e53bf-5f1c-431b-8ffc-eb0c2b2e8d2a', '5cb2a542-b368-45e8-ba24-429c6d7222ae', '4911c647-dae1-469e-8768-a7c45c105c5c', '096063b8-16da-453f-863f-61567b25a904', 'e5a7e776-3ccf-4ae7-b21c-3af178daa251', '9b69af4f-5c45-4492-9eaf-318ca768571b', '173c5812-e3b5-4fd2-9537-13a2d0bca23c']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"db_id_list=['e73f421b-3a91-4a6b-a269-444a3c7d1c90', '92c9bcb5-8681-4c4d-a9d8-9317ffbaef08', '56cb3306-27e3-4604-b4b0-59216fe996b3', '0cc90f14-b0bd-4976-a090-48b4996b74d4', 'cd976ec5-54b7-4462-ad00-b9517ccc6b67', 'a67d7ceb-b5f3-4cfd-bc08-043442cc8973', '28d97722-fbdc-4c8b-a6c4-65672407bce9', 'a146f37d-44f9-4763-8cd6-f9a76414eef6', 'a64cb073-eff9-4725-8bba-95896776eb07', '290a0e04-0f66-4ffe-b51d-a9fd7cda6c25', 'cfbe8a09-b93e-4e1c-bc1a-2ff02c94fbc4', '792b2cfe-a80a-4a26-89eb-471f018427b3', '3a928206-0868-4ae8-aa22-80f2301313d2', '5cb2a542-b368-45e8-ba24-429c6d7222ae']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for DataBlob.ls:\n",
    "# Tests for the completed parameter\n",
    "\n",
    "# Create a datablob\n",
    "db = DataBlob.from_s3(\n",
    "    uri=TEST_S3_URI,\n",
    ")\n",
    "\n",
    "# Passing completed=False. Should show all the datablobs.\n",
    "dbx = DataBlob.ls(completed=False, limit=5000)\n",
    "db_id_list = [db.uuid for db in dbx]\n",
    "\n",
    "display(f\"{db_id_list=}\")\n",
    "assert db.uuid in db_id_list\n",
    "\n",
    "# Passing completed=True. Should show only the pulled datablobs.\n",
    "dbx = DataBlob.ls(completed=True, limit=5000)\n",
    "\n",
    "db_id_list = [db.uuid for db in dbx]\n",
    "display(f\"{db_id_list=}\")\n",
    "assert db.uuid not in db_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd4c507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datablob_uuid</th>\n",
       "      <th>datasource_uuids</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "      <th>region</th>\n",
       "      <th>cloud_provider</th>\n",
       "      <th>tags</th>\n",
       "      <th>pulled_on</th>\n",
       "      <th>folder_size</th>\n",
       "      <th>ready</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92c9bcb5-8681-4c4d-a9d8-9317ffbaef08</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>s3</td>\n",
       "      <td>s3://test-airt-service/ecommerce_behavior_note...</td>\n",
       "      <td>eu-west-3</td>\n",
       "      <td>aws</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>2023-02-23T09:46:27</td>\n",
       "      <td>10191763.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a67d7ceb-b5f3-4cfd-bc08-043442cc8973</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>s3</td>\n",
       "      <td>s3://test-airt-service/ecommerce_behavior_note...</td>\n",
       "      <td>eu-west-3</td>\n",
       "      <td>aws</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>2023-02-23T09:50:51</td>\n",
       "      <td>10191763.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28d97722-fbdc-4c8b-a6c4-65672407bce9</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>s3</td>\n",
       "      <td>s3://test-airt-service/ecommerce_behavior_note...</td>\n",
       "      <td>eu-west-1</td>\n",
       "      <td>aws</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>2023-02-23T09:51:48</td>\n",
       "      <td>10191763.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a146f37d-44f9-4763-8cd6-f9a76414eef6</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>s3</td>\n",
       "      <td>s3://test-airt-service/ecommerce_behavior_note...</td>\n",
       "      <td>westeurope</td>\n",
       "      <td>azure</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>2023-02-23T09:53:17</td>\n",
       "      <td>10191763.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>98d15c9f-17e1-4ba5-bae5-80ee3a5c482c</td>\n",
       "      <td>&lt;none&gt;</td>\n",
       "      <td>s3</td>\n",
       "      <td>s3://fake-bucket-not-existing/fake-object-not-...</td>\n",
       "      <td>eu-west-1</td>\n",
       "      <td>aws</td>\n",
       "      <td>latest</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          datablob_uuid datasource_uuids type  \\\n",
       "1  92c9bcb5-8681-4c4d-a9d8-9317ffbaef08           <none>   s3   \n",
       "6  a67d7ceb-b5f3-4cfd-bc08-043442cc8973           <none>   s3   \n",
       "7  28d97722-fbdc-4c8b-a6c4-65672407bce9           <none>   s3   \n",
       "8  a146f37d-44f9-4763-8cd6-f9a76414eef6           <none>   s3   \n",
       "9  98d15c9f-17e1-4ba5-bae5-80ee3a5c482c           <none>   s3   \n",
       "\n",
       "                                              source      region  \\\n",
       "1  s3://test-airt-service/ecommerce_behavior_note...   eu-west-3   \n",
       "6  s3://test-airt-service/ecommerce_behavior_note...   eu-west-3   \n",
       "7  s3://test-airt-service/ecommerce_behavior_note...   eu-west-1   \n",
       "8  s3://test-airt-service/ecommerce_behavior_note...  westeurope   \n",
       "9  s3://fake-bucket-not-existing/fake-object-not-...   eu-west-1   \n",
       "\n",
       "  cloud_provider    tags            pulled_on  folder_size  ready  \n",
       "1            aws  <none>  2023-02-23T09:46:27   10191763.0   True  \n",
       "6            aws  <none>  2023-02-23T09:50:51   10191763.0   True  \n",
       "7            aws  <none>  2023-02-23T09:51:48   10191763.0   True  \n",
       "8          azure  <none>  2023-02-23T09:53:17   10191763.0   True  \n",
       "9            aws  latest                 None          NaN  False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tests for DataBlob.as_df:\n",
    "\n",
    "dbx = DataBlob.ls()\n",
    "\n",
    "df = DataBlob.as_df(dbx)\n",
    "\n",
    "for c in [\"datasource_uuids\", \"datablob_uuid\", \"source\"]:\n",
    "    assert c in list(df.columns)\n",
    "\n",
    "\n",
    "assert df.shape == (len(dbx), len(DataBlob.BASIC_DB_COLS) - 1)\n",
    "assert \"<none>\" in df[\"datasource_uuids\"].to_list()\n",
    "\n",
    "df[df.type == \"s3\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bacc0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datablob_uuid</th>\n",
       "      <th>datasource_uuids</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "      <th>region</th>\n",
       "      <th>cloud_provider</th>\n",
       "      <th>tags</th>\n",
       "      <th>pulled_on</th>\n",
       "      <th>folder_size</th>\n",
       "      <th>ready</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [datablob_uuid, datasource_uuids, type, source, region, cloud_provider, tags, pulled_on, folder_size, ready]\n",
       "Index: []"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tests for DataBlob.as_df:\n",
    "# Testing with empty response\n",
    "\n",
    "dbx = []\n",
    "\n",
    "df = DataBlob.as_df(dbx)\n",
    "\n",
    "for c in [\"datasource_uuids\", \"datablob_uuid\"]:\n",
    "    assert c in list(df.columns)\n",
    "\n",
    "assert df.shape == (len(dbx), len(DataBlob.BASIC_DB_COLS) - 1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "@patch\n",
    "def to_datasource(\n",
    "    self: DataBlob,\n",
    "    *,\n",
    "    file_type:str,\n",
    "    index_column: str,\n",
    "    sort_by: Union[str, List[str]],\n",
    "    deduplicate_data: bool = False,\n",
    "    blocksize: str = \"256MB\",\n",
    "    **kwargs,\n",
    ") -> DataSource:\n",
    "    \"\"\"Process the datablob and return a datasource object.\n",
    "\n",
    "    Args:\n",
    "        file_type: The file type of the datablob. Currently, the API only supports **\"csv\"** and **\"parquet\"** as file types.\n",
    "        index_column: The column to use as index (row labels).\n",
    "        sort_by: The column(s) to sort the data. Can either be a string or a list of strings.\n",
    "        deduplicate_data: If set to **True** (default value **False**), the datasource will be created with duplicate rows removed.\n",
    "        blocksize: The number of bytes used to split larger files. If None, then the default value **256MB** will be used.\n",
    "        kwargs: Additional keyword arguments to use while processing the data.e.g: To skip 100 lines from the bottom of file, \n",
    "            pass **{\"skipfooter\": 100}\n",
    "\n",
    "    Returns:\n",
    "        An instance of the `DataSource` class.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the CSV file processing fails.\n",
    "        ConnectionError: If the server address is invalid or not reachable.\n",
    "    \"\"\"\n",
    "    json_req = dict(\n",
    "        file_type=file_type,\n",
    "        deduplicate_data=deduplicate_data,\n",
    "        index_column=index_column,\n",
    "        sort_by=sort_by,\n",
    "        blocksize=blocksize,\n",
    "        kwargs=kwargs,\n",
    "    )\n",
    "    response = Client._post_data(\n",
    "        relative_url=f\"/datablob/{self.uuid}/to_datasource\", json=json_req\n",
    "    )\n",
    "\n",
    "    return DataSource(uuid=response[\"uuid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92b634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "add_example_to_docs(DataBlob.to_datasource, _docstring_example.__doc__) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f27b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ds.uuid='8218dde1-b39b-4dba-8f57-fc826e57573f'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:55<00:00, 55.80s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'len(ds.head())=10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"ds.dtypes['event_time'][0]='datetime64[ns, UTC]'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for DataBlob.to_datasource:\n",
    "# Positive case: Uploading a from from s3\n",
    "\n",
    "with generate_db() as db:\n",
    "    # Creating ds with kwargs\n",
    "    ds = db.to_datasource(\n",
    "        file_type=\"parquet\",\n",
    "        index_column=\"user_id\",\n",
    "        sort_by=\"event_time\",\n",
    "        **{\"parse_dates\": [\"event_time\"], \"skipfooter\": 100}\n",
    "    )\n",
    "\n",
    "    display(f\"{ds.uuid=}\")\n",
    "    assert len (ds.uuid.replace('-', '')) == 32\n",
    "\n",
    "    ds.progress_bar()\n",
    "\n",
    "    display(f\"{len(ds.head())=}\")\n",
    "    assert len(ds.head()) == 10\n",
    "\n",
    "    display(f\"{ds.dtypes['event_time'][0]=}\")\n",
    "    assert ds.dtypes[\"event_time\"][0] == 'datetime64[ns, UTC]', ds.dtypes[\"event_time\"][0]\n",
    "\n",
    "    ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ac4878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/_common_metadata to ../../../tmp/test_s3_download_w9woyb82/parquet/_common_metadata\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/_metadata to ../../../tmp/test_s3_download_w9woyb82/parquet/_metadata\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.0.parquet to ../../../tmp/test_s3_download_w9woyb82/parquet/part.0.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.14.parquet to ../../../tmp/test_s3_download_w9woyb82/parquet/part.14.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.10.parquet to ../../../tmp/test_s3_download_w9woyb82/parquet/part.10.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.11.parquet to ../../../tmp/test_s3_download_w9woyb82/parquet/part.11.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.12.parquet to ../../../tmp/test_s3_download_w9woyb82/parquet/part.12.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.1.parquet to ../../../tmp/test_s3_download_w9woyb82/parquet/part.1.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.15.parquet to ../../../tmp/test_s3_download_w9woyb82/parquet/part.15.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.13.parquet to ../../../tmp/test_s3_download_w9woyb82/parquet/part.13.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.17.parquet to ../../../tmp/test_s3_download_w9woyb82/parquet/part.17.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.16.parquet to ../../../tmp/test_s3_download_w9woyb82/parquet/part.16.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.18.parquet to ../../../tmp/test_s3_download_w9woyb82/parquet/part.18.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.7.parquet to ../../../tmp/test_s3_download_w9woyb82/parquet/part.7.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.3.parquet to ../../../tmp/test_s3_download_w9woyb82/parquet/part.3.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.19.parquet to ../../../tmp/test_s3_download_w9woyb82/parquet/part.19.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.2.parquet to ../../../tmp/test_s3_download_w9woyb82/parquet/part.2.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.4.parquet to ../../../tmp/test_s3_download_w9woyb82/parquet/part.4.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.5.parquet to ../../../tmp/test_s3_download_w9woyb82/parquet/part.5.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.6.parquet to ../../../tmp/test_s3_download_w9woyb82/parquet/part.6.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.8.parquet to ../../../tmp/test_s3_download_w9woyb82/parquet/part.8.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.9.parquet to ../../../tmp/test_s3_download_w9woyb82/parquet/part.9.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Path('/tmp/test_s3_download_w9woyb82/csv/file-15.csv'),\n",
       " Path('/tmp/test_s3_download_w9woyb82/csv/file-13.csv'),\n",
       " Path('/tmp/test_s3_download_w9woyb82/csv/file-17.csv'),\n",
       " Path('/tmp/test_s3_download_w9woyb82/csv/file-4.csv'),\n",
       " Path('/tmp/test_s3_download_w9woyb82/csv/file-19.csv'),\n",
       " Path('/tmp/test_s3_download_w9woyb82/csv/file-3.csv'),\n",
       " Path('/tmp/test_s3_download_w9woyb82/csv/file-18.csv'),\n",
       " Path('/tmp/test_s3_download_w9woyb82/csv/file-2.csv'),\n",
       " Path('/tmp/test_s3_download_w9woyb82/csv/file-11.csv'),\n",
       " Path('/tmp/test_s3_download_w9woyb82/csv/file-9.csv'),\n",
       " Path('/tmp/test_s3_download_w9woyb82/csv/file-0.csv'),\n",
       " Path('/tmp/test_s3_download_w9woyb82/csv/file-7.csv'),\n",
       " Path('/tmp/test_s3_download_w9woyb82/csv/file-5.csv'),\n",
       " Path('/tmp/test_s3_download_w9woyb82/csv/file-1.csv'),\n",
       " Path('/tmp/test_s3_download_w9woyb82/csv/file-16.csv'),\n",
       " Path('/tmp/test_s3_download_w9woyb82/csv/file-6.csv'),\n",
       " Path('/tmp/test_s3_download_w9woyb82/csv/file-8.csv'),\n",
       " Path('/tmp/test_s3_download_w9woyb82/csv/file-14.csv'),\n",
       " Path('/tmp/test_s3_download_w9woyb82/csv/file-12.csv'),\n",
       " Path('/tmp/test_s3_download_w9woyb82/csv/file-10.csv')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:03<00:00,  3.25s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"db_local_csv.uuid='88c66045-05d8-46f1-8885-183e7395aa9a'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'db_local_csv.is_ready()=True'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"ds.uuid='a979066a-edbc-402d-99ca-df01b3cc3fcf'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:30<00:00, 30.46s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'len(ds.head())=10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_code</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>user_session</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>447889667</th>\n",
       "      <td>2019-11-06 06:54:15+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>1306569</td>\n",
       "      <td>2053013558920217191</td>\n",
       "      <td>computers.notebook</td>\n",
       "      <td>acer</td>\n",
       "      <td>1029.60</td>\n",
       "      <td>219e1ee2-dc29-40fe-84e5-386309f11d82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490599351</th>\n",
       "      <td>2019-11-06 00:42:06+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>1305808</td>\n",
       "      <td>2053013558920217191</td>\n",
       "      <td>computers.notebook</td>\n",
       "      <td>hp</td>\n",
       "      <td>869.78</td>\n",
       "      <td>3ec0eb00-1072-4ce1-b221-94d9ffe25072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497403461</th>\n",
       "      <td>2019-11-06 05:37:02+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>1307310</td>\n",
       "      <td>2053013558920217191</td>\n",
       "      <td>computers.notebook</td>\n",
       "      <td>acer</td>\n",
       "      <td>283.07</td>\n",
       "      <td>e53c264b-db03-4e0f-b7ca-9f2f893f32c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497403461</th>\n",
       "      <td>2019-11-06 05:38:47+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>1307310</td>\n",
       "      <td>2053013558920217191</td>\n",
       "      <td>computers.notebook</td>\n",
       "      <td>acer</td>\n",
       "      <td>283.07</td>\n",
       "      <td>e53c264b-db03-4e0f-b7ca-9f2f893f32c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499359460</th>\n",
       "      <td>2019-11-06 01:36:08+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>1307076</td>\n",
       "      <td>2053013558920217191</td>\n",
       "      <td>computers.notebook</td>\n",
       "      <td>asus</td>\n",
       "      <td>669.23</td>\n",
       "      <td>28cfd249-10d7-4ca4-8d59-77d4f5bfec8c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500383663</th>\n",
       "      <td>2019-11-05 20:33:53+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>1307004</td>\n",
       "      <td>2053013558920217191</td>\n",
       "      <td>computers.notebook</td>\n",
       "      <td>lenovo</td>\n",
       "      <td>290.60</td>\n",
       "      <td>fb1c58ec-3ded-453e-b90a-9aff884f2653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501884298</th>\n",
       "      <td>2019-11-06 06:13:47+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>1300742</td>\n",
       "      <td>2053013558920217191</td>\n",
       "      <td>computers.notebook</td>\n",
       "      <td>apple</td>\n",
       "      <td>2181.22</td>\n",
       "      <td>7ec67179-bd15-4c55-8c6d-8f643ffe5bc4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501884298</th>\n",
       "      <td>2019-11-06 06:14:35+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>1306315</td>\n",
       "      <td>2053013558920217191</td>\n",
       "      <td>computers.notebook</td>\n",
       "      <td>apple</td>\n",
       "      <td>1492.70</td>\n",
       "      <td>7ec67179-bd15-4c55-8c6d-8f643ffe5bc4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501884298</th>\n",
       "      <td>2019-11-06 06:14:47+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>1306198</td>\n",
       "      <td>2053013558920217191</td>\n",
       "      <td>computers.notebook</td>\n",
       "      <td>apple</td>\n",
       "      <td>1783.55</td>\n",
       "      <td>7ec67179-bd15-4c55-8c6d-8f643ffe5bc4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501884298</th>\n",
       "      <td>2019-11-06 06:15:34+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>1304409</td>\n",
       "      <td>2053013558920217191</td>\n",
       "      <td>computers.notebook</td>\n",
       "      <td>apple</td>\n",
       "      <td>1402.87</td>\n",
       "      <td>7ec67179-bd15-4c55-8c6d-8f643ffe5bc4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          event_time event_type  product_id  \\\n",
       "user_id                                                       \n",
       "447889667  2019-11-06 06:54:15+00:00       view     1306569   \n",
       "490599351  2019-11-06 00:42:06+00:00       view     1305808   \n",
       "497403461  2019-11-06 05:37:02+00:00       view     1307310   \n",
       "497403461  2019-11-06 05:38:47+00:00       view     1307310   \n",
       "499359460  2019-11-06 01:36:08+00:00       view     1307076   \n",
       "500383663  2019-11-05 20:33:53+00:00       view     1307004   \n",
       "501884298  2019-11-06 06:13:47+00:00       view     1300742   \n",
       "501884298  2019-11-06 06:14:35+00:00       view     1306315   \n",
       "501884298  2019-11-06 06:14:47+00:00       view     1306198   \n",
       "501884298  2019-11-06 06:15:34+00:00       view     1304409   \n",
       "\n",
       "                   category_id       category_code   brand    price  \\\n",
       "user_id                                                               \n",
       "447889667  2053013558920217191  computers.notebook    acer  1029.60   \n",
       "490599351  2053013558920217191  computers.notebook      hp   869.78   \n",
       "497403461  2053013558920217191  computers.notebook    acer   283.07   \n",
       "497403461  2053013558920217191  computers.notebook    acer   283.07   \n",
       "499359460  2053013558920217191  computers.notebook    asus   669.23   \n",
       "500383663  2053013558920217191  computers.notebook  lenovo   290.60   \n",
       "501884298  2053013558920217191  computers.notebook   apple  2181.22   \n",
       "501884298  2053013558920217191  computers.notebook   apple  1492.70   \n",
       "501884298  2053013558920217191  computers.notebook   apple  1783.55   \n",
       "501884298  2053013558920217191  computers.notebook   apple  1402.87   \n",
       "\n",
       "                                   user_session  \n",
       "user_id                                          \n",
       "447889667  219e1ee2-dc29-40fe-84e5-386309f11d82  \n",
       "490599351  3ec0eb00-1072-4ce1-b221-94d9ffe25072  \n",
       "497403461  e53c264b-db03-4e0f-b7ca-9f2f893f32c4  \n",
       "497403461  e53c264b-db03-4e0f-b7ca-9f2f893f32c4  \n",
       "499359460  28cfd249-10d7-4ca4-8d59-77d4f5bfec8c  \n",
       "500383663  fb1c58ec-3ded-453e-b90a-9aff884f2653  \n",
       "501884298  7ec67179-bd15-4c55-8c6d-8f643ffe5bc4  \n",
       "501884298  7ec67179-bd15-4c55-8c6d-8f643ffe5bc4  \n",
       "501884298  7ec67179-bd15-4c55-8c6d-8f643ffe5bc4  \n",
       "501884298  7ec67179-bd15-4c55-8c6d-8f643ffe5bc4  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tests for DataBlob.to_datasource:\n",
    "# Positive case: Uploading a single csv file from local\n",
    "\n",
    "# Downloading the sample \n",
    "temp_dir, csv_dirpath, paruqet_dirpath = get_test_csv_path()\n",
    "\n",
    "db_local_csv = DataBlob.from_local(\n",
    "    path=csv_dirpath / \"file-1.csv\"\n",
    ")\n",
    "\n",
    "display(f\"{db_local_csv.uuid=}\")\n",
    "assert len(remove_hypens_from_id(db_local_csv.uuid)) == 32\n",
    "\n",
    "display(f\"{db_local_csv.is_ready()=}\")\n",
    "assert db_local_csv.is_ready()\n",
    "db_local_csv.progress_bar()\n",
    "\n",
    "ds = db_local_csv.to_datasource(\n",
    "    file_type=\"csv\",\n",
    "    index_column=\"user_id\",\n",
    "    sort_by=\"event_time\",\n",
    ")\n",
    "\n",
    "display(f\"{ds.uuid=}\")\n",
    "assert len (ds.uuid.replace('-', '')) == 32\n",
    "\n",
    "ds.progress_bar()\n",
    "\n",
    "display(f\"{len(ds.head())=}\")\n",
    "assert len(ds.head()) == 10\n",
    "\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca999994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "@patch\n",
    "def tag(self: DataBlob, name: str) -> pd.DataFrame:\n",
    "    \"\"\"Tag an existing datablob in the server.\n",
    "\n",
    "    Args:\n",
    "        name: A string to tag the datablob.\n",
    "\n",
    "    Returns:\n",
    "        A pandas dataframe with the details of the tagged datablob.\n",
    "\n",
    "    Raises:\n",
    "        ConnectionError: If the server address is invalid or not reachable.\n",
    "    \"\"\"\n",
    "    response = Client._post_data(\n",
    "        relative_url=f\"/datablob/{self.uuid}/tag\", json=dict(name=name)\n",
    "    )\n",
    "    \n",
    "    response = DataBlob._get_tag_name_and_datasource_id(response)\n",
    "\n",
    "    df = pd.DataFrame([response])[DataBlob.BASIC_DB_COLS]\n",
    "\n",
    "    df = df.rename(columns=DataBlob.COLS_TO_RENAME)\n",
    "    \n",
    "    return add_ready_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52f8420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "add_example_to_docs(DataBlob.tag, _docstring_example.__doc__) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd24c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datablob_uuid</th>\n",
       "      <th>datasource_uuids</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "      <th>region</th>\n",
       "      <th>cloud_provider</th>\n",
       "      <th>tags</th>\n",
       "      <th>pulled_on</th>\n",
       "      <th>folder_size</th>\n",
       "      <th>ready</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a146f37d-44f9-4763-8cd6-f9a76414eef6</td>\n",
       "      <td>8218dde1-b39b-4dba-8f57-fc826e57573f</td>\n",
       "      <td>s3</td>\n",
       "      <td>s3://test-airt-service/ecommerce_behavior_note...</td>\n",
       "      <td>westeurope</td>\n",
       "      <td>azure</td>\n",
       "      <td>v1.1.0</td>\n",
       "      <td>2023-02-23T09:53:17</td>\n",
       "      <td>10191763</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          datablob_uuid                      datasource_uuids  \\\n",
       "0  a146f37d-44f9-4763-8cd6-f9a76414eef6  8218dde1-b39b-4dba-8f57-fc826e57573f   \n",
       "\n",
       "  type                                             source      region  \\\n",
       "0   s3  s3://test-airt-service/ecommerce_behavior_note...  westeurope   \n",
       "\n",
       "  cloud_provider    tags            pulled_on  folder_size  ready  \n",
       "0          azure  v1.1.0  2023-02-23T09:53:17     10191763   True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for DataBlob.tag\n",
    "\n",
    "with generate_db() as db:\n",
    "\n",
    "    # getting the details of the data source\n",
    "    df = db.tag(name=\"v1.1.0\")\n",
    "\n",
    "    display(df)\n",
    "    assert 'v1.1.0' in df.tags[0], df.tags[0]\n",
    "    assert df[\"source\"][0] == TEST_S3_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaec660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "@patch\n",
    "def delete(self: DataBlob) -> pd.DataFrame:\n",
    "    \"\"\"Delete a datablob from the server.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame encapsulating the details of the deleted datablob.\n",
    "\n",
    "    Raises:\n",
    "        ConnectionError: If the server address is invalid or not reachable.\n",
    "    \"\"\"\n",
    "\n",
    "    response = Client._delete_data(relative_url=f\"/datablob/{self.uuid}\")\n",
    "    \n",
    "    response = DataBlob._get_tag_name_and_datasource_id(response)\n",
    "\n",
    "    df = pd.DataFrame([response])[DataBlob.BASIC_DB_COLS]\n",
    "    \n",
    "    df = df.rename(columns=DataBlob.COLS_TO_RENAME)\n",
    "\n",
    "    return add_ready_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "add_example_to_docs(DataBlob.delete, _docstring_example.__doc__) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8638425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datablob_uuid</th>\n",
       "      <th>datasource_uuids</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "      <th>region</th>\n",
       "      <th>cloud_provider</th>\n",
       "      <th>tags</th>\n",
       "      <th>pulled_on</th>\n",
       "      <th>folder_size</th>\n",
       "      <th>ready</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a146f37d-44f9-4763-8cd6-f9a76414eef6</td>\n",
       "      <td>8218dde1-b39b-4dba-8f57-fc826e57573f</td>\n",
       "      <td>s3</td>\n",
       "      <td>s3://test-airt-service/ecommerce_behavior_note...</td>\n",
       "      <td>westeurope</td>\n",
       "      <td>azure</td>\n",
       "      <td>v1.1.0</td>\n",
       "      <td>2023-02-23T09:53:17</td>\n",
       "      <td>10191763</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          datablob_uuid                      datasource_uuids  \\\n",
       "0  a146f37d-44f9-4763-8cd6-f9a76414eef6  8218dde1-b39b-4dba-8f57-fc826e57573f   \n",
       "\n",
       "  type                                             source      region  \\\n",
       "0   s3  s3://test-airt-service/ecommerce_behavior_note...  westeurope   \n",
       "\n",
       "  cloud_provider    tags            pulled_on  folder_size  ready  \n",
       "0          azure  v1.1.0  2023-02-23T09:53:17     10191763   True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"db_id_list=['e73f421b-3a91-4a6b-a269-444a3c7d1c90', '92c9bcb5-8681-4c4d-a9d8-9317ffbaef08', '56cb3306-27e3-4604-b4b0-59216fe996b3', '0cc90f14-b0bd-4976-a090-48b4996b74d4', 'cd976ec5-54b7-4462-ad00-b9517ccc6b67', '0fe1ff4c-f176-4965-9b38-1650b0ae850b', 'a67d7ceb-b5f3-4cfd-bc08-043442cc8973', '28d97722-fbdc-4c8b-a6c4-65672407bce9', '98d15c9f-17e1-4ba5-bae5-80ee3a5c482c', 'a64cb073-eff9-4725-8bba-95896776eb07', '290a0e04-0f66-4ffe-b51d-a9fd7cda6c25', 'cfbe8a09-b93e-4e1c-bc1a-2ff02c94fbc4', 'c4c969e4-3e27-4375-b6c4-1ff536354d9b', '792b2cfe-a80a-4a26-89eb-471f018427b3', '3e2d89f8-88e3-40cd-a4a6-e589c116377b', '0f1ecfc4-85ed-409d-b027-1bd211c2cced', '3a928206-0868-4ae8-aa22-80f2301313d2', '35955244-47bb-434d-9afd-0271b78e30e8', '863e53bf-5f1c-431b-8ffc-eb0c2b2e8d2a', '5cb2a542-b368-45e8-ba24-429c6d7222ae', '4911c647-dae1-469e-8768-a7c45c105c5c', '096063b8-16da-453f-863f-61567b25a904', 'e5a7e776-3ccf-4ae7-b21c-3af178daa251', '9b69af4f-5c45-4492-9eaf-318ca768571b', '173c5812-e3b5-4fd2-9537-13a2d0bca23c', '88c66045-05d8-46f1-8885-183e7395aa9a']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"db_id_list=['2266a8b6-b242-4400-96e6-a3eda7157482', 'a146f37d-44f9-4763-8cd6-f9a76414eef6']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"e.value=ValueError('The datablob has already been deleted.')\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for Datablob.delete\n",
    "# Testing positive scenario\n",
    "\n",
    "with generate_db() as db:\n",
    "    df = db.delete()\n",
    "\n",
    "    display(df)\n",
    "    assert df.datablob_uuid[0] == db.uuid\n",
    "    assert df.shape == (1, len(DataBlob.BASIC_DB_COLS) - 1), df.shape\n",
    "    assert df[\"source\"][0] == TEST_S3_URI\n",
    "    \n",
    "    # Passing disabled=False. Should show only the active datablobs.\n",
    "    dbx = DataBlob.ls(disabled=False, limit=5000)\n",
    "    db_id_list = [db.uuid for db in dbx]\n",
    "\n",
    "    display(f\"{db_id_list=}\")\n",
    "    assert db.uuid not in db_id_list\n",
    "\n",
    "    # Passing disabled=True. Should show only the deleted datablobs.\n",
    "    dbx = DataBlob.ls(disabled=True, limit=5000)\n",
    "\n",
    "    db_id_list = [db.uuid for db in dbx]\n",
    "    display(f\"{db_id_list=}\")\n",
    "    assert db.uuid in db_id_list\n",
    "\n",
    "    # Testing negative scenario. Deleting already deleted datablob\n",
    "    with pytest.raises(ValueError) as e:\n",
    "        db.delete()\n",
    "\n",
    "    display(f\"{e.value=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f230162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"e.value=ValueError('The datablob uuid is incorrect. Please try again.')\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for Datablob.delete\n",
    "# Testing negative scenario. Deleting invalid datablob\n",
    "\n",
    "\n",
    "with pytest.raises(ValueError) as e:\n",
    "    db = DataBlob(uuid=RANDOM_UUID_FOR_TESTING, type=\"s3\")\n",
    "    db.delete()\n",
    "\n",
    "display(f\"{e.value=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bf4fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
