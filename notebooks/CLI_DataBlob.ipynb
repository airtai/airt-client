{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: This module encapsulates a CLI interface for all the methods available\n",
    "  in DataBlob class.\n",
    "output-file: cli_datablob.html\n",
    "title: CLI_DataBlob\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp cli.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt.testing.activate_by_import: Testing environment activated.\n"
     ]
    }
   ],
   "source": [
    "from airt.testing import activate_by_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import typer\n",
    "from typer import echo\n",
    "from tabulate import tabulate\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "from airt.client import Client\n",
    "from airt.cli import helper\n",
    "from airt.logger import get_logger, set_level\n",
    "from airt.constant import CLIENT_DB_USERNAME, CLIENT_DB_PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from urllib.parse import quote_plus as urlquote\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import logging\n",
    "import pytest\n",
    "\n",
    "from typer.testing import CliRunner\n",
    "from sqlmodel import create_engine\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.mgmt.storage import StorageManagementClient\n",
    "\n",
    "import airt.sanitizer\n",
    "from airt.constant import SERVICE_TOKEN, SERVER_URL, SERVICE_USERNAME, SERVICE_PASSWORD, CLIENT_NAME, CLIENT_DB_USERNAME, CLIENT_DB_PASSWORD\n",
    "from airt.client import DataBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "app = typer.Typer(\n",
    "    help=\"\"\"A set of commands for importing and processing data from sources such as CSV/parquet files, databases, AWS S3 buckets, and Azure Blob Storage.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = CliRunner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_level(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] __main__: This is a warning\n",
      "[ERROR] __main__: This is an error\n"
     ]
    }
   ],
   "source": [
    "# Testing logger settings\n",
    "\n",
    "display(logger.getEffectiveLevel())\n",
    "assert logger.getEffectiveLevel() == logging.WARNING\n",
    "\n",
    "logger.debug(\"This is a debug message\")\n",
    "logger.info(\"This is an info\")\n",
    "logger.warning(\"This is a warning\")\n",
    "logger.error(\"This is an error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper context manager for testing\n",
    "\n",
    "_airt_service_token = None\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def set_airt_service_token_envvar():\n",
    "    global _airt_service_token\n",
    "    if _airt_service_token is None:\n",
    "        display(\"_airt_service_token is None, getting a token...\")\n",
    "        \n",
    "        username = os.environ[SERVICE_USERNAME]\n",
    "        password = os.environ[SERVICE_PASSWORD]\n",
    "\n",
    "        Client.get_token(username=username, password=password)\n",
    "        _airt_service_token = Client.auth_token\n",
    "\n",
    "    try:\n",
    "        os.environ[SERVICE_TOKEN] = _airt_service_token\n",
    "\n",
    "        yield\n",
    "    finally:\n",
    "        del os.environ[SERVICE_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_airt_service_token is None, getting a token...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'*******************************************************************************************************************************'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with set_airt_service_token_envvar():\n",
    "    display(\"*\" * len((os.environ[SERVICE_TOKEN])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_has_help(xs: List[str]):\n",
    "    result = runner.invoke(app, xs + [\"--help\"])\n",
    "\n",
    "    display(result.stdout)\n",
    "    assert \" \".join(xs) in result.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_S3_URI = \"s3://test-airt-service/ecommerce_behavior_notebooks\"\n",
    "TEST_S3_CSV_URI = \"s3://test-airt-service/ecommerce_behavior_csv\"\n",
    "TEST_AZURE_URI = \"https://testairtservice.blob.core.windows.net/test-container/ecommerce_behavior_notebooks\"\n",
    "RANDOM_UUID_FOR_TESTING = \"00000000-0000-0000-0000-000000000000\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hypens_from_id(id:str) -> str:\n",
    "    return \"\".join((id).split(\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00000000000000000000000000000000'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = remove_hypens_from_id(RANDOM_UUID_FOR_TESTING)\n",
    "assert len(actual) == 32\n",
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to create a datablob\n",
    "\n",
    "\n",
    "_db = None\n",
    "@contextmanager\n",
    "def generate_db(force_create: bool = False):\n",
    "    global _db\n",
    "    \n",
    "    if _db is None or force_create:\n",
    "\n",
    "        _db = DataBlob.from_s3(\n",
    "            uri=TEST_S3_URI,\n",
    "            access_key=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "            secret_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "        )\n",
    "\n",
    "        display(f\"{_db.uuid=}\")\n",
    "        assert len(remove_hypens_from_id(_db.uuid)) == 32\n",
    "        \n",
    "        _db.progress_bar()\n",
    "    \n",
    "    yield _db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "\n",
    "@app.command()\n",
    "@helper.display_formated_table\n",
    "@helper.requires_auth_token\n",
    "def details(\n",
    "    uuid: str = typer.Argument(\n",
    "        ...,\n",
    "        help=\"Datablob uuid.\",\n",
    "    ),\n",
    "    format: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--format\",\n",
    "        \"-f\",\n",
    "        help=\"Format output and show only the given column(s) values.\"\n",
    "    ),\n",
    "    debug: bool = typer.Option(\n",
    "        False,\n",
    "        \"--debug\",\n",
    "        \"-d\",\n",
    "        help=\"Set logger level to DEBUG and output everything.\",\n",
    "    ),\n",
    ") -> Dict[\"str\", Union[pd.DataFrame, str]]:\n",
    "    \"\"\"Return details of a datablob.\"\"\"\n",
    "\n",
    "    from airt.client import DataBlob\n",
    "    \n",
    "    db = DataBlob(uuid=uuid)\n",
    "    df = db.details()\n",
    "    \n",
    "    df['pulled_on'] = helper.humanize_date(df['pulled_on'])\n",
    "    df['folder_size'] = helper.humanize_size(df['folder_size'])\n",
    "    \n",
    "    return {\"df\": df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Usage: details [OPTIONS] UUID\\n\\n  Return details of a datablob.\\n\\nArguments:\\n  UUID  Datablob uuid.  [required]\\n\\nOptions:\\n  -f, --format TEXT               Format output and show only the given\\n                                  column(s) values.\\n  -d, --debug                     Set logger level to DEBUG and output\\n                                  everything.\\n  --install-completion [bash|zsh|fish|powershell|pwsh]\\n                                  Install completion for the specified shell.\\n  --show-completion [bash|zsh|fish|powershell|pwsh]\\n                                  Show completion for the specified shell, to\\n                                  copy it or customize the installation.\\n  --help                          Show this message and exit.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| include: false\n",
    "\n",
    "assert_has_help([\"details\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"_db.uuid='5f4579a6-4fab-4f5e-9363-41abea96dd2e'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:20<00:00, 20.24s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'5f4579a6-4fab-4f5e-9363-41abea96dd2e\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for details\n",
    "# Testing positive scenario\n",
    "\n",
    "# Helper function to extract ID\n",
    "\n",
    "def extract_id(res) -> str:\n",
    "    r = (res.split(\"\\n\")[1]).strip()\n",
    "    return r.split(\" \")[0]\n",
    "\n",
    "with set_airt_service_token_envvar():\n",
    "    with generate_db() as db:\n",
    "        db_uuid = db.uuid\n",
    "\n",
    "        # Getting Details of the data source\n",
    "        format_str = \"{'datablob_uuid': '{}'}\"\n",
    "        result = runner.invoke(app, [db_uuid, \"--format\", format_str])\n",
    "\n",
    "        display(result.stdout)\n",
    "\n",
    "        assert result.exit_code == 0\n",
    "        assert result.stdout == f\"{db_uuid}\\n\", f\"{result.stdout=} {db_uuid=}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Error: The datablob uuid is incorrect. Please try again.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| include: false\n",
    "\n",
    "# Tests for details\n",
    "# Testing negative scenario. Passing invalid data_id\n",
    "\n",
    "with set_airt_service_token_envvar():\n",
    "\n",
    "    data_uuid = RANDOM_UUID_FOR_TESTING\n",
    "    result = runner.invoke(app, [data_uuid])\n",
    "\n",
    "    display(result.stdout)\n",
    "\n",
    "    assert result.exit_code == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "\n",
    "@app.command(\"from-s3\")\n",
    "@helper.requires_auth_token\n",
    "def from_s3(\n",
    "    uri: str = typer.Argument(\n",
    "        ..., help=\"The AWS S3 bucket uri.\"\n",
    "    ),\n",
    "    access_key: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        help=\"Access key for the S3 bucket. If **None** (default value), then the value from **AWS_ACCESS_KEY_ID** environment variable is used.\",\n",
    "    ),\n",
    "    secret_key: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        help=\"Secret key for the S3 bucket. If **None** (default value), then the value from **AWS_SECRET_ACCESS_KEY** environment variable is used.\",\n",
    "    ),\n",
    "    cloud_provider: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--cloud-provider\",\n",
    "        \"-cp\",\n",
    "        help=\"The destination cloud storage provider's name to store the datablob. Currently, the API only supports **aws** and **azure** as cloud storage providers. If **None** (default value), then **aws**  will be used as the cloud storage provider.\",\n",
    "    ),\n",
    "    region: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--region\",\n",
    "        \"-r\",\n",
    "        help=\"The destination cloud provider's region to save your datablob. If **None** (default value) then the default region will be assigned based on the cloud provider. \" \\\n",
    "            \"In the case of **aws**, the datablob's source bucket region will be used and in the case of **azure**, **westeurope** will be used. \" \\\n",
    "            \"The supported AWS regions are: ap-northeast-1, ap-northeast-2, ap-south-1, ap-southeast-1, ap-southeast-2, ca-central-1, eu-central-1, \" \\\n",
    "            \"eu-north-1, eu-west-1, eu-west-2, eu-west-3, sa-east-1, us-east-1, us-east-2, us-west-1, us-west-2. The supported Azure Blob Storage \" \\\n",
    "            \"regions are: australiacentral, australiacentral2, australiaeast, australiasoutheast, brazilsouth, canadacentral, canadaeast, centralindia, \" \\\n",
    "            \"centralus, eastasia, eastus, eastus2, francecentral, francesouth, germanynorth, germanywestcentral, japaneast, japanwest, koreacentral, koreasouth, \" \\\n",
    "            \"northcentralus, northeurope, norwayeast, norwaywest, southafricanorth, southafricawest, southcentralus, southeastasia, southindia, switzerlandnorth, \" \\\n",
    "            \"switzerlandwest, uaecentral, uaenorth, uksouth, ukwest, westcentralus, westeurope, westindia, westus, westus2.\"\n",
    "    ),\n",
    "    tag: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--tag\",\n",
    "        \"-t\",\n",
    "        help=\"A string to tag the datablob. If not passed, then the tag **latest** will be assigned to the datablob.\",\n",
    "    ),\n",
    "    quiet: bool = typer.Option(\n",
    "        False,\n",
    "        \"--quiet\",\n",
    "        \"-q\",\n",
    "        help=\"Output datablob uuid only.\",\n",
    "    ),\n",
    "    debug: bool = typer.Option(\n",
    "        False,\n",
    "        \"--debug\",\n",
    "        \"-d\",\n",
    "        help=\"Set logger level to DEBUG and output everything.\",\n",
    "    ),\n",
    "):\n",
    "    \"\"\"Create and return a datablob that encapsulates the data from an AWS S3 bucket.\"\"\"\n",
    "\n",
    "    from airt.client import DataBlob\n",
    "\n",
    "    db = DataBlob.from_s3(uri=uri, access_key=access_key, secret_key=secret_key, cloud_provider=cloud_provider, region=region, tag=tag)\n",
    "\n",
    "    if quiet:\n",
    "        db.wait()\n",
    "\n",
    "        typer.echo(f\"{db.uuid}\")\n",
    "    else:\n",
    "        typer.echo(f\"Pulling datablob uuid: {db.uuid}\")\n",
    "\n",
    "        db.progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Usage: root from-s3 [OPTIONS] URI\\n\\n  Create and return a datablob that encapsulates the data from an AWS S3 bucket.\\n\\nArguments:\\n  URI  The AWS S3 bucket uri.  [required]\\n\\nOptions:\\n  --access-key TEXT           Access key for the S3 bucket. If **None** (default\\n                              value), then the value from **AWS_ACCESS_KEY_ID**\\n                              environment variable is used.\\n  --secret-key TEXT           Secret key for the S3 bucket. If **None** (default\\n                              value), then the value from\\n                              **AWS_SECRET_ACCESS_KEY** environment variable is\\n                              used.\\n  -cp, --cloud-provider TEXT  The destination cloud storage provider's name to\\n                              store the datablob. Currently, the API only\\n                              supports **aws** and **azure** as cloud storage\\n                              providers. If **None** (default value), then\\n                              **aws**  will be used as the cloud storage\\n                              provider.\\n  -r, --region TEXT           The destination cloud provider's region to save\\n                              your datablob. If **None** (default value) then\\n                              the default region will be assigned based on the\\n                              cloud provider. In the case of **aws**, the\\n                              datablob's source bucket region will be used and\\n                              in the case of **azure**, **westeurope** will be\\n                              used. The supported AWS regions are: ap-\\n                              northeast-1, ap-northeast-2, ap-south-1, ap-\\n                              southeast-1, ap-southeast-2, ca-central-1, eu-\\n                              central-1, eu-north-1, eu-west-1, eu-west-2, eu-\\n                              west-3, sa-east-1, us-east-1, us-east-2, us-\\n                              west-1, us-west-2. The supported Azure Blob\\n                              Storage regions are: australiacentral,\\n                              australiacentral2, australiaeast,\\n                              australiasoutheast, brazilsouth, canadacentral,\\n                              canadaeast, centralindia, centralus, eastasia,\\n                              eastus, eastus2, francecentral, francesouth,\\n                              germanynorth, germanywestcentral, japaneast,\\n                              japanwest, koreacentral, koreasouth,\\n                              northcentralus, northeurope, norwayeast,\\n                              norwaywest, southafricanorth, southafricawest,\\n                              southcentralus, southeastasia, southindia,\\n                              switzerlandnorth, switzerlandwest, uaecentral,\\n                              uaenorth, uksouth, ukwest, westcentralus,\\n                              westeurope, westindia, westus, westus2.\\n  -t, --tag TEXT              A string to tag the datablob. If not passed, then\\n                              the tag **latest** will be assigned to the\\n                              datablob.\\n  -q, --quiet                 Output datablob uuid only.\\n  -d, --debug                 Set logger level to DEBUG and output everything.\\n  --help                      Show this message and exit.\\n\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| include: false\n",
    "\n",
    "assert_has_help([\"from-s3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to test multiple scenarios.\n",
    "\n",
    "\n",
    "def assert_datablob(xs: List[str]):\n",
    "\n",
    "    # Testing Negative scenario\n",
    "    # Creating datablob without token\n",
    "    \n",
    "    # Clearing previously set env variables\n",
    "    _token_flag = False\n",
    "\n",
    "    if os.environ.get(SERVICE_TOKEN):\n",
    "        _token_flag = True\n",
    "        airt_service_token = os.environ[SERVICE_TOKEN]\n",
    "        del os.environ[SERVICE_TOKEN]\n",
    "\n",
    "    result = runner.invoke(app, xs)\n",
    "    display(result.stdout)\n",
    "    assert result.exit_code == 1\n",
    "    assert f\"KeyError: The environment variable '{SERVICE_TOKEN}' is not set.\\n\\nPlease run the command '{CLIENT_NAME} token'\" in result.stdout\n",
    "    \n",
    "    if _token_flag:\n",
    "        os.environ[SERVICE_TOKEN] = airt_service_token\n",
    "\n",
    "    # Testing Positive scenario\n",
    "    # With and without quite\n",
    "\n",
    "    with set_airt_service_token_envvar():\n",
    "        # Without quiet (verbose)\n",
    "        result = runner.invoke(app, xs)\n",
    "        display(result.stdout)\n",
    "        assert \"Pulling datablob uuid:\" in result.stdout, result.stdout\n",
    "\n",
    "        # With quiet\n",
    "        display(\"*\" * 120)\n",
    "        result = runner.invoke(app, xs + [\"-q\"])\n",
    "        display(result.stdout)\n",
    "        assert len(remove_hypens_from_id(result.stdout[:-1])) == 32, len(result.stdout[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"KeyError: The environment variable 'AIRT_SERVICE_TOKEN' is not set.\\n\\nPlease run the command 'airt token' to get the application token and set it in the environment variable `AIRT_SERVICE_TOKEN`.\\n\\nTry 'airt token --help' for help.\\n\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Pulling datablob uuid: 52fe570b-ddbf-495b-93d1-97d6b65f276a\\n\\r  0%|          | 0/1 [00:00<?, ?it/s]\\r  0%|          | 0/1 [00:05<?, ?it/s]\\r  0%|          | 0/1 [00:10<?, ?it/s]\\r  0%|          | 0/1 [00:15<?, ?it/s]\\r  0%|          | 0/1 [00:20<?, ?it/s]\\r  0%|          | 0/1 [00:25<?, ?it/s]\\r  0%|          | 0/1 [00:30<?, ?it/s]\\r100%|██████████| 1/1 [00:35<00:00,  5.05s/it]\\r100%|██████████| 1/1 [00:35<00:00, 35.37s/it]\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'************************************************************************************************************************'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'5d47fdf7-ac39-48e2-84e1-ed3fb248a980\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for Datablob s3\n",
    "\n",
    "cmd = [\"from-s3\", f\"{TEST_S3_CSV_URI}\"]\n",
    "\n",
    "assert_datablob(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "\n",
    "@app.command(\"from-azure-blob-storage\")\n",
    "@helper.requires_auth_token\n",
    "def from_azure_blob_storage(\n",
    "    uri: str = typer.Argument(\n",
    "        ..., help=\"Azure Blob Storage URI of the source file.\"\n",
    "    ),\n",
    "    credential: str = typer.Option(\n",
    "        ...,\n",
    "        \"--credential\",\n",
    "        \"-c\",\n",
    "        help=\"Credential to access the Azure Blob Storage.\",\n",
    "    ),\n",
    "    cloud_provider: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--cloud-provider\",\n",
    "        \"-cp\",\n",
    "        help=\"The destination cloud storage provider's name to store the datablob. Currently, the API only supports **aws** and **azure** as cloud storage providers. If **None** (default value), then **azure**  will be used as the cloud storage provider.\",\n",
    "    ),\n",
    "    region: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--region\",\n",
    "        \"-r\",\n",
    "        help=\"The destination cloud provider's region to save your datablob. If **None** (default value) then the default region will be assigned based on the cloud provider. \" \\\n",
    "            \"In the case of **aws**, **eu-west-1** will be used and in the case of **azure**, **westeurope** will be used. \" \\\n",
    "            \"The supported AWS regions are: ap-northeast-1, ap-northeast-2, ap-south-1, ap-southeast-1, ap-southeast-2, ca-central-1, eu-central-1, \" \\\n",
    "            \"eu-north-1, eu-west-1, eu-west-2, eu-west-3, sa-east-1, us-east-1, us-east-2, us-west-1, us-west-2. The supported Azure Blob Storage \" \\\n",
    "            \"regions are: australiacentral, australiacentral2, australiaeast, australiasoutheast, brazilsouth, canadacentral, canadaeast, centralindia, \" \\\n",
    "            \"centralus, eastasia, eastus, eastus2, francecentral, francesouth, germanynorth, germanywestcentral, japaneast, japanwest, koreacentral, koreasouth, \" \\\n",
    "            \"northcentralus, northeurope, norwayeast, norwaywest, southafricanorth, southafricawest, southcentralus, southeastasia, southindia, switzerlandnorth, \" \\\n",
    "            \"switzerlandwest, uaecentral, uaenorth, uksouth, ukwest, westcentralus, westeurope, westindia, westus, westus2.\"\n",
    "    ),\n",
    "    tag: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--tag\",\n",
    "        \"-t\",\n",
    "        help=\"A string to tag the datablob. If not passed, then the tag **latest** will be assigned to the datablob.\",\n",
    "    ),\n",
    "    quiet: bool = typer.Option(\n",
    "        False,\n",
    "        \"--quiet\",\n",
    "        \"-q\",\n",
    "        help=\"Output datablob uuid only.\",\n",
    "    ),\n",
    "    debug: bool = typer.Option(\n",
    "        False,\n",
    "        \"--debug\",\n",
    "        \"-d\",\n",
    "        help=\"Set logger level to DEBUG and output everything.\",\n",
    "    ),\n",
    "):\n",
    "    \"\"\"Create and return a datablob that encapsulates the data from an Azure Blob Storage.\"\"\"\n",
    "\n",
    "    from airt.client import DataBlob\n",
    "\n",
    "    db = DataBlob.from_azure_blob_storage(uri=uri, credential=credential, cloud_provider=cloud_provider, region=region, tag=tag)\n",
    "\n",
    "    if quiet:\n",
    "        db.wait()\n",
    "\n",
    "        typer.echo(f\"{db.uuid}\")\n",
    "    else:\n",
    "        typer.echo(f\"Pulling datablob uuid: {db.uuid}\")\n",
    "\n",
    "        db.progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Usage: root from-azure-blob-storage [OPTIONS] URI\\n\\n  Create and return a datablob that encapsulates the data from an Azure Blob\\n  Storage.\\n\\nArguments:\\n  URI  Azure Blob Storage URI of the source file.  [required]\\n\\nOptions:\\n  -c, --credential TEXT       Credential to access the Azure Blob Storage.\\n                              [required]\\n  -cp, --cloud-provider TEXT  The destination cloud storage provider's name to\\n                              store the datablob. Currently, the API only\\n                              supports **aws** and **azure** as cloud storage\\n                              providers. If **None** (default value), then\\n                              **azure**  will be used as the cloud storage\\n                              provider.\\n  -r, --region TEXT           The destination cloud provider's region to save\\n                              your datablob. If **None** (default value) then\\n                              the default region will be assigned based on the\\n                              cloud provider. In the case of **aws**, **eu-\\n                              west-1** will be used and in the case of\\n                              **azure**, **westeurope** will be used. The\\n                              supported AWS regions are: ap-northeast-1, ap-\\n                              northeast-2, ap-south-1, ap-southeast-1, ap-\\n                              southeast-2, ca-central-1, eu-central-1, eu-\\n                              north-1, eu-west-1, eu-west-2, eu-west-3, sa-\\n                              east-1, us-east-1, us-east-2, us-west-1, us-\\n                              west-2. The supported Azure Blob Storage regions\\n                              are: australiacentral, australiacentral2,\\n                              australiaeast, australiasoutheast, brazilsouth,\\n                              canadacentral, canadaeast, centralindia,\\n                              centralus, eastasia, eastus, eastus2,\\n                              francecentral, francesouth, germanynorth,\\n                              germanywestcentral, japaneast, japanwest,\\n                              koreacentral, koreasouth, northcentralus,\\n                              northeurope, norwayeast, norwaywest,\\n                              southafricanorth, southafricawest, southcentralus,\\n                              southeastasia, southindia, switzerlandnorth,\\n                              switzerlandwest, uaecentral, uaenorth, uksouth,\\n                              ukwest, westcentralus, westeurope, westindia,\\n                              westus, westus2.\\n  -t, --tag TEXT              A string to tag the datablob. If not passed, then\\n                              the tag **latest** will be assigned to the\\n                              datablob.\\n  -q, --quiet                 Output datablob uuid only.\\n  -d, --debug                 Set logger level to DEBUG and output everything.\\n  --help                      Show this message and exit.\\n\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert_has_help([\"from-azure-blob-storage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"KeyError: The environment variable 'AIRT_SERVICE_TOKEN' is not set.\\n\\nPlease run the command 'airt token' to get the application token and set it in the environment variable `AIRT_SERVICE_TOKEN`.\\n\\nTry 'airt token --help' for help.\\n\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Pulling datablob uuid: 2221ab31-82db-433e-9f97-81e494e54088\\n\\r  0%|          | 0/1 [00:00<?, ?it/s]\\r  0%|          | 0/1 [00:05<?, ?it/s]\\r  0%|          | 0/1 [00:10<?, ?it/s]\\r100%|██████████| 1/1 [00:15<00:00,  5.05s/it]\\r100%|██████████| 1/1 [00:15<00:00, 15.19s/it]\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'************************************************************************************************************************'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'106d0e83-2129-4df8-83ad-32490b9e4da0\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for from-azure-blob-storage\n",
    "# Positive Scenario: Passing credential in arguments\n",
    "\n",
    "storage_client = StorageManagementClient(\n",
    "    DefaultAzureCredential(), os.environ[\"AZURE_SUBSCRIPTION_ID\"]\n",
    ")\n",
    "keys = storage_client.storage_accounts.list_keys(\n",
    "    \"test-airt-service\", \"testairtservice\"\n",
    ")\n",
    "credential = keys.keys[0].value\n",
    "\n",
    "cmd = [\n",
    "    \"from-azure-blob-storage\",\n",
    "    f\"{TEST_AZURE_URI}\",\n",
    "    \"--credential\",\n",
    "    f\"{credential}\",\n",
    "]\n",
    "\n",
    "assert_datablob(cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'91f38db9-7cea-4d5b-a72a-053ad044546b\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'91f38db9-7cea-4d5b-a72a-053ad044546b'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'datablob_uuid                         datasource_uuids    type                source                                                                                     region      cloud_provider    tags    pulled_on      folder_size    user_uuid                             error    disabled    ready\\n91f38db9-7cea-4d5b-a72a-053ad044546b  <none>              azure_blob_storage  https://testairtservice.blob.core.windows.net/test-container/ecommerce_behavior_notebooks  westeurope  azure             latest  8 seconds ago  10.2 MB        06a385d1-66a1-4ffc-8306-7f5821902fcc  <none>   False       True\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'05f83868-b5f1-430d-b6f3-ecf81aa99476\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'05f83868-b5f1-430d-b6f3-ecf81aa99476'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'datablob_uuid                         datasource_uuids    type                source                                                                                     region       cloud_provider    tags    pulled_on      folder_size    user_uuid                             error    disabled    ready\\n05f83868-b5f1-430d-b6f3-ecf81aa99476  <none>              azure_blob_storage  https://testairtservice.blob.core.windows.net/test-container/ecommerce_behavior_notebooks  northeurope  azure             latest  8 seconds ago  10.2 MB        06a385d1-66a1-4ffc-8306-7f5821902fcc  <none>   False       True\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for from-azure-blob-storage\n",
    "# Positive Scenario: Validating the default region\n",
    "with set_airt_service_token_envvar():\n",
    "    \n",
    "    for region in [\"westeurope\", \"northeurope\"]:\n",
    "        \n",
    "        cmd = [\n",
    "            \"from-azure-blob-storage\",\n",
    "            f\"{TEST_AZURE_URI}\",\n",
    "            \"--credential\",\n",
    "            f\"{credential}\",\n",
    "            \"--cloud-provider\",\n",
    "            \"azure\",\n",
    "            \"--region\",\n",
    "            f\"{region}\",\n",
    "            \"-q\"\n",
    "        ]\n",
    "\n",
    "        result = runner.invoke(app, cmd )\n",
    "        display(result.stdout)\n",
    "\n",
    "        db_uuid = result.stdout[:-1]\n",
    "        display(db_uuid)\n",
    "        assert len(remove_hypens_from_id(db_uuid)) == 32\n",
    "\n",
    "        result = runner.invoke(app, [\"details\", db_uuid])\n",
    "        display(result.stdout)\n",
    "        assert result.exit_code == 0\n",
    "        assert region in result.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "\n",
    "@app.command(\"from-mysql\")\n",
    "@helper.requires_auth_token\n",
    "def from_mysql(\n",
    "    host: str = typer.Option(..., help=\"Remote database host name.\"),\n",
    "    database: str = typer.Option(\n",
    "        ..., help=\"Database name.\"\n",
    "    ),\n",
    "    table: str = typer.Option(..., help=\"Table name.\"),\n",
    "    port: int = typer.Option(\n",
    "        3306,\n",
    "        help=\"Host port number. If not passed, then the default value **3306** will be used.\",\n",
    "    ),\n",
    "    cloud_provider: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--cloud-provider\",\n",
    "        \"-cp\",\n",
    "        help=\"The destination cloud storage provider's name to store the datablob. Currently, the API only supports **aws** and **azure** as cloud storage providers. If **None** (default value), then **aws**  will be used as the cloud storage provider.\",\n",
    "    ),\n",
    "    region: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--region\",\n",
    "        \"-r\",\n",
    "        help=\"The destination cloud provider's region to save your datablob. If **None** (default value) then the default region will be assigned based on the cloud provider. \" \\\n",
    "            \"In the case of **aws**, **eu-west-1** will be used and in the case of **azure**, **westeurope** will be used. \" \\\n",
    "            \"The supported AWS regions are: ap-northeast-1, ap-northeast-2, ap-south-1, ap-southeast-1, ap-southeast-2, ca-central-1, eu-central-1, \" \\\n",
    "            \"eu-north-1, eu-west-1, eu-west-2, eu-west-3, sa-east-1, us-east-1, us-east-2, us-west-1, us-west-2. The supported Azure Blob Storage \" \\\n",
    "            \"regions are: australiacentral, australiacentral2, australiaeast, australiasoutheast, brazilsouth, canadacentral, canadaeast, centralindia, \" \\\n",
    "            \"centralus, eastasia, eastus, eastus2, francecentral, francesouth, germanynorth, germanywestcentral, japaneast, japanwest, koreacentral, koreasouth, \" \\\n",
    "            \"northcentralus, northeurope, norwayeast, norwaywest, southafricanorth, southafricawest, southcentralus, southeastasia, southindia, switzerlandnorth, \" \\\n",
    "            \"switzerlandwest, uaecentral, uaenorth, uksouth, ukwest, westcentralus, westeurope, westindia, westus, westus2.\"\n",
    "    ),\n",
    "    username: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--username\",\n",
    "        \"-u\",\n",
    "        help=f'Database username. If not passed, the default value \"root\" will be used unless the value is explicitly set in the environment variable **{CLIENT_DB_USERNAME}**.'\n",
    "    ),\n",
    "    password: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--password\",\n",
    "        \"-p\",\n",
    "        help=f'Database password. If not passed, the default value \"\" will be used unless the value is explicitly set in the environment variable **{CLIENT_DB_PASSWORD}**.'\n",
    "    ),\n",
    "    tag: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--tag\",\n",
    "        \"-t\",\n",
    "        help=\"A string to tag the datablob. If not passed, then the tag **latest** will be assigned to the datablob.\",\n",
    "    ),\n",
    "    quiet: bool = typer.Option(\n",
    "        False,\n",
    "        \"--quiet\",\n",
    "        \"-q\",\n",
    "        help=\"Output datablob uuid only.\",\n",
    "    ),\n",
    "    debug: bool = typer.Option(\n",
    "        False,\n",
    "        \"--debug\",\n",
    "        \"-d\",\n",
    "        help=\"Set logger level to DEBUG and output everything.\",\n",
    "    ),\n",
    "):\n",
    "    \"\"\"Create and return a datablob that encapsulates the data from a mysql database.\n",
    "    \n",
    "    If the database requires authentication, pass the username/password as commandline arguments or store it in\n",
    "    the **AIRT_CLIENT_DB_USERNAME** and **AIRT_CLIENT_DB_PASSWORD** environment variables.\n",
    "    \"\"\"\n",
    "\n",
    "    from airt.client import DataBlob\n",
    "\n",
    "    db = DataBlob.from_mysql(\n",
    "        host=host,\n",
    "        database=database,\n",
    "        port=port,\n",
    "        table=table,\n",
    "        username=username,\n",
    "        password=password,\n",
    "        cloud_provider=cloud_provider,\n",
    "        region=region,\n",
    "        tag=tag\n",
    "    )\n",
    "\n",
    "    if quiet:\n",
    "        db.wait()\n",
    "        typer.echo(f\"{db.uuid}\")\n",
    "    else:\n",
    "        typer.echo(f\"Pulling datablob uuid: {db.uuid}\")\n",
    "        db.progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Usage: root from-mysql [OPTIONS]\\n\\n  Create and return a datablob that encapsulates the data from a mysql database.\\n\\n  If the database requires authentication, pass the username/password as\\n  commandline arguments or store it in the **AIRT_CLIENT_DB_USERNAME** and\\n  **AIRT_CLIENT_DB_PASSWORD** environment variables.\\n\\nOptions:\\n  --host TEXT                 Remote database host name.  [required]\\n  --database TEXT             Database name.  [required]\\n  --table TEXT                Table name.  [required]\\n  --port INTEGER              Host port number. If not passed, then the default\\n                              value **3306** will be used.  [default: 3306]\\n  -cp, --cloud-provider TEXT  The destination cloud storage provider\\'s name to\\n                              store the datablob. Currently, the API only\\n                              supports **aws** and **azure** as cloud storage\\n                              providers. If **None** (default value), then\\n                              **aws**  will be used as the cloud storage\\n                              provider.\\n  -r, --region TEXT           The destination cloud provider\\'s region to save\\n                              your datablob. If **None** (default value) then\\n                              the default region will be assigned based on the\\n                              cloud provider. In the case of **aws**, **eu-\\n                              west-1** will be used and in the case of\\n                              **azure**, **westeurope** will be used. The\\n                              supported AWS regions are: ap-northeast-1, ap-\\n                              northeast-2, ap-south-1, ap-southeast-1, ap-\\n                              southeast-2, ca-central-1, eu-central-1, eu-\\n                              north-1, eu-west-1, eu-west-2, eu-west-3, sa-\\n                              east-1, us-east-1, us-east-2, us-west-1, us-\\n                              west-2. The supported Azure Blob Storage regions\\n                              are: australiacentral, australiacentral2,\\n                              australiaeast, australiasoutheast, brazilsouth,\\n                              canadacentral, canadaeast, centralindia,\\n                              centralus, eastasia, eastus, eastus2,\\n                              francecentral, francesouth, germanynorth,\\n                              germanywestcentral, japaneast, japanwest,\\n                              koreacentral, koreasouth, northcentralus,\\n                              northeurope, norwayeast, norwaywest,\\n                              southafricanorth, southafricawest, southcentralus,\\n                              southeastasia, southindia, switzerlandnorth,\\n                              switzerlandwest, uaecentral, uaenorth, uksouth,\\n                              ukwest, westcentralus, westeurope, westindia,\\n                              westus, westus2.\\n  -u, --username TEXT         Database username. If not passed, the default\\n                              value \"root\" will be used unless the value is\\n                              explicitly set in the environment variable\\n                              **AIRT_CLIENT_DB_USERNAME**.\\n  -p, --password TEXT         Database password. If not passed, the default\\n                              value \"\" will be used unless the value is\\n                              explicitly set in the environment variable\\n                              **AIRT_CLIENT_DB_PASSWORD**.\\n  -t, --tag TEXT              A string to tag the datablob. If not passed, then\\n                              the tag **latest** will be assigned to the\\n                              datablob.\\n  -q, --quiet                 Output datablob uuid only.\\n  -d, --debug                 Set logger level to DEBUG and output everything.\\n  --help                      Show this message and exit.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert_has_help([\"from-mysql\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pulling datablob uuid: 3c5a1784-d9cc-4098-a214-11ef8adf7769\\n\\r  0%|          | 0/1 [00:00<?, ?it/s]\\r  0%|          | 0/1 [00:05<?, ?it/s]\\nError: (MySQLdb.OperationalError) (2005, \"Unknown MySQL server host \\'db.staging.airt.ai\\' (-2)\")\\n(Background on this error at: https://sqlalche.me/e/14/e3q8)\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tests for db. Testing negative scenario.\n",
    "# Passing invalid host address\n",
    "\n",
    "cmd = [\n",
    "    \"from-mysql\",\n",
    "    \"--host\",\n",
    "    \"db.staging.airt.ai\",\n",
    "    \"--database\",\n",
    "    \"test\",\n",
    "    \"--table\",\n",
    "    \"test\",\n",
    "]\n",
    "\n",
    "\n",
    "with set_airt_service_token_envvar():\n",
    "    # Without quiet (verbose)\n",
    "    result = runner.invoke(app, cmd)\n",
    "    display(result.stdout)\n",
    "    assert \"Unknown MySQL server host 'db.staging.airt.ai'\" in result.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/_common_metadata to ../../../tmp/test_s3_download_ycsu_oym/_common_metadata\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/_metadata to ../../../tmp/test_s3_download_ycsu_oym/_metadata\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.11.parquet to ../../../tmp/test_s3_download_ycsu_oym/part.11.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.0.parquet to ../../../tmp/test_s3_download_ycsu_oym/part.0.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.15.parquet to ../../../tmp/test_s3_download_ycsu_oym/part.15.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.1.parquet to ../../../tmp/test_s3_download_ycsu_oym/part.1.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.13.parquet to ../../../tmp/test_s3_download_ycsu_oym/part.13.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.12.parquet to ../../../tmp/test_s3_download_ycsu_oym/part.12.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.10.parquet to ../../../tmp/test_s3_download_ycsu_oym/part.10.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.14.parquet to ../../../tmp/test_s3_download_ycsu_oym/part.14.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.16.parquet to ../../../tmp/test_s3_download_ycsu_oym/part.16.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.17.parquet to ../../../tmp/test_s3_download_ycsu_oym/part.17.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.18.parquet to ../../../tmp/test_s3_download_ycsu_oym/part.18.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.2.parquet to ../../../tmp/test_s3_download_ycsu_oym/part.2.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.4.parquet to ../../../tmp/test_s3_download_ycsu_oym/part.4.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.3.parquet to ../../../tmp/test_s3_download_ycsu_oym/part.3.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.7.parquet to ../../../tmp/test_s3_download_ycsu_oym/part.7.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.19.parquet to ../../../tmp/test_s3_download_ycsu_oym/part.19.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.9.parquet to ../../../tmp/test_s3_download_ycsu_oym/part.9.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.8.parquet to ../../../tmp/test_s3_download_ycsu_oym/part.8.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.5.parquet to ../../../tmp/test_s3_download_ycsu_oym/part.5.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.6.parquet to ../../../tmp/test_s3_download_ycsu_oym/part.6.parquet\n",
      "_common_metadata  part.12.parquet  part.18.parquet  part.6.parquet\n",
      "_metadata         part.13.parquet  part.19.parquet  part.7.parquet\n",
      "part.0.parquet    part.14.parquet  part.2.parquet   part.8.parquet\n",
      "part.1.parquet    part.15.parquet  part.3.parquet   part.9.parquet\n",
      "part.10.parquet   part.16.parquet  part.4.parquet\n",
      "part.11.parquet   part.17.parquet  part.5.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ValueError(\"Table 'test_db_pull' already exists.\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Pulling datablob uuid: 21660a1e-1b90-477a-a9c1-493db7def964\\n\\r  0%|          | 0/1 [00:00<?, ?it/s]\\r  0%|          | 0/1 [00:05<?, ?it/s]\\r100%|██████████| 1/1 [00:10<00:00,  5.06s/it]\\r100%|██████████| 1/1 [00:10<00:00, 10.15s/it]\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'518fd551-fd62-43ad-bb9c-22db6660d0de'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'datablob_uuid                         datasource_uuids    type    source                                               region     cloud_provider    tags    pulled_on      folder_size    user_uuid                             error    disabled    ready\\n518fd551-fd62-43ad-bb9c-22db6660d0de  <none>              db      mysql://harish-mysql:3306/airt_service/test_db_pull  eu-west-1  aws               latest  2 seconds ago  8.0 MB         06a385d1-66a1-4ffc-8306-7f5821902fcc  <none>   False       True\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Pulling datablob uuid: b1589391-1c13-4fa2-800f-fd2d73012d1a\\n\\r  0%|          | 0/1 [00:00<?, ?it/s]\\r  0%|          | 0/1 [00:05<?, ?it/s]\\r100%|██████████| 1/1 [00:10<00:00,  5.05s/it]\\r100%|██████████| 1/1 [00:10<00:00, 10.14s/it]\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'4d4b37f3-01ff-4f90-9e31-a2432449d93d'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'datablob_uuid                         datasource_uuids    type    source                                               region     cloud_provider    tags    pulled_on      folder_size    user_uuid                             error    disabled    ready\\n4d4b37f3-01ff-4f90-9e31-a2432449d93d  <none>              db      mysql://harish-mysql:3306/airt_service/test_db_pull  eu-west-3  aws               latest  2 seconds ago  8.0 MB         06a385d1-66a1-4ffc-8306-7f5821902fcc  <none>   False       True\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tests for db. Testing positive scenario.\n",
    "\n",
    "# Helper function to create new table in the mysql db\n",
    "\n",
    "def get_db_engine():\n",
    "    \n",
    "    username=os.environ[\"DB_USERNAME\"]\n",
    "    password=os.environ[\"DB_PASSWORD\"]\n",
    "    host=os.environ[\"DB_HOST\"]\n",
    "    port=int(os.environ[\"DB_PORT\"])\n",
    "    database=os.environ[\"DB_DATABASE\"]\n",
    "    database_server=os.environ[\"DB_DATABASE_SERVER\"]\n",
    "    \n",
    "    quoted_password = urlquote(password)\n",
    "    conn_str = f\"{database_server}://{username}:{quoted_password}@{host}:{port}/{database}\"\n",
    "    engine = create_engine(conn_str)\n",
    "    \n",
    "    return engine\n",
    "\n",
    "with tempfile.TemporaryDirectory(prefix=\"test_s3_download_\") as d:\n",
    "    !aws s3 sync {TEST_S3_URI} {d}\n",
    "    !ls {d}\n",
    "    \n",
    "    engine = get_db_engine()\n",
    "    \n",
    "    df = pd.read_parquet(d)\n",
    "    try:\n",
    "        df.to_sql(\"test_db_pull\", con=engine, if_exists=\"fail\")\n",
    "    except ValueError as e:\n",
    "        display(e)\n",
    "\n",
    "\n",
    "with set_airt_service_token_envvar():\n",
    "    \n",
    "    for region in [\"eu-west-1\", \"eu-west-3\"]:\n",
    "        \n",
    "        # Creating a new datasource\n",
    "        cmd = [\n",
    "            \"from-mysql\", \n",
    "            \"--host\", os.environ[\"DB_HOST\"],\n",
    "            \"--database\", os.environ[\"DB_DATABASE\"],\n",
    "            \"--table\", \"test_db_pull\",\n",
    "            \"--username\", os.environ[\"DB_USERNAME\"],\n",
    "            \"--password\", os.environ[\"DB_PASSWORD\"],\n",
    "            \"--tag\", \"v1.1.0\"\n",
    "        ]\n",
    "\n",
    "        cmd_q = [\n",
    "            \"from-mysql\", \n",
    "            \"--host\", os.environ[\"DB_HOST\"],\n",
    "            \"--database\", os.environ[\"DB_DATABASE\"],\n",
    "            \"--table\", \"test_db_pull\",\n",
    "            \"--username\", os.environ[\"DB_USERNAME\"],\n",
    "            \"--password\", os.environ[\"DB_PASSWORD\"],\n",
    "            \"-cp\", \"aws\",\n",
    "            \"--region\", region,\n",
    "            \"-q\",\n",
    "        ]\n",
    "    \n",
    "        # Without quiet\n",
    "        result = runner.invoke(app, cmd)\n",
    "\n",
    "        display(result.stdout)\n",
    "        assert \"Pulling datablob uuid:\" in str(result.stdout)\n",
    "\n",
    "        # With quiet\n",
    "        result = runner.invoke(app, cmd_q)\n",
    "        db_uuid = result.stdout[:-1]\n",
    "        display(db_uuid)\n",
    "        assert len(remove_hypens_from_id(db_uuid)) == 32\n",
    "\n",
    "        result = runner.invoke(app, [\"details\", db_uuid])\n",
    "        display(result.stdout)\n",
    "        assert result.exit_code == 0\n",
    "        assert region in result.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "\n",
    "@app.command(\"to-datasource\")\n",
    "@helper.requires_auth_token\n",
    "def to_datasource(\n",
    "    uuid: str = typer.Option(\n",
    "        ...,\n",
    "        help=\"Datablob uuid.\",\n",
    "    ),\n",
    "    file_type: str = typer.Option(\n",
    "        ...,\n",
    "        help='The file type of the datablob. Currently, the API only supports \"csv\" and \"parquet\" as file types.',\n",
    "    ),\n",
    "    index_column: str = typer.Option(\n",
    "        ...,\n",
    "        help=\"The column to use as index (row labels).\",\n",
    "    ),\n",
    "    sort_by: str = typer.Option(\n",
    "        ...,\n",
    "        help=\"The column(s) to sort the data. Can either be a string or a JSON encoded list of strings.\",\n",
    "    ),\n",
    "    deduplicate_data: bool = typer.Option(\n",
    "        False,\n",
    "        help=\"If set to **True** (default value **False**), the datasource will be created with duplicate rows removed.\",\n",
    "    ),\n",
    "    blocksize: str = typer.Option(\n",
    "        \"256MB\",\n",
    "        help=\"The number of bytes used to split larger files. If None, then the default value **256MB** will be used.\",\n",
    "    ),\n",
    "    kwargs_json: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        help=\"Additional JSON encoded dict arguments to use while processing the data.e.g: To skip 100 lines from the bottom of file, pass '{\"\n",
    "        '\"skipfooter\"'\n",
    "        \": 100}'\",\n",
    "    ),\n",
    "    quiet: bool = typer.Option(\n",
    "        False,\n",
    "        \"--quiet\",\n",
    "        \"-q\",\n",
    "        help=\"Output datasource uuid only.\",\n",
    "    ),\n",
    "    debug: bool = typer.Option(\n",
    "        False,\n",
    "        \"--debug\",\n",
    "        \"-d\",\n",
    "        help=\"Set logger level to DEBUG and output everything.\",\n",
    "    ),\n",
    "):\n",
    "    \"\"\"Process the datablob and return a datasource object.\"\"\"\n",
    "\n",
    "    from airt.client import DataBlob\n",
    "\n",
    "    kwargs = json.loads(kwargs_json) if kwargs_json else {}\n",
    "\n",
    "    try:\n",
    "        sort_by = json.loads(sort_by)\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        pass\n",
    "\n",
    "    db = DataBlob(uuid=uuid)\n",
    "    ds = db.to_datasource(\n",
    "        file_type=file_type,\n",
    "        index_column=index_column,\n",
    "        sort_by=sort_by,\n",
    "        deduplicate_data=deduplicate_data,\n",
    "        blocksize=blocksize,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    if quiet:\n",
    "        ds.wait()\n",
    "        typer.echo(f\"{ds.uuid}\")\n",
    "    else:\n",
    "        typer.echo(f\"Processing and pulling the datasource uuid: {ds.uuid}\")\n",
    "\n",
    "        ds.progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Usage: root to-datasource [OPTIONS]\\n\\n  Process the datablob and return a datasource object.\\n\\nOptions:\\n  --uuid TEXT                     Datablob uuid.  [required]\\n  --file-type TEXT                The file type of the datablob. Currently, the\\n                                  API only supports \"csv\" and \"parquet\" as file\\n                                  types.  [required]\\n  --index-column TEXT             The column to use as index (row labels).\\n                                  [required]\\n  --sort-by TEXT                  The column(s) to sort the data. Can either be\\n                                  a string or a JSON encoded list of strings.\\n                                  [required]\\n  --deduplicate-data / --no-deduplicate-data\\n                                  If set to **True** (default value **False**),\\n                                  the datasource will be created with duplicate\\n                                  rows removed.  [default: no-deduplicate-data]\\n  --blocksize TEXT                The number of bytes used to split larger\\n                                  files. If None, then the default value\\n                                  **256MB** will be used.  [default: 256MB]\\n  --kwargs-json TEXT              Additional JSON encoded dict arguments to use\\n                                  while processing the data.e.g: To skip 100\\n                                  lines from the bottom of file, pass\\n                                  \\'{\"skipfooter\": 100}\\'\\n  -q, --quiet                     Output datasource uuid only.\\n  -d, --debug                     Set logger level to DEBUG and output\\n                                  everything.\\n  --help                          Show this message and exit.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert_has_help([\"to-datasource\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Processing and pulling the datasource uuid: 8b5b59ae-7dd5-4ff0-b35b-bc040768ef6f\\n\\r  0%|          | 0/1 [00:00<?, ?it/s]\\r  0%|          | 0/1 [00:05<?, ?it/s]\\r  0%|          | 0/1 [00:10<?, ?it/s]\\r  0%|          | 0/1 [00:15<?, ?it/s]\\r  0%|          | 0/1 [00:20<?, ?it/s]\\r  0%|          | 0/1 [00:25<?, ?it/s]\\r100%|██████████| 1/1 [00:30<00:00,  5.05s/it]\\r100%|██████████| 1/1 [00:30<00:00, 30.36s/it]\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'3978f659-a943-404a-b246-c95670c2e060\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for to-datasource\n",
    "\n",
    "with set_airt_service_token_envvar():\n",
    "    with generate_db() as db:\n",
    "        cmd = [\n",
    "            \"to-datasource\",\n",
    "            \"--uuid\", f\"{db.uuid}\",\n",
    "            \"--file-type\", \"parquet\",\n",
    "            \"--index-column\", \"user_id\",\n",
    "            \"--sort-by\", \"event_time\",\n",
    "            \"--kwargs-json\", '{\"parse_dates\": [\"event_time\"], \"skipfooter\": 100}',\n",
    "        ]\n",
    "        result = runner.invoke(app, cmd)\n",
    "\n",
    "        display(result.stdout)\n",
    "        assert result.exit_code == 0, f\"{result.stdout=}, {result.exit_code=}\"\n",
    "        assert \"Processing and pulling the datasource uuid:\" in result.stdout, result.stdout\n",
    "        \n",
    "        cmd = [\n",
    "            \"to-datasource\",\n",
    "            \"--uuid\", f\"{db.uuid}\",\n",
    "            \"--file-type\", \"parquet\",\n",
    "            \"--index-column\", \"user_id\",\n",
    "            \"--sort-by\", '[\"event_time\", \"category_id\"]',\n",
    "            \"--kwargs-json\", '{\"parse_dates\": [\"event_time\"], \"skipfooter\": 100}',\n",
    "            \"-q\",\n",
    "        ]\n",
    "        result = runner.invoke(app, cmd)\n",
    "\n",
    "        display(result.stdout)\n",
    "        assert result.exit_code == 0, f\"{result.stdout=}, {result.exit_code=}\"\n",
    "        assert len (result.stdout[:-1].replace('-', '').replace('\\n', '')) == 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Error: \"Data has no column \\'random-col\\': use any column of [\\'event_time\\', \\'event_type\\', \\'product_id\\', \\'category_id\\', \\'category_code\\', \\'brand\\', \\'price\\', \\'user_id\\', \\'user_session\\']\"\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for to-datasource. Passing wrong index and sort column names\n",
    "\n",
    "with set_airt_service_token_envvar():\n",
    "    with generate_db() as db:\n",
    "    \n",
    "        cmd = [\"to-datasource\", \"--uuid\", f\"{db.uuid}\", \"--file-type\", \"parquet\", \"--index-column\", \"random-col\", \"--sort-by\", \"random-col\", \"-q\"]\n",
    "        result = runner.invoke(app, cmd)\n",
    "\n",
    "        display(result.stdout)\n",
    "        assert \"'random-col'\" in result.stdout, result.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "\n",
    "@app.command()\n",
    "@helper.display_formated_table\n",
    "@helper.requires_auth_token\n",
    "def ls(\n",
    "    offset: int = typer.Option(\n",
    "        0,\n",
    "        \"--offset\",\n",
    "        \"-o\",\n",
    "        help=\"The number of datablobs to offset at the beginning. If **None**, then the default value **0** will be used.\",\n",
    "    ),\n",
    "    limit: int = typer.Option(\n",
    "        100,\n",
    "        \"--limit\",\n",
    "        \"-l\",\n",
    "        help=\"The maximum number of datablobs to return from the server. If **None**, then the default value **100** will be used.\",\n",
    "    ),\n",
    "    disabled: bool = typer.Option(\n",
    "        False,\n",
    "        \"--disabled\",\n",
    "        help=\"If set to **True**, then only the deleted datablobs will be returned.\" \\\n",
    "            \"Else, the default value **False** will be used to return only the list\" \\\n",
    "            \"of active datablobs.\"\n",
    "    ),\n",
    "    completed: bool = typer.Option(\n",
    "        False,\n",
    "        \"--completed\",\n",
    "        help=\"If set to **True**, then only the datablobs that are successfully downloaded\" \\\n",
    "            \"to the server will be returned. Else, the default value **False** will be used to\" \\\n",
    "            \"return all the datablobs.\"\n",
    "    ),\n",
    "    format: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--format\",\n",
    "        \"-f\",\n",
    "        help=\"Format output and show only the given column(s) values.\"\n",
    "    ),\n",
    "    quiet: bool = typer.Option(\n",
    "        False,\n",
    "        \"--quiet\",\n",
    "        \"-q\",\n",
    "        help=\"Output only datablob uuids separated by space\",\n",
    "    ),\n",
    "    debug: bool = typer.Option(\n",
    "        False,\n",
    "        \"--debug\",\n",
    "        \"-d\",\n",
    "        help=\"Set logger level to DEBUG and output everything.\",\n",
    "    ),\n",
    ") -> Dict[\"str\", Union[pd.DataFrame, str]]:\n",
    "    \"\"\"Return the list of datablobs.\"\"\"\n",
    "\n",
    "    from airt.client import DataBlob\n",
    "    \n",
    "    dbx = DataBlob.ls(offset=offset, limit=limit, disabled=disabled, completed=completed)\n",
    "    \n",
    "    df = DataBlob.as_df(dbx)\n",
    "    \n",
    "    df['pulled_on'] = helper.humanize_date(df['pulled_on'])\n",
    "    df['folder_size'] = helper.humanize_size(df['folder_size'])\n",
    "    \n",
    "    return {\"df\": df, \"quite_column_name\": \"datablob_uuid\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Usage: root ls [OPTIONS]\\n\\n  Return the list of datablobs.\\n\\nOptions:\\n  -o, --offset INTEGER  The number of datablobs to offset at the beginning. If\\n                        **None**, then the default value **0** will be used.\\n                        [default: 0]\\n  -l, --limit INTEGER   The maximum number of datablobs to return from the\\n                        server. If **None**, then the default value **100** will\\n                        be used.  [default: 100]\\n  --disabled            If set to **True**, then only the deleted datablobs will\\n                        be returned.Else, the default value **False** will be\\n                        used to return only the listof active datablobs.\\n  --completed           If set to **True**, then only the datablobs that are\\n                        successfully downloadedto the server will be returned.\\n                        Else, the default value **False** will be used toreturn\\n                        all the datablobs.\\n  -f, --format TEXT     Format output and show only the given column(s) values.\\n  -q, --quiet           Output only datablob uuids separated by space\\n  -d, --debug           Set logger level to DEBUG and output everything.\\n  --help                Show this message and exit.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert_has_help([\"ls\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datablob_uuid                         type\\ne6493ad2-bf39-4edb-b08e-0da06c148635  azure_blob_storage\\n1966d500-0b0c-49ff-bd6e-fc3a99956910  s3\\nc89b15b1-8e63-40f8-8824-4c3d5c857abc  azure_blob_storage\\n8cdbc837-723d-48da-b3ac-9b0e8ad6435c  db\\n76cb6e5c-4c9b-4b9a-8e93-7415f022a0b1  db\\ned044904-4647-4001-896d-7b56bf047616  local\\n406fb790-f5d9-4d86-8c11-a31ea91b1249  s3\\nb78ae923-f6d5-49f4-bcbd-1492fdb8c00b  s3\\n8efd5d95-a01c-49f6-8c63-d8fefd3dea22  s3\\nc75e0516-6cbf-4356-b4b0-fdb9a393ecb8  azure_blob_storage\\n1b4dfe61-781f-4267-a8b4-3956826bb351  azure_blob_storage\\n75d00af3-19a1-4731-ac2b-0e7d11526aa2  azure_blob_storage\\n9ee91442-b110-4af2-b2f1-b5445b6208e3  azure_blob_storage\\nd8a17bcf-659b-4f51-95cc-ffee2fe191f9  db\\n13c0b5d7-2d64-483e-9ee5-fb8cf476897b  db\\n726efd1b-e79f-4c82-8c32-f37e25bde427  db\\n7933283e-2232-4dda-a111-bb1e0b7551e1  db\\n05a54859-1192-4bb4-8db6-6a88d2aa0043  db\\n52fbdd0c-1726-4cfb-8317-fb4b1559643d  db\\nd35c6ea5-3ad3-4979-9b19-2bda297be074  local\\nc76d6759-edf4-4eaa-bc64-0145471f7272  local\\n3cc0d538-c4f5-4cab-be69-d732262e4046  local\\n2c3cccb6-09a4-4bfa-b278-525d65b68721  local\\nbf2b7764-7b0e-443d-aa8d-154994108370  s3\\n9c2fc83a-2a26-4eaa-9f9f-4f71be50816d  local\\nc507a683-864b-4fff-8c0a-1dd6c4e695f3  azure_blob_storage\\n7aa4d380-cf11-4525-9edd-a2deff7306a1  s3\\nebd3a56a-be18-45d4-b0f7-07e454e5dba7  azure_blob_storage\\n32a08352-8239-422a-90ad-4f5b27f3364f  db\\n9cb85aaf-9a12-4d3b-ad1c-2fdf6d6b57ff  db\\n24504a2f-5956-48fd-b6d6-95e96e5a91a3  local\\nb01763dc-14af-4574-851b-5b2aee095dc0  s3\\nd85c40e1-09a4-4e1a-ae8b-3ea13fcd3bfa  s3\\nc50fd1a8-3bdc-469e-8be9-0898b45f160e  s3\\n2e1b95c2-7737-4dd5-bc4c-2c850e006f09  azure_blob_storage\\ndf0a0ecd-446c-4603-9cf3-42dccc3967b9  azure_blob_storage\\nddbddecc-2926-497c-9a3c-b5dab5d5e2a8  azure_blob_storage\\n12f440c6-b926-4024-b469-5c8d2f91b47a  azure_blob_storage\\nef8b78a0-f12c-4d78-aa57-0bd5e666d0c0  db\\n88e9b843-065b-475e-93dd-a1d977029081  db\\n4f39b681-f7f7-42ff-951d-46b2ce7d88c3  db\\n829a8941-897b-4dd9-a089-b1e25617a003  db\\n1aee1a63-d40d-4a64-96ad-f5fb89ee4909  db\\n19b1d338-6998-4e6b-8dea-66d50d3a64d9  db\\nb8ca6641-591f-4dfa-b02f-2d1fd909014d  local\\n7e95733b-43ca-44b5-a48d-a1e2b02b3c5e  local\\n641f890f-4f20-4c3d-a4f9-7d9235d832fa  local\\ncd6fe347-6128-4e9d-9bfa-cc67469a67d5  local\\nb9ec1a5b-f353-4ade-88e5-a24e82f43250  s3\\n5f0a7764-687e-45dc-97d0-e0110414846f  local\\n344d5909-0f53-4235-ab3e-a95faa15ae6f  s3\\nf2763fd5-ad62-4740-9c53-5075e0f11c98  s3\\n98dab2c3-8fc4-4dba-b10e-16981e837066  s3\\n644d3404-4f16-4f6d-96c3-19d92e94ca39  s3\\nd93aa70f-03b8-4d73-adeb-68045f7a7e7a  s3\\nc05181ee-f6f3-4d16-85d3-9a32c7c320b3  s3\\n6f9f3f83-0b2e-4e85-9859-181ca0bec005  s3\\n42edc605-b361-427d-a951-3f29e38d3f25  s3\\n0123c488-04cf-496e-809f-49a09ede5d46  s3\\nc11439f7-324f-472e-a71b-7a73e4812270  s3\\n8ec72307-cd99-4b58-aa81-6a0ac15d600d  s3\\ne44c10b4-9b3c-4429-ad4f-bb6aa64fa303  s3\\n9206c290-008b-453c-a045-80069de4f176  s3\\n314bfe29-500c-4ebd-aa62-865a3c11d362  s3\\nf831ee12-66d4-4edc-ab81-615cb1c896bd  s3\\ncdd24843-37cb-4c0a-8270-0a47e7cc8ac3  s3\\n9b403f05-5d62-4b26-9f98-338bb006431d  s3\\nf565f941-1f6b-4a7b-92c6-730718266450  s3\\n6e73f6c6-3dee-4c0f-93c8-d21cfd966194  azure_blob_storage\\n65769cc6-5d62-4a12-b6fe-fc9791b4eaca  s3\\n17aa8509-2dc0-4fe0-a4ec-3a3ce9f8032a  s3\\nd59f8f06-c176-48e4-a3b2-397c4948a3b2  s3\\nf575d869-175d-4f7a-8d3e-9eb6f35428a6  s3\\ncc80213e-81fd-4642-89c3-51aea0650661  s3\\naebbdf7b-dc41-4866-bfd3-6fb6d9d8e71c  azure_blob_storage\\nabc073ea-6020-4528-9c87-e45f9d873d9f  s3\\n28fabd31-bdf7-4596-8d63-cc406fece769  s3\\n6d85539b-fc8a-4f9e-b158-3e3f90bff2c6  s3\\n7739b23d-5938-44b7-b918-b72a7f352a7f  s3\\nba913a36-bda3-40bd-86e8-0a9a3762b548  azure_blob_storage\\n0b63afe3-8e37-4056-8ae4-aec29c9984f6  azure_blob_storage\\n5cc79ef0-f8c0-4539-a33f-1505285688f3  s3\\n37a3c501-bee1-4bd2-a0f9-6dd3c40b0a19  azure_blob_storage\\nb7c67989-80b0-479b-95ea-34eeeef9d45e  db\\n5d9a3183-8a1c-4eb2-b81b-becdd7e98fdc  s3\\n6ead340e-840d-4980-82d3-0f323629ecf2  azure_blob_storage\\ne1bb1a82-0354-4542-9fc7-d7b50567d810  db\\ncd03749d-61e2-476a-859f-ae54fb9609b4  s3\\n76856e6a-0bb8-4590-9fe7-cfe752992abd  s3\\n3b69afcf-03d6-4455-919f-d973e2097edd  local\\n80cc940b-36fa-42b1-ad4c-2c022f88332c  db\\naff7b74b-348f-4b33-80a0-76ff353d54ce  db\\nedc881f2-d2bc-4e79-a3fc-1c9079a61482  s3\\n5d6b7e73-907e-4014-91f8-b09339589585  s3\\ne1f5942c-caac-4fd7-95f3-837b1f576e6a  db\\n7057acc5-1f7a-4ef0-b29b-4b2a9309ece4  db\\nb23f9005-471e-445c-95df-e17ecc3595db  db\\n804f81b1-1464-431d-82f8-dc9e113a8d38  s3\\n88abcd34-8085-4c7d-bf42-b3efc7cc5b08  s3\\nb4ce882d-9842-414a-a284-658e81c7c5cd  azure_blob_storage\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'e6493ad2-bf39-4edb-b08e-0da06c148635\\n1966d500-0b0c-49ff-bd6e-fc3a99956910\\nc89b15b1-8e63-40f8-8824-4c3d5c857abc\\n8cdbc837-723d-48da-b3ac-9b0e8ad6435c\\n76cb6e5c-4c9b-4b9a-8e93-7415f022a0b1\\ned044904-4647-4001-896d-7b56bf047616\\n406fb790-f5d9-4d86-8c11-a31ea91b1249\\nb78ae923-f6d5-49f4-bcbd-1492fdb8c00b\\n8efd5d95-a01c-49f6-8c63-d8fefd3dea22\\nc75e0516-6cbf-4356-b4b0-fdb9a393ecb8\\n1b4dfe61-781f-4267-a8b4-3956826bb351\\n75d00af3-19a1-4731-ac2b-0e7d11526aa2\\n9ee91442-b110-4af2-b2f1-b5445b6208e3\\nd8a17bcf-659b-4f51-95cc-ffee2fe191f9\\n13c0b5d7-2d64-483e-9ee5-fb8cf476897b\\n726efd1b-e79f-4c82-8c32-f37e25bde427\\n7933283e-2232-4dda-a111-bb1e0b7551e1\\n05a54859-1192-4bb4-8db6-6a88d2aa0043\\n52fbdd0c-1726-4cfb-8317-fb4b1559643d\\nd35c6ea5-3ad3-4979-9b19-2bda297be074\\nc76d6759-edf4-4eaa-bc64-0145471f7272\\n3cc0d538-c4f5-4cab-be69-d732262e4046\\n2c3cccb6-09a4-4bfa-b278-525d65b68721\\nbf2b7764-7b0e-443d-aa8d-154994108370\\n9c2fc83a-2a26-4eaa-9f9f-4f71be50816d\\nc507a683-864b-4fff-8c0a-1dd6c4e695f3\\n7aa4d380-cf11-4525-9edd-a2deff7306a1\\nebd3a56a-be18-45d4-b0f7-07e454e5dba7\\n32a08352-8239-422a-90ad-4f5b27f3364f\\n9cb85aaf-9a12-4d3b-ad1c-2fdf6d6b57ff\\n24504a2f-5956-48fd-b6d6-95e96e5a91a3\\nb01763dc-14af-4574-851b-5b2aee095dc0\\nd85c40e1-09a4-4e1a-ae8b-3ea13fcd3bfa\\nc50fd1a8-3bdc-469e-8be9-0898b45f160e\\n2e1b95c2-7737-4dd5-bc4c-2c850e006f09\\ndf0a0ecd-446c-4603-9cf3-42dccc3967b9\\nddbddecc-2926-497c-9a3c-b5dab5d5e2a8\\n12f440c6-b926-4024-b469-5c8d2f91b47a\\nef8b78a0-f12c-4d78-aa57-0bd5e666d0c0\\n88e9b843-065b-475e-93dd-a1d977029081\\n4f39b681-f7f7-42ff-951d-46b2ce7d88c3\\n829a8941-897b-4dd9-a089-b1e25617a003\\n1aee1a63-d40d-4a64-96ad-f5fb89ee4909\\n19b1d338-6998-4e6b-8dea-66d50d3a64d9\\nb8ca6641-591f-4dfa-b02f-2d1fd909014d\\n7e95733b-43ca-44b5-a48d-a1e2b02b3c5e\\n641f890f-4f20-4c3d-a4f9-7d9235d832fa\\ncd6fe347-6128-4e9d-9bfa-cc67469a67d5\\nb9ec1a5b-f353-4ade-88e5-a24e82f43250\\n5f0a7764-687e-45dc-97d0-e0110414846f\\n344d5909-0f53-4235-ab3e-a95faa15ae6f\\nf2763fd5-ad62-4740-9c53-5075e0f11c98\\n98dab2c3-8fc4-4dba-b10e-16981e837066\\n644d3404-4f16-4f6d-96c3-19d92e94ca39\\nd93aa70f-03b8-4d73-adeb-68045f7a7e7a\\nc05181ee-f6f3-4d16-85d3-9a32c7c320b3\\n6f9f3f83-0b2e-4e85-9859-181ca0bec005\\n42edc605-b361-427d-a951-3f29e38d3f25\\n0123c488-04cf-496e-809f-49a09ede5d46\\nc11439f7-324f-472e-a71b-7a73e4812270\\n8ec72307-cd99-4b58-aa81-6a0ac15d600d\\ne44c10b4-9b3c-4429-ad4f-bb6aa64fa303\\n9206c290-008b-453c-a045-80069de4f176\\n314bfe29-500c-4ebd-aa62-865a3c11d362\\nf831ee12-66d4-4edc-ab81-615cb1c896bd\\ncdd24843-37cb-4c0a-8270-0a47e7cc8ac3\\n9b403f05-5d62-4b26-9f98-338bb006431d\\nf565f941-1f6b-4a7b-92c6-730718266450\\n6e73f6c6-3dee-4c0f-93c8-d21cfd966194\\n65769cc6-5d62-4a12-b6fe-fc9791b4eaca\\n17aa8509-2dc0-4fe0-a4ec-3a3ce9f8032a\\nd59f8f06-c176-48e4-a3b2-397c4948a3b2\\nf575d869-175d-4f7a-8d3e-9eb6f35428a6\\ncc80213e-81fd-4642-89c3-51aea0650661\\naebbdf7b-dc41-4866-bfd3-6fb6d9d8e71c\\nabc073ea-6020-4528-9c87-e45f9d873d9f\\n28fabd31-bdf7-4596-8d63-cc406fece769\\n6d85539b-fc8a-4f9e-b158-3e3f90bff2c6\\n7739b23d-5938-44b7-b918-b72a7f352a7f\\nba913a36-bda3-40bd-86e8-0a9a3762b548\\n0b63afe3-8e37-4056-8ae4-aec29c9984f6\\n5cc79ef0-f8c0-4539-a33f-1505285688f3\\n37a3c501-bee1-4bd2-a0f9-6dd3c40b0a19\\nb7c67989-80b0-479b-95ea-34eeeef9d45e\\n5d9a3183-8a1c-4eb2-b81b-becdd7e98fdc\\n6ead340e-840d-4980-82d3-0f323629ecf2\\ne1bb1a82-0354-4542-9fc7-d7b50567d810\\ncd03749d-61e2-476a-859f-ae54fb9609b4\\n76856e6a-0bb8-4590-9fe7-cfe752992abd\\n3b69afcf-03d6-4455-919f-d973e2097edd\\n80cc940b-36fa-42b1-ad4c-2c022f88332c\\naff7b74b-348f-4b33-80a0-76ff353d54ce\\nedc881f2-d2bc-4e79-a3fc-1c9079a61482\\n5d6b7e73-907e-4014-91f8-b09339589585\\ne1f5942c-caac-4fd7-95f3-837b1f576e6a\\n7057acc5-1f7a-4ef0-b29b-4b2a9309ece4\\nb23f9005-471e-445c-95df-e17ecc3595db\\n804f81b1-1464-431d-82f8-dc9e113a8d38\\n88abcd34-8085-4c7d-bf42-b3efc7cc5b08\\nb4ce882d-9842-414a-a284-658e81c7c5cd\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"uuids=['e6493ad2-bf39-4edb-b08e-0da06c148635', '1966d500-0b0c-49ff-bd6e-fc3a99956910', 'c89b15b1-8e63-40f8-8824-4c3d5c857abc', '8cdbc837-723d-48da-b3ac-9b0e8ad6435c', '76cb6e5c-4c9b-4b9a-8e93-7415f022a0b1', 'ed044904-4647-4001-896d-7b56bf047616', '406fb790-f5d9-4d86-8c11-a31ea91b1249', 'b78ae923-f6d5-49f4-bcbd-1492fdb8c00b', '8efd5d95-a01c-49f6-8c63-d8fefd3dea22', 'c75e0516-6cbf-4356-b4b0-fdb9a393ecb8', '1b4dfe61-781f-4267-a8b4-3956826bb351', '75d00af3-19a1-4731-ac2b-0e7d11526aa2', '9ee91442-b110-4af2-b2f1-b5445b6208e3', 'd8a17bcf-659b-4f51-95cc-ffee2fe191f9', '13c0b5d7-2d64-483e-9ee5-fb8cf476897b', '726efd1b-e79f-4c82-8c32-f37e25bde427', '7933283e-2232-4dda-a111-bb1e0b7551e1', '05a54859-1192-4bb4-8db6-6a88d2aa0043', '52fbdd0c-1726-4cfb-8317-fb4b1559643d', 'd35c6ea5-3ad3-4979-9b19-2bda297be074', 'c76d6759-edf4-4eaa-bc64-0145471f7272', '3cc0d538-c4f5-4cab-be69-d732262e4046', '2c3cccb6-09a4-4bfa-b278-525d65b68721', 'bf2b7764-7b0e-443d-aa8d-154994108370', '9c2fc83a-2a26-4eaa-9f9f-4f71be50816d', 'c507a683-864b-4fff-8c0a-1dd6c4e695f3', '7aa4d380-cf11-4525-9edd-a2deff7306a1', 'ebd3a56a-be18-45d4-b0f7-07e454e5dba7', '32a08352-8239-422a-90ad-4f5b27f3364f', '9cb85aaf-9a12-4d3b-ad1c-2fdf6d6b57ff', '24504a2f-5956-48fd-b6d6-95e96e5a91a3', 'b01763dc-14af-4574-851b-5b2aee095dc0', 'd85c40e1-09a4-4e1a-ae8b-3ea13fcd3bfa', 'c50fd1a8-3bdc-469e-8be9-0898b45f160e', '2e1b95c2-7737-4dd5-bc4c-2c850e006f09', 'df0a0ecd-446c-4603-9cf3-42dccc3967b9', 'ddbddecc-2926-497c-9a3c-b5dab5d5e2a8', '12f440c6-b926-4024-b469-5c8d2f91b47a', 'ef8b78a0-f12c-4d78-aa57-0bd5e666d0c0', '88e9b843-065b-475e-93dd-a1d977029081', '4f39b681-f7f7-42ff-951d-46b2ce7d88c3', '829a8941-897b-4dd9-a089-b1e25617a003', '1aee1a63-d40d-4a64-96ad-f5fb89ee4909', '19b1d338-6998-4e6b-8dea-66d50d3a64d9', 'b8ca6641-591f-4dfa-b02f-2d1fd909014d', '7e95733b-43ca-44b5-a48d-a1e2b02b3c5e', '641f890f-4f20-4c3d-a4f9-7d9235d832fa', 'cd6fe347-6128-4e9d-9bfa-cc67469a67d5', 'b9ec1a5b-f353-4ade-88e5-a24e82f43250', '5f0a7764-687e-45dc-97d0-e0110414846f', '344d5909-0f53-4235-ab3e-a95faa15ae6f', 'f2763fd5-ad62-4740-9c53-5075e0f11c98', '98dab2c3-8fc4-4dba-b10e-16981e837066', '644d3404-4f16-4f6d-96c3-19d92e94ca39', 'd93aa70f-03b8-4d73-adeb-68045f7a7e7a', 'c05181ee-f6f3-4d16-85d3-9a32c7c320b3', '6f9f3f83-0b2e-4e85-9859-181ca0bec005', '42edc605-b361-427d-a951-3f29e38d3f25', '0123c488-04cf-496e-809f-49a09ede5d46', 'c11439f7-324f-472e-a71b-7a73e4812270', '8ec72307-cd99-4b58-aa81-6a0ac15d600d', 'e44c10b4-9b3c-4429-ad4f-bb6aa64fa303', '9206c290-008b-453c-a045-80069de4f176', '314bfe29-500c-4ebd-aa62-865a3c11d362', 'f831ee12-66d4-4edc-ab81-615cb1c896bd', 'cdd24843-37cb-4c0a-8270-0a47e7cc8ac3', '9b403f05-5d62-4b26-9f98-338bb006431d', 'f565f941-1f6b-4a7b-92c6-730718266450', '6e73f6c6-3dee-4c0f-93c8-d21cfd966194', '65769cc6-5d62-4a12-b6fe-fc9791b4eaca', '17aa8509-2dc0-4fe0-a4ec-3a3ce9f8032a', 'd59f8f06-c176-48e4-a3b2-397c4948a3b2', 'f575d869-175d-4f7a-8d3e-9eb6f35428a6', 'cc80213e-81fd-4642-89c3-51aea0650661', 'aebbdf7b-dc41-4866-bfd3-6fb6d9d8e71c', 'abc073ea-6020-4528-9c87-e45f9d873d9f', '28fabd31-bdf7-4596-8d63-cc406fece769', '6d85539b-fc8a-4f9e-b158-3e3f90bff2c6', '7739b23d-5938-44b7-b918-b72a7f352a7f', 'ba913a36-bda3-40bd-86e8-0a9a3762b548', '0b63afe3-8e37-4056-8ae4-aec29c9984f6', '5cc79ef0-f8c0-4539-a33f-1505285688f3', '37a3c501-bee1-4bd2-a0f9-6dd3c40b0a19', 'b7c67989-80b0-479b-95ea-34eeeef9d45e', '5d9a3183-8a1c-4eb2-b81b-becdd7e98fdc', '6ead340e-840d-4980-82d3-0f323629ecf2', 'e1bb1a82-0354-4542-9fc7-d7b50567d810', 'cd03749d-61e2-476a-859f-ae54fb9609b4', '76856e6a-0bb8-4590-9fe7-cfe752992abd', '3b69afcf-03d6-4455-919f-d973e2097edd', '80cc940b-36fa-42b1-ad4c-2c022f88332c', 'aff7b74b-348f-4b33-80a0-76ff353d54ce', 'edc881f2-d2bc-4e79-a3fc-1c9079a61482', '5d6b7e73-907e-4014-91f8-b09339589585', 'e1f5942c-caac-4fd7-95f3-837b1f576e6a', '7057acc5-1f7a-4ef0-b29b-4b2a9309ece4', 'b23f9005-471e-445c-95df-e17ecc3595db', '804f81b1-1464-431d-82f8-dc9e113a8d38', '88abcd34-8085-4c7d-bf42-b3efc7cc5b08', 'b4ce882d-9842-414a-a284-658e81c7c5cd']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for datasource_ls\n",
    "# Testing positive scenario. Saving the token in env variable\n",
    "\n",
    "def get_uuids_from_result(result) -> List[int]:\n",
    "    return [uuid for uuid in result.stdout[:-1].split(\"\\n\")]\n",
    "\n",
    "\n",
    "with set_airt_service_token_envvar():\n",
    "\n",
    "    # Without quiet\n",
    "    format_str = \"{'datablob_uuid': '{}', 'type': '{}'}\"\n",
    "    result = runner.invoke(app, [\"ls\", \"--format\", format_str])\n",
    "    display(result.stdout)\n",
    "\n",
    "    assert \"type\" in result.stdout\n",
    "    assert result.exit_code == 0\n",
    "\n",
    "    # With quiet\n",
    "    result = runner.invoke(app, [\"ls\", \"-q\"])\n",
    "    display(result.stdout)\n",
    "\n",
    "    assert result.exit_code == 0\n",
    "    uuids = get_uuids_from_result(result)\n",
    "    display(f\"{uuids=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"uuids=['1966d500-0b0c-49ff-bd6e-fc3a99956910']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"uuids=['1966d500-0b0c-49ff-bd6e-fc3a99956910', 'c89b15b1-8e63-40f8-8824-4c3d5c857abc', '8cdbc837-723d-48da-b3ac-9b0e8ad6435c', '76cb6e5c-4c9b-4b9a-8e93-7415f022a0b1', 'ed044904-4647-4001-896d-7b56bf047616', '406fb790-f5d9-4d86-8c11-a31ea91b1249', 'b78ae923-f6d5-49f4-bcbd-1492fdb8c00b', '8efd5d95-a01c-49f6-8c63-d8fefd3dea22', 'c75e0516-6cbf-4356-b4b0-fdb9a393ecb8', '1b4dfe61-781f-4267-a8b4-3956826bb351']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"uuids=['1966d500-0b0c-49ff-bd6e-fc3a99956910', 'c89b15b1-8e63-40f8-8824-4c3d5c857abc', '8cdbc837-723d-48da-b3ac-9b0e8ad6435c', '76cb6e5c-4c9b-4b9a-8e93-7415f022a0b1', 'ed044904-4647-4001-896d-7b56bf047616', '406fb790-f5d9-4d86-8c11-a31ea91b1249', 'b78ae923-f6d5-49f4-bcbd-1492fdb8c00b', '8efd5d95-a01c-49f6-8c63-d8fefd3dea22', 'c75e0516-6cbf-4356-b4b0-fdb9a393ecb8', '1b4dfe61-781f-4267-a8b4-3956826bb351', '75d00af3-19a1-4731-ac2b-0e7d11526aa2', '9ee91442-b110-4af2-b2f1-b5445b6208e3', 'd8a17bcf-659b-4f51-95cc-ffee2fe191f9', '13c0b5d7-2d64-483e-9ee5-fb8cf476897b', '726efd1b-e79f-4c82-8c32-f37e25bde427', '7933283e-2232-4dda-a111-bb1e0b7551e1', '05a54859-1192-4bb4-8db6-6a88d2aa0043', '52fbdd0c-1726-4cfb-8317-fb4b1559643d', 'd35c6ea5-3ad3-4979-9b19-2bda297be074', 'c76d6759-edf4-4eaa-bc64-0145471f7272', '3cc0d538-c4f5-4cab-be69-d732262e4046', '2c3cccb6-09a4-4bfa-b278-525d65b68721', 'bf2b7764-7b0e-443d-aa8d-154994108370', '9c2fc83a-2a26-4eaa-9f9f-4f71be50816d', 'c507a683-864b-4fff-8c0a-1dd6c4e695f3', '7aa4d380-cf11-4525-9edd-a2deff7306a1', 'ebd3a56a-be18-45d4-b0f7-07e454e5dba7', '32a08352-8239-422a-90ad-4f5b27f3364f', '9cb85aaf-9a12-4d3b-ad1c-2fdf6d6b57ff', '24504a2f-5956-48fd-b6d6-95e96e5a91a3', 'b01763dc-14af-4574-851b-5b2aee095dc0', 'd85c40e1-09a4-4e1a-ae8b-3ea13fcd3bfa', 'c50fd1a8-3bdc-469e-8be9-0898b45f160e', '2e1b95c2-7737-4dd5-bc4c-2c850e006f09', 'df0a0ecd-446c-4603-9cf3-42dccc3967b9', 'ddbddecc-2926-497c-9a3c-b5dab5d5e2a8', '12f440c6-b926-4024-b469-5c8d2f91b47a', 'ef8b78a0-f12c-4d78-aa57-0bd5e666d0c0', '88e9b843-065b-475e-93dd-a1d977029081', '4f39b681-f7f7-42ff-951d-46b2ce7d88c3', '829a8941-897b-4dd9-a089-b1e25617a003', '1aee1a63-d40d-4a64-96ad-f5fb89ee4909', '19b1d338-6998-4e6b-8dea-66d50d3a64d9', 'b8ca6641-591f-4dfa-b02f-2d1fd909014d', '7e95733b-43ca-44b5-a48d-a1e2b02b3c5e', '641f890f-4f20-4c3d-a4f9-7d9235d832fa', 'cd6fe347-6128-4e9d-9bfa-cc67469a67d5', 'b9ec1a5b-f353-4ade-88e5-a24e82f43250', '5f0a7764-687e-45dc-97d0-e0110414846f', '344d5909-0f53-4235-ab3e-a95faa15ae6f', 'f2763fd5-ad62-4740-9c53-5075e0f11c98', '98dab2c3-8fc4-4dba-b10e-16981e837066', '644d3404-4f16-4f6d-96c3-19d92e94ca39', 'd93aa70f-03b8-4d73-adeb-68045f7a7e7a', 'c05181ee-f6f3-4d16-85d3-9a32c7c320b3', '6f9f3f83-0b2e-4e85-9859-181ca0bec005', '42edc605-b361-427d-a951-3f29e38d3f25', '0123c488-04cf-496e-809f-49a09ede5d46', 'c11439f7-324f-472e-a71b-7a73e4812270', '8ec72307-cd99-4b58-aa81-6a0ac15d600d', 'e44c10b4-9b3c-4429-ad4f-bb6aa64fa303', '9206c290-008b-453c-a045-80069de4f176', '314bfe29-500c-4ebd-aa62-865a3c11d362', 'f831ee12-66d4-4edc-ab81-615cb1c896bd', 'cdd24843-37cb-4c0a-8270-0a47e7cc8ac3', '9b403f05-5d62-4b26-9f98-338bb006431d', 'f565f941-1f6b-4a7b-92c6-730718266450', '6e73f6c6-3dee-4c0f-93c8-d21cfd966194', '65769cc6-5d62-4a12-b6fe-fc9791b4eaca', '17aa8509-2dc0-4fe0-a4ec-3a3ce9f8032a', 'd59f8f06-c176-48e4-a3b2-397c4948a3b2', 'f575d869-175d-4f7a-8d3e-9eb6f35428a6', 'cc80213e-81fd-4642-89c3-51aea0650661', 'aebbdf7b-dc41-4866-bfd3-6fb6d9d8e71c', 'abc073ea-6020-4528-9c87-e45f9d873d9f', '28fabd31-bdf7-4596-8d63-cc406fece769', '6d85539b-fc8a-4f9e-b158-3e3f90bff2c6', '7739b23d-5938-44b7-b918-b72a7f352a7f', 'ba913a36-bda3-40bd-86e8-0a9a3762b548', '0b63afe3-8e37-4056-8ae4-aec29c9984f6', '5cc79ef0-f8c0-4539-a33f-1505285688f3', '37a3c501-bee1-4bd2-a0f9-6dd3c40b0a19', 'b7c67989-80b0-479b-95ea-34eeeef9d45e', '5d9a3183-8a1c-4eb2-b81b-becdd7e98fdc', '6ead340e-840d-4980-82d3-0f323629ecf2', 'e1bb1a82-0354-4542-9fc7-d7b50567d810', 'cd03749d-61e2-476a-859f-ae54fb9609b4', '76856e6a-0bb8-4590-9fe7-cfe752992abd', '3b69afcf-03d6-4455-919f-d973e2097edd', '80cc940b-36fa-42b1-ad4c-2c022f88332c', 'aff7b74b-348f-4b33-80a0-76ff353d54ce', 'edc881f2-d2bc-4e79-a3fc-1c9079a61482', '5d6b7e73-907e-4014-91f8-b09339589585', 'e1f5942c-caac-4fd7-95f3-837b1f576e6a', '7057acc5-1f7a-4ef0-b29b-4b2a9309ece4', 'b23f9005-471e-445c-95df-e17ecc3595db', '804f81b1-1464-431d-82f8-dc9e113a8d38', '88abcd34-8085-4c7d-bf42-b3efc7cc5b08', 'b4ce882d-9842-414a-a284-658e81c7c5cd', '82f5d9d2-4c3c-47d7-9c2f-610222940854', '0b975ede-77bc-4c0f-af54-05bec0abfffa', '1695441a-a08e-4737-b07f-0c757000258b', '62898778-c3d5-42c8-83a2-a4c2bc956db2', 'd49f8e11-43d1-4da8-95c7-01f376e9a1a2', '977c5b57-bb52-49d5-8217-4c71b99af0f5', '3f9b0f0c-84d6-40d9-85af-a1d7072d7d87', 'bfc879b8-e4df-4198-918b-c21f7228f5f3', 'c03cea83-6393-4be7-b50b-b772847e5b78', 'dd876efd-856d-4654-bb69-b6d9ef4249af', 'c654fa5f-e3ee-4f8a-b3a0-d8cab626390e', '4e3f7757-a872-4fcb-bb2c-234c8c35a799', '68faf988-3afe-4c93-9d53-066669055fa7', 'befb0619-1e3c-49b9-839f-93af83fd96ea', '58b9cf6a-dcdc-4b54-a985-08f1b5805618', '35032e74-c208-43d9-a479-0cb785be3d7e', 'c37cee48-cd1e-43fd-b235-f8e58ff08e45', 'd9ee6e7f-e9c0-41af-9068-840d764238b2', 'ba0540e5-67ac-4354-b701-3a5a9366041d', '03f6c0ab-542e-4c1a-b519-0cf3828c77e5', 'f0e189e7-2e28-498f-8f3a-e46295cfbbe0', 'd5475107-ffbe-471f-b7be-fe2325c0777b', '7db205c9-38f4-4fc7-b7e9-98a18aa862ac', '8769a325-cca6-4ea3-8801-5884ac502537', 'd97d0499-b7c6-483f-961a-bc6beca7d734', '36c93228-3dab-4c27-b216-cdfa63b10b20', '8382d82a-f3c1-49d3-b053-388d73dda68a', '5f4579a6-4fab-4f5e-9363-41abea96dd2e', '52fe570b-ddbf-495b-93d1-97d6b65f276a', '5d47fdf7-ac39-48e2-84e1-ed3fb248a980', '2221ab31-82db-433e-9f97-81e494e54088', '106d0e83-2129-4df8-83ad-32490b9e4da0', '91f38db9-7cea-4d5b-a72a-053ad044546b', '05f83868-b5f1-430d-b6f3-ecf81aa99476', '3c5a1784-d9cc-4098-a214-11ef8adf7769', '21660a1e-1b90-477a-a9c1-493db7def964', '518fd551-fd62-43ad-bb9c-22db6660d0de', 'b1589391-1c13-4fa2-800f-fd2d73012d1a', '4d4b37f3-01ff-4f90-9e31-a2432449d93d']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for datasource_ls\n",
    "# Testing positive scenario.\n",
    "# Testing by passing different values for  limit\n",
    "\n",
    "\n",
    "with set_airt_service_token_envvar():\n",
    "\n",
    "    for limit in [1, 10, 1000]:\n",
    "        offset = 1\n",
    "        result = runner.invoke(\n",
    "            app, [\"ls\", \"--offset\", offset, \"--limit\", limit, \"-q\"]\n",
    "        )\n",
    "\n",
    "        assert result.exit_code == 0\n",
    "\n",
    "        uuids = get_uuids_from_result(result)\n",
    "        display(f\"{uuids=}\")\n",
    "        assert limit >= len(uuids) >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datablob_uuid    datasource_uuids    type    source    region    cloud_provider    tags    pulled_on    folder_size    ready\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for datasource_ls\n",
    "# Testing positive scenario.\n",
    "# Testing by passing large value for offset.\n",
    "\n",
    "with set_airt_service_token_envvar():\n",
    "\n",
    "    limit = 10\n",
    "    offset = 1_000_000\n",
    "    result = runner.invoke(app, [\"ls\", \"--offset\", offset, \"--limit\", limit])\n",
    "\n",
    "    assert result.exit_code == 0\n",
    "\n",
    "    display(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "\n",
    "@app.command()\n",
    "@helper.display_formated_table\n",
    "@helper.requires_auth_token\n",
    "def rm(\n",
    "    uuid: str = typer.Argument(\n",
    "        ...,\n",
    "        help=\"Datablob uuid.\",\n",
    "    ),\n",
    "    format: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--format\",\n",
    "        \"-f\",\n",
    "        help=\"Format output and show only the given column(s) values.\"\n",
    "    ),\n",
    "    quiet: bool = typer.Option(\n",
    "        False,\n",
    "        \"--quiet\",\n",
    "        \"-q\",\n",
    "        help=\"Output the deleted datablob uuid only.\",\n",
    "    ),\n",
    "    debug: bool = typer.Option(\n",
    "        False,\n",
    "        \"--debug\",\n",
    "        \"-d\",\n",
    "        help=\"Set logger level to DEBUG and output everything.\",\n",
    "    ),\n",
    ") -> Dict[\"str\", Union[pd.DataFrame, str]]:\n",
    "    \"\"\"Delete a datablob from the server.\"\"\"\n",
    "\n",
    "    from airt.client import DataBlob\n",
    "    \n",
    "    db = DataBlob(uuid=uuid)\n",
    "    df = db.delete()\n",
    "    \n",
    "    df['pulled_on'] = helper.humanize_date(df['pulled_on'])\n",
    "    df['folder_size'] = helper.humanize_size(df['folder_size'])\n",
    "    \n",
    "    return {\"df\": df, \"quite_column_name\": \"datablob_uuid\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Usage: root rm [OPTIONS] UUID\\n\\n  Delete a datablob from the server.\\n\\nArguments:\\n  UUID  Datablob uuid.  [required]\\n\\nOptions:\\n  -f, --format TEXT  Format output and show only the given column(s) values.\\n  -q, --quiet        Output the deleted datablob uuid only.\\n  -d, --debug        Set logger level to DEBUG and output everything.\\n  --help             Show this message and exit.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert_has_help([\"rm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5f4579a6-4fab-4f5e-9363-41abea96dd2e'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['e6493ad2-bf39-4edb-b08e-0da06c148635',\n",
       " '1966d500-0b0c-49ff-bd6e-fc3a99956910',\n",
       " 'c89b15b1-8e63-40f8-8824-4c3d5c857abc',\n",
       " '8cdbc837-723d-48da-b3ac-9b0e8ad6435c',\n",
       " '76cb6e5c-4c9b-4b9a-8e93-7415f022a0b1',\n",
       " 'ed044904-4647-4001-896d-7b56bf047616',\n",
       " '406fb790-f5d9-4d86-8c11-a31ea91b1249',\n",
       " 'b78ae923-f6d5-49f4-bcbd-1492fdb8c00b',\n",
       " '8efd5d95-a01c-49f6-8c63-d8fefd3dea22',\n",
       " 'c75e0516-6cbf-4356-b4b0-fdb9a393ecb8',\n",
       " '1b4dfe61-781f-4267-a8b4-3956826bb351',\n",
       " '75d00af3-19a1-4731-ac2b-0e7d11526aa2',\n",
       " '9ee91442-b110-4af2-b2f1-b5445b6208e3',\n",
       " 'd8a17bcf-659b-4f51-95cc-ffee2fe191f9',\n",
       " '13c0b5d7-2d64-483e-9ee5-fb8cf476897b',\n",
       " '726efd1b-e79f-4c82-8c32-f37e25bde427',\n",
       " '7933283e-2232-4dda-a111-bb1e0b7551e1',\n",
       " '05a54859-1192-4bb4-8db6-6a88d2aa0043',\n",
       " '52fbdd0c-1726-4cfb-8317-fb4b1559643d',\n",
       " 'd35c6ea5-3ad3-4979-9b19-2bda297be074',\n",
       " 'c76d6759-edf4-4eaa-bc64-0145471f7272',\n",
       " '3cc0d538-c4f5-4cab-be69-d732262e4046',\n",
       " '2c3cccb6-09a4-4bfa-b278-525d65b68721',\n",
       " 'bf2b7764-7b0e-443d-aa8d-154994108370',\n",
       " '9c2fc83a-2a26-4eaa-9f9f-4f71be50816d',\n",
       " 'c507a683-864b-4fff-8c0a-1dd6c4e695f3',\n",
       " '7aa4d380-cf11-4525-9edd-a2deff7306a1',\n",
       " 'ebd3a56a-be18-45d4-b0f7-07e454e5dba7',\n",
       " '32a08352-8239-422a-90ad-4f5b27f3364f',\n",
       " '9cb85aaf-9a12-4d3b-ad1c-2fdf6d6b57ff',\n",
       " '24504a2f-5956-48fd-b6d6-95e96e5a91a3',\n",
       " 'b01763dc-14af-4574-851b-5b2aee095dc0',\n",
       " 'd85c40e1-09a4-4e1a-ae8b-3ea13fcd3bfa',\n",
       " 'c50fd1a8-3bdc-469e-8be9-0898b45f160e',\n",
       " '2e1b95c2-7737-4dd5-bc4c-2c850e006f09',\n",
       " 'df0a0ecd-446c-4603-9cf3-42dccc3967b9',\n",
       " 'ddbddecc-2926-497c-9a3c-b5dab5d5e2a8',\n",
       " '12f440c6-b926-4024-b469-5c8d2f91b47a',\n",
       " 'ef8b78a0-f12c-4d78-aa57-0bd5e666d0c0',\n",
       " '88e9b843-065b-475e-93dd-a1d977029081',\n",
       " '4f39b681-f7f7-42ff-951d-46b2ce7d88c3',\n",
       " '829a8941-897b-4dd9-a089-b1e25617a003',\n",
       " '1aee1a63-d40d-4a64-96ad-f5fb89ee4909',\n",
       " '19b1d338-6998-4e6b-8dea-66d50d3a64d9',\n",
       " 'b8ca6641-591f-4dfa-b02f-2d1fd909014d',\n",
       " '7e95733b-43ca-44b5-a48d-a1e2b02b3c5e',\n",
       " '641f890f-4f20-4c3d-a4f9-7d9235d832fa',\n",
       " 'cd6fe347-6128-4e9d-9bfa-cc67469a67d5',\n",
       " 'b9ec1a5b-f353-4ade-88e5-a24e82f43250',\n",
       " '5f0a7764-687e-45dc-97d0-e0110414846f',\n",
       " '344d5909-0f53-4235-ab3e-a95faa15ae6f',\n",
       " 'f2763fd5-ad62-4740-9c53-5075e0f11c98',\n",
       " '98dab2c3-8fc4-4dba-b10e-16981e837066',\n",
       " '644d3404-4f16-4f6d-96c3-19d92e94ca39',\n",
       " 'd93aa70f-03b8-4d73-adeb-68045f7a7e7a',\n",
       " 'c05181ee-f6f3-4d16-85d3-9a32c7c320b3',\n",
       " '6f9f3f83-0b2e-4e85-9859-181ca0bec005',\n",
       " '42edc605-b361-427d-a951-3f29e38d3f25',\n",
       " '0123c488-04cf-496e-809f-49a09ede5d46',\n",
       " 'c11439f7-324f-472e-a71b-7a73e4812270',\n",
       " '8ec72307-cd99-4b58-aa81-6a0ac15d600d',\n",
       " 'e44c10b4-9b3c-4429-ad4f-bb6aa64fa303',\n",
       " '9206c290-008b-453c-a045-80069de4f176',\n",
       " '314bfe29-500c-4ebd-aa62-865a3c11d362',\n",
       " 'f831ee12-66d4-4edc-ab81-615cb1c896bd',\n",
       " 'cdd24843-37cb-4c0a-8270-0a47e7cc8ac3',\n",
       " '9b403f05-5d62-4b26-9f98-338bb006431d',\n",
       " 'f565f941-1f6b-4a7b-92c6-730718266450',\n",
       " '6e73f6c6-3dee-4c0f-93c8-d21cfd966194',\n",
       " '65769cc6-5d62-4a12-b6fe-fc9791b4eaca',\n",
       " '17aa8509-2dc0-4fe0-a4ec-3a3ce9f8032a',\n",
       " 'd59f8f06-c176-48e4-a3b2-397c4948a3b2',\n",
       " 'f575d869-175d-4f7a-8d3e-9eb6f35428a6',\n",
       " 'cc80213e-81fd-4642-89c3-51aea0650661',\n",
       " 'aebbdf7b-dc41-4866-bfd3-6fb6d9d8e71c',\n",
       " 'abc073ea-6020-4528-9c87-e45f9d873d9f',\n",
       " '28fabd31-bdf7-4596-8d63-cc406fece769',\n",
       " '6d85539b-fc8a-4f9e-b158-3e3f90bff2c6',\n",
       " '7739b23d-5938-44b7-b918-b72a7f352a7f',\n",
       " 'ba913a36-bda3-40bd-86e8-0a9a3762b548',\n",
       " '0b63afe3-8e37-4056-8ae4-aec29c9984f6',\n",
       " '5cc79ef0-f8c0-4539-a33f-1505285688f3',\n",
       " '37a3c501-bee1-4bd2-a0f9-6dd3c40b0a19',\n",
       " 'b7c67989-80b0-479b-95ea-34eeeef9d45e',\n",
       " '5d9a3183-8a1c-4eb2-b81b-becdd7e98fdc',\n",
       " '6ead340e-840d-4980-82d3-0f323629ecf2',\n",
       " 'e1bb1a82-0354-4542-9fc7-d7b50567d810',\n",
       " 'cd03749d-61e2-476a-859f-ae54fb9609b4',\n",
       " '76856e6a-0bb8-4590-9fe7-cfe752992abd',\n",
       " '3b69afcf-03d6-4455-919f-d973e2097edd',\n",
       " '80cc940b-36fa-42b1-ad4c-2c022f88332c',\n",
       " 'aff7b74b-348f-4b33-80a0-76ff353d54ce',\n",
       " 'edc881f2-d2bc-4e79-a3fc-1c9079a61482',\n",
       " '5d6b7e73-907e-4014-91f8-b09339589585',\n",
       " 'e1f5942c-caac-4fd7-95f3-837b1f576e6a',\n",
       " '7057acc5-1f7a-4ef0-b29b-4b2a9309ece4',\n",
       " 'b23f9005-471e-445c-95df-e17ecc3595db',\n",
       " '804f81b1-1464-431d-82f8-dc9e113a8d38',\n",
       " '88abcd34-8085-4c7d-bf42-b3efc7cc5b08',\n",
       " 'b4ce882d-9842-414a-a284-658e81c7c5cd']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'b7500d61-9011-4db6-a86b-a3c521f2ed3e\\n98161b86-953e-4a4f-8fc6-a8f0ab6184c0\\nd8bcafc6-b2c1-4607-8a35-574f5e621229\\nc0ea8dda-38fb-46bb-8e21-09bfc46d9022\\n84b81d57-c8ca-4a55-a280-d4f164dc5fd9\\n44974a95-4e06-4189-b4fa-b1c6970c6e49\\n9f31dffc-9762-4c7d-b635-217fa5ddf32a\\n9b2d5fd9-845c-4b02-bfe4-bc1a636c4613\\n68c873c1-2df7-4552-84b8-b54c28953a82\\n5f4579a6-4fab-4f5e-9363-41abea96dd2e\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"disabled_db_uuids=['b7500d61-9011-4db6-a86b-a3c521f2ed3e', '98161b86-953e-4a4f-8fc6-a8f0ab6184c0', 'd8bcafc6-b2c1-4607-8a35-574f5e621229', 'c0ea8dda-38fb-46bb-8e21-09bfc46d9022', '84b81d57-c8ca-4a55-a280-d4f164dc5fd9', '44974a95-4e06-4189-b4fa-b1c6970c6e49', '9f31dffc-9762-4c7d-b635-217fa5ddf32a', '9b2d5fd9-845c-4b02-bfe4-bc1a636c4613', '68c873c1-2df7-4552-84b8-b54c28953a82', '5f4579a6-4fab-4f5e-9363-41abea96dd2e']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Error: The datablob has already been deleted.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Error: The datablob has already been deleted.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for datasource rm\n",
    "# Testing positive scenario with quite\n",
    "\n",
    "with set_airt_service_token_envvar():\n",
    "    with generate_db() as db:\n",
    "        db_uuid = db.uuid\n",
    "\n",
    "        # Deleting the created data source from the server\n",
    "        result = runner.invoke(app, [\"rm\", db_uuid, \"-q\"])\n",
    "        deleted_uuid = result.stdout[:-1]\n",
    "\n",
    "        display(deleted_uuid)\n",
    "\n",
    "        assert result.exit_code == 0\n",
    "        assert deleted_uuid == db_uuid\n",
    "\n",
    "        # List the existing data source ids in server and make sure the deleted id is not present in the server\n",
    "        format_str = \"{'datablob_uuid': '{}'}\"\n",
    "        ls_result = runner.invoke(app, [\"ls\", \"--format\", format_str])\n",
    "        ls_uuids = get_uuids_from_result(ls_result)\n",
    "\n",
    "        display(ls_uuids)\n",
    "        assert deleted_uuid not in ls_uuids\n",
    "        \n",
    "        # ls with quiet and disabled = True\n",
    "        result = runner.invoke(app, [\"ls\", \"--disabled\", \"-q\"])\n",
    "\n",
    "        display(result.stdout)\n",
    "        assert result.exit_code == 0\n",
    "\n",
    "        disabled_db_uuids = get_uuids_from_result(result)\n",
    "\n",
    "        display(f\"{disabled_db_uuids=}\")\n",
    "        assert deleted_uuid in disabled_db_uuids\n",
    "\n",
    "        # Testing negative scenario. Deleting already deleted data source\n",
    "        result = runner.invoke(app, [\"rm\", deleted_uuid, \"-q\"])\n",
    "        display(result.stdout)\n",
    "        assert result.exit_code == 1\n",
    "\n",
    "        # Testing negative scenario. Getting the details of the deleted data source\n",
    "        result = runner.invoke(app, [\"details\", deleted_uuid])\n",
    "        display(result.stdout)\n",
    "        assert result.exit_code == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Error: The datablob uuid is incorrect. Please try again.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for datasource rm\n",
    "# Testing negative scenario. Deleting invalid data source\n",
    "with set_airt_service_token_envvar():\n",
    "    # Testing negative scenario. Deleting already deleted data source\n",
    "    result = runner.invoke(app, [\"rm\", RANDOM_UUID_FOR_TESTING, \"-q\"])\n",
    "\n",
    "    display(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "\n",
    "@app.command()\n",
    "@helper.display_formated_table\n",
    "@helper.requires_auth_token\n",
    "def tag(\n",
    "    uuid: str = typer.Option(\n",
    "        ...,\n",
    "        \"--datablob_uuid\",\n",
    "        \"-uuid\",\n",
    "        help=\"Datablob uuid in the server.\",\n",
    "    ),\n",
    "    name: str = typer.Option(\n",
    "        ...,\n",
    "        \"--name\",\n",
    "        \"-n\",\n",
    "        help=\"A string to tag the datablob.\",\n",
    "    ),\n",
    "    format: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--format\",\n",
    "        \"-f\",\n",
    "        help=\"Format output and show only the given column(s) values.\"\n",
    "    ),\n",
    "    debug: bool = typer.Option(\n",
    "        False,\n",
    "        \"--debug\",\n",
    "        \"-d\",\n",
    "        help=\"Set logger level to DEBUG and output everything.\",\n",
    "    ),\n",
    ") -> Dict[\"str\", Union[pd.DataFrame, str]]:\n",
    "    \"\"\"Tag an existing datablob in the server.\"\"\"\n",
    "\n",
    "    from airt.client import DataBlob\n",
    "    \n",
    "    db = DataBlob(uuid=uuid)\n",
    "    df = db.tag(name=name)\n",
    "    \n",
    "    df['pulled_on'] = helper.humanize_date(df['pulled_on'])\n",
    "    df['folder_size'] = helper.humanize_size(df['folder_size'])\n",
    "    \n",
    "    return {\"df\": df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Usage: root tag [OPTIONS]\\n\\n  Tag an existing datablob in the server.\\n\\nOptions:\\n  -uuid, --datablob_uuid TEXT  Datablob uuid in the server.  [required]\\n  -n, --name TEXT              A string to tag the datablob.  [required]\\n  -f, --format TEXT            Format output and show only the given column(s)\\n                               values.\\n  -d, --debug                  Set logger level to DEBUG and output everything.\\n  --help                       Show this message and exit.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert_has_help([\"tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"_db.uuid='615b3357-e598-4a3e-a303-4483e6b3a092'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:15<00:00, 15.18s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'datablob_uuid                         tags\\n615b3357-e598-4a3e-a303-4483e6b3a092  latest, v1.1.0\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for tag\n",
    "# Testing positive scenario\n",
    "\n",
    "with set_airt_service_token_envvar():\n",
    "    with generate_db(force_create=True) as db:\n",
    "        db_uuid = db.uuid\n",
    "\n",
    "        # Tag the data source\n",
    "        format_str = \"{'datablob_uuid': '{}', 'tags': '{}'}\"\n",
    "        result = runner.invoke(app, [\"tag\", \"-uuid\", db_uuid, \"-n\", \"v1.1.0\", \"--format\", format_str])\n",
    "\n",
    "        display(result.stdout)\n",
    "\n",
    "        assert result.exit_code == 0\n",
    "        assert \"v1.1.0\" in str(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "\n",
    "@app.command(\"from-local\")\n",
    "@helper.requires_auth_token\n",
    "def from_local(\n",
    "    path: str = typer.Option(\n",
    "        ...,\n",
    "        \"--path\",\n",
    "        \"-p\",\n",
    "        help=\"The relative or absolute path to a local CSV/parquet file or to a directory containing the CSV/parquet files.\",\n",
    "    ),\n",
    "    cloud_provider: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--cloud-provider\",\n",
    "        \"-cp\",\n",
    "        help=\"The destination cloud storage provider's name to store the datablob. Currently, the API only supports **aws** and **azure** as cloud storage providers. If **None** (default value), then **aws**  will be used as the cloud storage provider.\",\n",
    "    ),\n",
    "    region: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--region\",\n",
    "        \"-r\",\n",
    "        help=\"The destination cloud provider's region to save your datablob. If **None** (default value) then the default region will be assigned based on the cloud provider. \" \\\n",
    "            \"In the case of **aws**, **eu-west-1** will be used and in the case of **azure**, **westeurope** will be used. \" \\\n",
    "            \"The supported AWS regions are: ap-northeast-1, ap-northeast-2, ap-south-1, ap-southeast-1, ap-southeast-2, ca-central-1, eu-central-1, \" \\\n",
    "            \"eu-north-1, eu-west-1, eu-west-2, eu-west-3, sa-east-1, us-east-1, us-east-2, us-west-1, us-west-2. The supported Azure Blob Storage \" \\\n",
    "            \"regions are: australiacentral, australiacentral2, australiaeast, australiasoutheast, brazilsouth, canadacentral, canadaeast, centralindia, \" \\\n",
    "            \"centralus, eastasia, eastus, eastus2, francecentral, francesouth, germanynorth, germanywestcentral, japaneast, japanwest, koreacentral, koreasouth, \" \\\n",
    "            \"northcentralus, northeurope, norwayeast, norwaywest, southafricanorth, southafricawest, southcentralus, southeastasia, southindia, switzerlandnorth, \" \\\n",
    "            \"switzerlandwest, uaecentral, uaenorth, uksouth, ukwest, westcentralus, westeurope, westindia, westus, westus2.\"\n",
    "\n",
    "    ),\n",
    "    tag: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--tag\",\n",
    "        \"-t\",\n",
    "        help=\"A string to tag the datablob. If not passed, then the tag **latest** will be assigned to the datablob.\",\n",
    "    ),\n",
    "    quiet: bool = typer.Option(\n",
    "        False,\n",
    "        \"--quiet\",\n",
    "        \"-q\",\n",
    "        help=\"Output data id only.\",\n",
    "    ),\n",
    "    debug: bool = typer.Option(\n",
    "        False,\n",
    "        \"--debug\",\n",
    "        \"-d\",\n",
    "        help=\"Set logger level to DEBUG and output everything.\",\n",
    "    ),\n",
    ") -> None:\n",
    "    \"\"\"Create and return a datablob from local csv file.\n",
    "    \n",
    "    The API currently allows users to create datablobs from CSV or Parquet files. We intend to support additional file formats in future releases.\n",
    "    \"\"\"\n",
    "\n",
    "    from airt.client import DataBlob\n",
    "\n",
    "    if quiet:\n",
    "        db = DataBlob.from_local(path=path, cloud_provider=cloud_provider, region=region, tag=tag, show_progress=False)\n",
    "        typer.echo(f\"{db.uuid}\")\n",
    "    else:\n",
    "        db = DataBlob.from_local(path=path, cloud_provider=cloud_provider, region=region, tag=tag)\n",
    "        typer.echo(f\"Successfully pulled the datablob uuid: {db.uuid}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Usage: root from-local [OPTIONS]\\n\\n  Create and return a datablob from local csv file.\\n\\n  The API currently allows users to create datablobs from CSV or Parquet files.\\n  We intend to support additional file formats in future releases.\\n\\nOptions:\\n  -p, --path TEXT             The relative or absolute path to a local\\n                              CSV/parquet file or to a directory containing the\\n                              CSV/parquet files.  [required]\\n  -cp, --cloud-provider TEXT  The destination cloud storage provider's name to\\n                              store the datablob. Currently, the API only\\n                              supports **aws** and **azure** as cloud storage\\n                              providers. If **None** (default value), then\\n                              **aws**  will be used as the cloud storage\\n                              provider.\\n  -r, --region TEXT           The destination cloud provider's region to save\\n                              your datablob. If **None** (default value) then\\n                              the default region will be assigned based on the\\n                              cloud provider. In the case of **aws**, **eu-\\n                              west-1** will be used and in the case of\\n                              **azure**, **westeurope** will be used. The\\n                              supported AWS regions are: ap-northeast-1, ap-\\n                              northeast-2, ap-south-1, ap-southeast-1, ap-\\n                              southeast-2, ca-central-1, eu-central-1, eu-\\n                              north-1, eu-west-1, eu-west-2, eu-west-3, sa-\\n                              east-1, us-east-1, us-east-2, us-west-1, us-\\n                              west-2. The supported Azure Blob Storage regions\\n                              are: australiacentral, australiacentral2,\\n                              australiaeast, australiasoutheast, brazilsouth,\\n                              canadacentral, canadaeast, centralindia,\\n                              centralus, eastasia, eastus, eastus2,\\n                              francecentral, francesouth, germanynorth,\\n                              germanywestcentral, japaneast, japanwest,\\n                              koreacentral, koreasouth, northcentralus,\\n                              northeurope, norwayeast, norwaywest,\\n                              southafricanorth, southafricawest, southcentralus,\\n                              southeastasia, southindia, switzerlandnorth,\\n                              switzerlandwest, uaecentral, uaenorth, uksouth,\\n                              ukwest, westcentralus, westeurope, westindia,\\n                              westus, westus2.\\n  -t, --tag TEXT              A string to tag the datablob. If not passed, then\\n                              the tag **latest** will be assigned to the\\n                              datablob.\\n  -q, --quiet                 Output data id only.\\n  -d, --debug                 Set logger level to DEBUG and output everything.\\n  --help                      Show this message and exit.\\n\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert_has_help([\"from-local\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/_common_metadata to ../../../tmp/test_s3_download_m9lr4eeg/parquet/_common_metadata\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/_metadata to ../../../tmp/test_s3_download_m9lr4eeg/parquet/_metadata\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.0.parquet to ../../../tmp/test_s3_download_m9lr4eeg/parquet/part.0.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.13.parquet to ../../../tmp/test_s3_download_m9lr4eeg/parquet/part.13.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.15.parquet to ../../../tmp/test_s3_download_m9lr4eeg/parquet/part.15.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.10.parquet to ../../../tmp/test_s3_download_m9lr4eeg/parquet/part.10.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.14.parquet to ../../../tmp/test_s3_download_m9lr4eeg/parquet/part.14.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.17.parquet to ../../../tmp/test_s3_download_m9lr4eeg/parquet/part.17.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.16.parquet to ../../../tmp/test_s3_download_m9lr4eeg/parquet/part.16.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.11.parquet to ../../../tmp/test_s3_download_m9lr4eeg/parquet/part.11.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.4.parquet to ../../../tmp/test_s3_download_m9lr4eeg/parquet/part.4.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.18.parquet to ../../../tmp/test_s3_download_m9lr4eeg/parquet/part.18.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.5.parquet to ../../../tmp/test_s3_download_m9lr4eeg/parquet/part.5.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.19.parquet to ../../../tmp/test_s3_download_m9lr4eeg/parquet/part.19.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.3.parquet to ../../../tmp/test_s3_download_m9lr4eeg/parquet/part.3.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.1.parquet to ../../../tmp/test_s3_download_m9lr4eeg/parquet/part.1.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.6.parquet to ../../../tmp/test_s3_download_m9lr4eeg/parquet/part.6.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.7.parquet to ../../../tmp/test_s3_download_m9lr4eeg/parquet/part.7.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.8.parquet to ../../../tmp/test_s3_download_m9lr4eeg/parquet/part.8.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.9.parquet to ../../../tmp/test_s3_download_m9lr4eeg/parquet/part.9.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.12.parquet to ../../../tmp/test_s3_download_m9lr4eeg/parquet/part.12.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.2.parquet to ../../../tmp/test_s3_download_m9lr4eeg/parquet/part.2.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Path('/tmp/test_s3_download_m9lr4eeg/csv/file-1.csv'),\n",
       " Path('/tmp/test_s3_download_m9lr4eeg/csv/file-15.csv'),\n",
       " Path('/tmp/test_s3_download_m9lr4eeg/csv/file-6.csv'),\n",
       " Path('/tmp/test_s3_download_m9lr4eeg/csv/file-8.csv'),\n",
       " Path('/tmp/test_s3_download_m9lr4eeg/csv/file-17.csv'),\n",
       " Path('/tmp/test_s3_download_m9lr4eeg/csv/file-19.csv'),\n",
       " Path('/tmp/test_s3_download_m9lr4eeg/csv/file-18.csv'),\n",
       " Path('/tmp/test_s3_download_m9lr4eeg/csv/file-5.csv'),\n",
       " Path('/tmp/test_s3_download_m9lr4eeg/csv/file-14.csv'),\n",
       " Path('/tmp/test_s3_download_m9lr4eeg/csv/file-0.csv'),\n",
       " Path('/tmp/test_s3_download_m9lr4eeg/csv/file-10.csv'),\n",
       " Path('/tmp/test_s3_download_m9lr4eeg/csv/file-7.csv'),\n",
       " Path('/tmp/test_s3_download_m9lr4eeg/csv/file-12.csv'),\n",
       " Path('/tmp/test_s3_download_m9lr4eeg/csv/file-4.csv'),\n",
       " Path('/tmp/test_s3_download_m9lr4eeg/csv/file-2.csv'),\n",
       " Path('/tmp/test_s3_download_m9lr4eeg/csv/file-3.csv'),\n",
       " Path('/tmp/test_s3_download_m9lr4eeg/csv/file-16.csv'),\n",
       " Path('/tmp/test_s3_download_m9lr4eeg/csv/file-13.csv'),\n",
       " Path('/tmp/test_s3_download_m9lr4eeg/csv/file-9.csv'),\n",
       " Path('/tmp/test_s3_download_m9lr4eeg/csv/file-11.csv')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\r  0%|          | 0/20 [00:00<?, ?it/s]\\r  5%|▌         | 1/20 [00:01<00:22,  1.20s/it]\\r 10%|█         | 2/20 [00:02<00:21,  1.19s/it]\\r 15%|█▌        | 3/20 [00:03<00:19,  1.14s/it]\\r 20%|██        | 4/20 [00:04<00:18,  1.13s/it]\\r 25%|██▌       | 5/20 [00:05<00:16,  1.12s/it]\\r 30%|███       | 6/20 [00:06<00:15,  1.10s/it]\\r 35%|███▌      | 7/20 [00:07<00:14,  1.13s/it]\\r 40%|████      | 8/20 [00:08<00:13,  1.10s/it]\\r 45%|████▌     | 9/20 [00:10<00:12,  1.10s/it]\\r 50%|█████     | 10/20 [00:11<00:10,  1.10s/it]\\r 55%|█████▌    | 11/20 [00:12<00:09,  1.09s/it]\\r 60%|██████    | 12/20 [00:13<00:08,  1.12s/it]\\r 65%|██████▌   | 13/20 [00:14<00:07,  1.11s/it]\\r 70%|███████   | 14/20 [00:15<00:06,  1.13s/it]\\r 75%|███████▌  | 15/20 [00:16<00:05,  1.13s/it]\\r 80%|████████  | 16/20 [00:18<00:04,  1.17s/it]\\r 85%|████████▌ | 17/20 [00:19<00:03,  1.15s/it]\\r 90%|█████████ | 18/20 [00:20<00:02,  1.15s/it]\\r 95%|█████████▌| 19/20 [00:21<00:01,  1.15s/it]\\r100%|██████████| 20/20 [00:22<00:00,  1.12s/it]\\r100%|██████████| 20/20 [00:22<00:00,  1.13s/it]\\nSuccessfully pulled the datablob uuid: f3663343-e308-4569-8082-4525a113fa07.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'b68d348a-0001-48ee-b04a-fc51ca83061b'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'datablob_uuid                         datasource_uuids    type    source                                    region     cloud_provider    tags    pulled_on    folder_size    user_uuid                             error    disabled    ready\\nb68d348a-0001-48ee-b04a-fc51ca83061b  <none>              local   local:/tmp/test_s3_download_m9lr4eeg/csv  eu-west-1  aws               latest  None         unknown        06a385d1-66a1-4ffc-8306-7f5821902fcc  <none>   False       False\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'temp_dir.exists()=False'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| include: false\n",
    "\n",
    "# Helper function to download a sample csv file into the temp directory for testing Datablob local csv command\n",
    "\n",
    "def get_test_csv_path() -> Path:\n",
    "    \"\"\"Downloads the account_312571_events from the s3 bucket and stores it in temp folder. \n",
    "    Finally converts the downloaded account_312571_events files to a csv file and returns the\n",
    "    path of the temp folder and the temp csv file.\n",
    "    \"\"\"\n",
    "    temp_dirpath = Path(tempfile.mkdtemp(prefix=\"test_s3_download_\"))\n",
    "\n",
    "    !aws s3 sync {TEST_S3_URI} {temp_dirpath / \"parquet\"}\n",
    "\n",
    "    parquet_path = Path(temp_dirpath / \"parquet\")\n",
    "    csv_dirpath = Path(temp_dirpath / \"csv\")\n",
    "    os.mkdir(csv_dirpath)\n",
    "    \n",
    "    for i, f in enumerate(list(parquet_path.glob(\"*.parquet\"))):\n",
    "        df = pd.read_parquet(f)\n",
    "        df.to_csv(csv_dirpath / f\"file-{i}.csv\", index=False)\n",
    "    \n",
    "    display(list(csv_dirpath.glob(\"*\")))\n",
    "\n",
    "    return temp_dirpath, csv_dirpath\n",
    "\n",
    "# Testing multiple files upload.\n",
    "\n",
    "# Create temp directory\n",
    "temp_dir, csv_dirpath = get_test_csv_path()\n",
    "\n",
    "# Creating a new datasource\n",
    "cmd = [\n",
    "    \"from-local\",\n",
    "    \"--path\",\n",
    "    f\"{csv_dirpath}\"\n",
    "]\n",
    "\n",
    "cmd_q = [\n",
    "    \"from-local\",\n",
    "    \"--path\",\n",
    "    f\"{csv_dirpath}\",\n",
    "    \"-q\"\n",
    "]\n",
    "\n",
    "with set_airt_service_token_envvar():\n",
    "    \n",
    "    # Without quiet\n",
    "    result = runner.invoke(app, cmd)\n",
    "    \n",
    "    display(result.stdout)\n",
    "    assert \"Successfully pulled the datablob uuid:\" in str(result.stdout)\n",
    "    \n",
    "    # With quiet\n",
    "    result = runner.invoke(app, cmd_q)\n",
    "    db_uuid = result.stdout[:-1]\n",
    "    display(db_uuid)\n",
    "    assert len(remove_hypens_from_id(db_uuid)) == 32\n",
    "    \n",
    "    result = runner.invoke(app, [\"details\", db_uuid])\n",
    "    display(result.stdout)\n",
    "    assert result.exit_code == 0\n",
    "    assert \"eu-west-1\" in result.stdout\n",
    "\n",
    "# Deleting the temp directory\n",
    "shutil.rmtree(temp_dir)\n",
    "display(f\"{temp_dir.exists()=}\")\n",
    "assert not temp_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/_common_metadata to ../../../tmp/test_s3_download_lwo2sndj/parquet/_common_metadata\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/_metadata to ../../../tmp/test_s3_download_lwo2sndj/parquet/_metadata\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.0.parquet to ../../../tmp/test_s3_download_lwo2sndj/parquet/part.0.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.1.parquet to ../../../tmp/test_s3_download_lwo2sndj/parquet/part.1.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.10.parquet to ../../../tmp/test_s3_download_lwo2sndj/parquet/part.10.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.15.parquet to ../../../tmp/test_s3_download_lwo2sndj/parquet/part.15.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.12.parquet to ../../../tmp/test_s3_download_lwo2sndj/parquet/part.12.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.13.parquet to ../../../tmp/test_s3_download_lwo2sndj/parquet/part.13.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.11.parquet to ../../../tmp/test_s3_download_lwo2sndj/parquet/part.11.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.14.parquet to ../../../tmp/test_s3_download_lwo2sndj/parquet/part.14.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.17.parquet to ../../../tmp/test_s3_download_lwo2sndj/parquet/part.17.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.16.parquet to ../../../tmp/test_s3_download_lwo2sndj/parquet/part.16.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.18.parquet to ../../../tmp/test_s3_download_lwo2sndj/parquet/part.18.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.4.parquet to ../../../tmp/test_s3_download_lwo2sndj/parquet/part.4.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.19.parquet to ../../../tmp/test_s3_download_lwo2sndj/parquet/part.19.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.2.parquet to ../../../tmp/test_s3_download_lwo2sndj/parquet/part.2.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.3.parquet to ../../../tmp/test_s3_download_lwo2sndj/parquet/part.3.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.5.parquet to ../../../tmp/test_s3_download_lwo2sndj/parquet/part.5.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.7.parquet to ../../../tmp/test_s3_download_lwo2sndj/parquet/part.7.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.8.parquet to ../../../tmp/test_s3_download_lwo2sndj/parquet/part.8.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.6.parquet to ../../../tmp/test_s3_download_lwo2sndj/parquet/part.6.parquet\n",
      "download: s3://test-airt-service/ecommerce_behavior_notebooks/part.9.parquet to ../../../tmp/test_s3_download_lwo2sndj/parquet/part.9.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Path('/tmp/test_s3_download_lwo2sndj/csv/file-1.csv'),\n",
       " Path('/tmp/test_s3_download_lwo2sndj/csv/file-15.csv'),\n",
       " Path('/tmp/test_s3_download_lwo2sndj/csv/file-6.csv'),\n",
       " Path('/tmp/test_s3_download_lwo2sndj/csv/file-8.csv'),\n",
       " Path('/tmp/test_s3_download_lwo2sndj/csv/file-17.csv'),\n",
       " Path('/tmp/test_s3_download_lwo2sndj/csv/file-19.csv'),\n",
       " Path('/tmp/test_s3_download_lwo2sndj/csv/file-18.csv'),\n",
       " Path('/tmp/test_s3_download_lwo2sndj/csv/file-5.csv'),\n",
       " Path('/tmp/test_s3_download_lwo2sndj/csv/file-14.csv'),\n",
       " Path('/tmp/test_s3_download_lwo2sndj/csv/file-0.csv'),\n",
       " Path('/tmp/test_s3_download_lwo2sndj/csv/file-10.csv'),\n",
       " Path('/tmp/test_s3_download_lwo2sndj/csv/file-7.csv'),\n",
       " Path('/tmp/test_s3_download_lwo2sndj/csv/file-12.csv'),\n",
       " Path('/tmp/test_s3_download_lwo2sndj/csv/file-4.csv'),\n",
       " Path('/tmp/test_s3_download_lwo2sndj/csv/file-2.csv'),\n",
       " Path('/tmp/test_s3_download_lwo2sndj/csv/file-3.csv'),\n",
       " Path('/tmp/test_s3_download_lwo2sndj/csv/file-16.csv'),\n",
       " Path('/tmp/test_s3_download_lwo2sndj/csv/file-13.csv'),\n",
       " Path('/tmp/test_s3_download_lwo2sndj/csv/file-9.csv'),\n",
       " Path('/tmp/test_s3_download_lwo2sndj/csv/file-11.csv')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\r  0%|          | 0/1 [00:00<?, ?it/s]\\r100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\\r100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\\nSuccessfully pulled the datablob uuid: 5141bb5a-bd08-4743-8d0e-3d0569cb3d4d.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'6f6dd429-7051-4cdc-ba75-53079e65749c\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'temp_dir.exists()=False'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing single files upload.\n",
    "\n",
    "# Create temp directory\n",
    "temp_dir, csv_dirpath = get_test_csv_path()\n",
    "\n",
    "# Creating a new datasource\n",
    "cmd = [\n",
    "    \"from-local\",\n",
    "    \"--path\", str(csv_dirpath / \"file-1.csv\")\n",
    "]\n",
    "\n",
    "cmd_q = [\n",
    "    \"from-local\",\n",
    "    \"--path\", str(csv_dirpath / \"file-1.csv\"),\n",
    "    \"-q\"\n",
    "]\n",
    "\n",
    "\n",
    "with set_airt_service_token_envvar():\n",
    "    \n",
    "    # Without quiet\n",
    "    result = runner.invoke(app, cmd)\n",
    "    \n",
    "    display(result.stdout)\n",
    "    assert \"Successfully pulled the datablob uuid:\" in str(result.stdout)\n",
    "    \n",
    "    # With quiet\n",
    "    result = runner.invoke(app, cmd_q)\n",
    "\n",
    "    display(result.stdout)\n",
    "    assert len(remove_hypens_from_id(result.stdout[:-1])) == 32\n",
    "\n",
    "\n",
    "# Deleting the temp directory\n",
    "shutil.rmtree(temp_dir)\n",
    "display(f\"{temp_dir.exists()=}\")\n",
    "assert not temp_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "\n",
    "@app.command(\"from-clickhouse\")\n",
    "@helper.requires_auth_token\n",
    "def from_clickhouse(\n",
    "    host: str = typer.Option(..., help=\"Remote database host name.\"),\n",
    "    database: str = typer.Option(..., help=\"Database name.\"),\n",
    "    table: str = typer.Option(..., help=\"Table name.\"),\n",
    "    protocol: str = typer.Option(..., help='Protocol to use. The valid values are \"native\" and \"http\".'),\n",
    "    index_column: str = typer.Option(\n",
    "        ..., help=\"The column to use as index (row labels).\"\n",
    "    ),\n",
    "    timestamp_column: str = typer.Option(..., help=\"Timestamp column name in the tabel.\"),\n",
    "    port: int = typer.Option(\n",
    "        0,\n",
    "        help=\"Host port number. If not passed, then the default value **0** will be used.\",\n",
    "    ),\n",
    "    cloud_provider: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--cloud-provider\",\n",
    "        \"-cp\",\n",
    "        help=\"The destination cloud storage provider's name to store the datablob. Currently, the API only supports **aws** and **azure** as cloud storage providers. If **None** (default value), then **aws**  will be used as the cloud storage provider.\",\n",
    "    ),\n",
    "    region: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--region\",\n",
    "        \"-r\",\n",
    "        help=\"The destination cloud provider's region to save your datablob. If **None** (default value) then the default region will be assigned based on the cloud provider. \" \\\n",
    "            \"In the case of **aws**, **eu-west-1** will be used and in the case of **azure**, **westeurope** will be used. \" \\\n",
    "            \"The supported AWS regions are: ap-northeast-1, ap-northeast-2, ap-south-1, ap-southeast-1, ap-southeast-2, ca-central-1, eu-central-1, \" \\\n",
    "            \"eu-north-1, eu-west-1, eu-west-2, eu-west-3, sa-east-1, us-east-1, us-east-2, us-west-1, us-west-2. The supported Azure Blob Storage \" \\\n",
    "            \"regions are: australiacentral, australiacentral2, australiaeast, australiasoutheast, brazilsouth, canadacentral, canadaeast, centralindia, \" \\\n",
    "            \"centralus, eastasia, eastus, eastus2, francecentral, francesouth, germanynorth, germanywestcentral, japaneast, japanwest, koreacentral, koreasouth, \" \\\n",
    "            \"northcentralus, northeurope, norwayeast, norwaywest, southafricanorth, southafricawest, southcentralus, southeastasia, southindia, switzerlandnorth, \" \\\n",
    "            \"switzerlandwest, uaecentral, uaenorth, uksouth, ukwest, westcentralus, westeurope, westindia, westus, westus2.\"\n",
    "    ),\n",
    "    username: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--username\",\n",
    "        \"-u\",\n",
    "        help=\"Database username. If not passed, the default value 'root' will be used unless the value is explicitly set in the environment variable **CLICKHOUSE_USERNAME**.\"\n",
    "    ),\n",
    "    password: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--password\",\n",
    "        \"-p\",\n",
    "        help=\"Database password. If not passed, the default value '' will be used unless the value is explicitly set in the environment variable **CLICKHOUSE_PASSWORD**.\"\n",
    "    ),\n",
    "    filters_json: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--filters-json\",\n",
    "        \"-f\",\n",
    "        help=\"Additional parameters to be used when importing data. For example, if you want to filter and extract data only for a specific user_id, pass '{\"\n",
    "        '\"user_id\"'\n",
    "        \": 1}'.\",\n",
    "    ),\n",
    "    tag: Optional[str] = typer.Option(\n",
    "        None,\n",
    "        \"--tag\",\n",
    "        \"-t\",\n",
    "        help=\"A string to tag the datablob. If not passed, then the tag **latest** will be assigned to the datablob.\",\n",
    "    ),\n",
    "    quiet: bool = typer.Option(\n",
    "        False,\n",
    "        \"--quiet\",\n",
    "        \"-q\",\n",
    "        help=\"Output datablob uuid only.\",\n",
    "    ),\n",
    "    debug: bool = typer.Option(\n",
    "        False,\n",
    "        \"--debug\",\n",
    "        \"-d\",\n",
    "        help=\"Set logger level to DEBUG and output everything.\",\n",
    "    ),\n",
    "):\n",
    "    \"\"\"Create and return a datablob that encapsulates the data from a ClickHouse database.\n",
    "\n",
    "    If the database requires authentication, pass the username/password as commandline arguments or store it in\n",
    "    the **CLICKHOUSE_USERNAME** and **CLICKHOUSE_PASSWORD** environment variables.\n",
    "    \"\"\"\n",
    "\n",
    "    filters = json.loads(filters_json) if filters_json else None\n",
    "    \n",
    "    from airt.client import DataBlob\n",
    "\n",
    "    db = DataBlob.from_clickhouse(\n",
    "        host=host,\n",
    "        database=database,\n",
    "        table=table,\n",
    "        protocol=protocol,\n",
    "        index_column=index_column,\n",
    "        timestamp_column=timestamp_column,\n",
    "        port=port,\n",
    "        username=username,\n",
    "        password=password,\n",
    "        filters=filters,\n",
    "        cloud_provider=cloud_provider,\n",
    "        region=region,\n",
    "        tag=tag,\n",
    "    )\n",
    "\n",
    "    if quiet:\n",
    "        db.wait()\n",
    "        typer.echo(f\"{db.uuid}\")\n",
    "    else:\n",
    "        typer.echo(f\"Pulling datablob uuid: {db.uuid}\")\n",
    "        db.progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Usage: root from-clickhouse [OPTIONS]\\n\\n  Create and return a datablob that encapsulates the data from a ClickHouse\\n  database.\\n\\n  If the database requires authentication, pass the username/password as\\n  commandline arguments or store it in the **CLICKHOUSE_USERNAME** and\\n  **CLICKHOUSE_PASSWORD** environment variables.\\n\\nOptions:\\n  --host TEXT                 Remote database host name.  [required]\\n  --database TEXT             Database name.  [required]\\n  --table TEXT                Table name.  [required]\\n  --protocol TEXT             Protocol to use. The valid values are \"native\" and\\n                              \"http\".  [required]\\n  --index-column TEXT         The column to use as index (row labels).\\n                              [required]\\n  --timestamp-column TEXT     Timestamp column name in the tabel.  [required]\\n  --port INTEGER              Host port number. If not passed, then the default\\n                              value **0** will be used.  [default: 0]\\n  -cp, --cloud-provider TEXT  The destination cloud storage provider\\'s name to\\n                              store the datablob. Currently, the API only\\n                              supports **aws** and **azure** as cloud storage\\n                              providers. If **None** (default value), then\\n                              **aws**  will be used as the cloud storage\\n                              provider.\\n  -r, --region TEXT           The destination cloud provider\\'s region to save\\n                              your datablob. If **None** (default value) then\\n                              the default region will be assigned based on the\\n                              cloud provider. In the case of **aws**, **eu-\\n                              west-1** will be used and in the case of\\n                              **azure**, **westeurope** will be used. The\\n                              supported AWS regions are: ap-northeast-1, ap-\\n                              northeast-2, ap-south-1, ap-southeast-1, ap-\\n                              southeast-2, ca-central-1, eu-central-1, eu-\\n                              north-1, eu-west-1, eu-west-2, eu-west-3, sa-\\n                              east-1, us-east-1, us-east-2, us-west-1, us-\\n                              west-2. The supported Azure Blob Storage regions\\n                              are: australiacentral, australiacentral2,\\n                              australiaeast, australiasoutheast, brazilsouth,\\n                              canadacentral, canadaeast, centralindia,\\n                              centralus, eastasia, eastus, eastus2,\\n                              francecentral, francesouth, germanynorth,\\n                              germanywestcentral, japaneast, japanwest,\\n                              koreacentral, koreasouth, northcentralus,\\n                              northeurope, norwayeast, norwaywest,\\n                              southafricanorth, southafricawest, southcentralus,\\n                              southeastasia, southindia, switzerlandnorth,\\n                              switzerlandwest, uaecentral, uaenorth, uksouth,\\n                              ukwest, westcentralus, westeurope, westindia,\\n                              westus, westus2.\\n  -u, --username TEXT         Database username. If not passed, the default\\n                              value \\'root\\' will be used unless the value is\\n                              explicitly set in the environment variable\\n                              **CLICKHOUSE_USERNAME**.\\n  -p, --password TEXT         Database password. If not passed, the default\\n                              value \\'\\' will be used unless the value is\\n                              explicitly set in the environment variable\\n                              **CLICKHOUSE_PASSWORD**.\\n  -f, --filters-json TEXT     Additional parameters to be used when importing\\n                              data. For example, if you want to filter and\\n                              extract data only for a specific user_id, pass\\n                              \\'{\"user_id\": 1}\\'.\\n  -t, --tag TEXT              A string to tag the datablob. If not passed, then\\n                              the tag **latest** will be assigned to the\\n                              datablob.\\n  -q, --quiet                 Output datablob uuid only.\\n  -d, --debug                 Set logger level to DEBUG and output everything.\\n  --help                      Show this message and exit.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert_has_help([\"from-clickhouse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pulling datablob uuid: ba17d649-00da-400c-b610-06be7a53085e\\n\\r  0%|          | 0/1 [00:00<?, ?it/s]\\r  0%|          | 0/1 [00:05<?, ?it/s]\\r  0%|          | 0/1 [00:10<?, ?it/s]\\r  0%|          | 0/1 [00:15<?, ?it/s]\\r100%|██████████| 1/1 [00:20<00:00,  5.05s/it]\\r100%|██████████| 1/1 [00:20<00:00, 20.24s/it]\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'be2e0852-a938-4c60-aaa9-0027d25cadd7'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'datablob_uuid                         datasource_uuids    type    source                                                        region     cloud_provider    tags    pulled_on      folder_size    user_uuid                             error    disabled    ready\\nbe2e0852-a938-4c60-aaa9-0027d25cadd7  <none>              db      clickhouse+native://35.158.134.25:0/infobip/airt_training_3m  eu-west-1  aws               latest  2 seconds ago  8.9 MB         06a385d1-66a1-4ffc-8306-7f5821902fcc  <none>   False       True\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'a30f79f4-14ec-42f0-85f8-f9b1495e0be6'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'datablob_uuid                         datasource_uuids    type    source                                                        region     cloud_provider    tags    pulled_on      folder_size    user_uuid                             error    disabled    ready\\na30f79f4-14ec-42f0-85f8-f9b1495e0be6  <none>              db      clickhouse+native://35.158.134.25:0/infobip/airt_training_3m  eu-west-3  aws               latest  3 seconds ago  8.9 MB         06a385d1-66a1-4ffc-8306-7f5821902fcc  <none>   False       True\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tests for from-clickhouse. Testing positive scenario.\n",
    "\n",
    "cmd = [\n",
    "    \"from-clickhouse\",\n",
    "    \"--host\", os.environ.get(\"CLICKHOUSE_HOST\"),\n",
    "    \"--database\", os.environ.get(\"CLICKHOUSE_DATABASE\"),\n",
    "    \"--table\", os.environ.get(\"CLICKHOUSE_EVENTS_TABLE\"),\n",
    "    \"--protocol\", \"native\",\n",
    "    \"--index-column\", \"PersonId\",\n",
    "    \"--timestamp-column\", \"OccurredTimeTicks\",\n",
    "    \"--filters-json\", '{\"AccountId\": 312571}'\n",
    "]\n",
    "\n",
    "\n",
    "with set_airt_service_token_envvar():\n",
    "    # Without quiet (verbose)\n",
    "    result = runner.invoke(app, cmd)\n",
    "    display(result.stdout)\n",
    "    assert \"Pulling datablob uuid: \" in result.stdout\n",
    "    \n",
    "    \n",
    "    result = runner.invoke(app, cmd + [\"-q\"])\n",
    "    db_uuid = result.stdout[:-1]\n",
    "    display(db_uuid)\n",
    "    assert len(remove_hypens_from_id(db_uuid)) == 32\n",
    "    \n",
    "    result = runner.invoke(app, [\"details\", db_uuid])\n",
    "    display(result.stdout)\n",
    "    assert result.exit_code == 0\n",
    "    assert \"eu-west-1\" in result.stdout\n",
    "    \n",
    "    result = runner.invoke(app, cmd + [\"-cp\", \"aws\", \"--region\", \"eu-west-3\", \"-q\"])\n",
    "    db_uuid = result.stdout[:-1]\n",
    "    display(db_uuid)\n",
    "    assert len(remove_hypens_from_id(db_uuid)) == 32\n",
    "    \n",
    "    result = runner.invoke(app, [\"details\", db_uuid])\n",
    "    display(result.stdout)\n",
    "    assert result.exit_code == 0\n",
    "    assert \"eu-west-3\" in result.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Pulling datablob uuid: 9c24af99-f638-4abd-b9da-4a58cd20ccfa\\n\\r  0%|          | 0/1 [00:00<?, ?it/s]\\r  0%|          | 0/1 [00:05<?, ?it/s]\\r  0%|          | 0/1 [00:10<?, ?it/s]\\nError: Orig exception: Code: 81.\\nDB::Exception: Database `fake-database` doesn't exist. Stack trace:\\n\\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x8b6cbba in /usr/bin/cli\\n\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tests for from-clickhouse. Testing negative scenario.\n",
    "\n",
    "cmd = [\n",
    "    \"from-clickhouse\",\n",
    "    \"--host\", os.environ.get(\"CLICKHOUSE_HOST\"),\n",
    "    \"--database\", \"fake-database\",\n",
    "    \"--table\", \"fake-table\",\n",
    "    \"--protocol\", \"native\",\n",
    "    \"--index-column\", \"PersonId\",\n",
    "    \"--timestamp-column\", \"OccurredTimeTicks\",\n",
    "    \"-f\", '{\"AccountId\": 312571}'\n",
    "]\n",
    "\n",
    "\n",
    "with set_airt_service_token_envvar():\n",
    "    # Without quiet (verbose)\n",
    "    result = runner.invoke(app, cmd)\n",
    "    display(result.stdout)\n",
    "    assert result.exit_code == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
