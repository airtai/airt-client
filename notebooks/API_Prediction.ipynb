{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: This module contains all classes encapsulating the prediction routes\n",
    "  of the API service.\n",
    "output-file: api_prediction.html\n",
    "title: API_Prediction\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _components.prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "\n",
    "While writing doc strings, please use the below syntax for linking methods/classes. So that the methods/classes gets highlighted in the browser and clicking on it will take the user to the linked function\n",
    "\n",
    "    - To link a method from the class same file please use the `method_name` format.\n",
    "    - To link a method from a different Class (can in a seperate file also) please use `Classname.method_name` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt.testing.activate_by_import: Testing environment activated.\n"
     ]
    }
   ],
   "source": [
    "from airt._testing import activate_by_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "import os\n",
    "import textwrap\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from fastcore.foundation import patch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from airt._components.client import Client\n",
    "from airt._components.progress_status import ProgressStatus\n",
    "from airt._constant import CLIENT_DB_PASSWORD, CLIENT_DB_USERNAME\n",
    "from airt._helper import (\n",
    "    add_example_to_docs,\n",
    "    add_ready_column,\n",
    "    delete_data,\n",
    "    generate_df,\n",
    "    get_attributes_from_instances,\n",
    "    get_data,\n",
    "    post_data,\n",
    "    export,\n",
    ")\n",
    "from airt._logger import get_logger, set_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import tempfile\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pytest\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.mgmt.storage import StorageManagementClient\n",
    "\n",
    "import airt._sanitizer\n",
    "from airt._components.datablob import DataBlob\n",
    "from airt._components.datasource import DataSource\n",
    "from airt._constant import SERVICE_PASSWORD, SERVICE_USERNAME\n",
    "from airt._docstring.helpers import run_examples_from_docstring\n",
    "from airt.client import User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: This is an info\n",
      "[WARNING] __main__: This is a warning\n",
      "[ERROR] __main__: This is an error\n"
     ]
    }
   ],
   "source": [
    "display(logger.getEffectiveLevel())\n",
    "assert logger.getEffectiveLevel() == logging.INFO\n",
    "\n",
    "logger.debug(\"This is a debug message\")\n",
    "logger.info(\"This is an info\")\n",
    "logger.warning(\"This is a warning\")\n",
    "logger.error(\"This is an error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_S3_URI = \"s3://test-airt-service/ecommerce_behavior_notebooks\"\n",
    "TEST_AZURE_PUSH_URI = (\n",
    "    \"https://testairtservice.blob.core.windows.net/test-client-push-container\"\n",
    ")\n",
    "RANDOM_UUID_FOR_TESTING = \"00000000-0000-0000-0000-000000000000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@export(\"airt.client\")\n",
    "class Prediction(ProgressStatus):\n",
    "    \"\"\"A class to manage and download the predictions.\n",
    "\n",
    "    The **Prediction** class is automatically instantiated by calling the `Model.predict` method of a `Model` instance.\n",
    "    Currently, it is the only way to instantiate this class.\n",
    "\n",
    "    At the moment, the prediction results can only be\n",
    "\n",
    "    - downloaded to a local folder in parquet file format\n",
    "\n",
    "    - pushed to Azure Blob Storage or an AWS S3 bucket\n",
    "\n",
    "    - pushed to MySql or ClickHouse database\n",
    "\n",
    "    We intend to support additional databases and storage mediums in future releases.\n",
    "    \"\"\"\n",
    "\n",
    "    BASIC_PRED_COLS = [\"uuid\", \"created\", \"total_steps\", \"completed_steps\"]\n",
    "    ALL_PRED_COLS = BASIC_PRED_COLS + [\n",
    "        \"model\",\n",
    "        \"datasource\",\n",
    "        \"region\",\n",
    "        \"cloud_provider\",\n",
    "        \"error\",\n",
    "    ]\n",
    "\n",
    "    COLS_TO_RENAME = {\n",
    "        \"uuid\": \"prediction_uuid\",\n",
    "        \"datasource\": \"datasource_uuid\",\n",
    "        \"model\": \"model_uuid\",\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        uuid: str,\n",
    "        datasource: Optional[str] = None,\n",
    "        model: Optional[str] = None,\n",
    "        created: Optional[str] = None,\n",
    "        total_steps: Optional[int] = None,\n",
    "        completed_steps: Optional[int] = None,\n",
    "        region: Optional[str] = None,\n",
    "        cloud_provider: Optional[str] = None,\n",
    "        error: Optional[str] = None,\n",
    "        disabled: Optional[bool] = None,\n",
    "    ):\n",
    "        \"\"\"Constructs a new **Prediction** instance\n",
    "\n",
    "        Warning:\n",
    "            Do not construct this object directly by calling the constructor, instead please use\n",
    "            `Model.predict` method of the Model instance.\n",
    "\n",
    "        Args:\n",
    "            uuid: Prediction uuid.\n",
    "            datasource: DataSource uuid.\n",
    "            model: Model uuid.\n",
    "            created: Prediction creation date.\n",
    "            total_steps: No of steps needed to complete the model prediction.\n",
    "            completed_steps: No of steps completed so far in the model prediction.\n",
    "            region: The region name of the cloud provider where the prediction is stored.\n",
    "            cloud_provider: The name of the cloud storage provider where the prediction is stored.\n",
    "            error: Contains the error message if running the predictions fails.\n",
    "            disabled: A flag that indicates the prediction's status. If the prediction is deleted, then **False** will be set.\n",
    "        \"\"\"\n",
    "        self.uuid = uuid\n",
    "        self.datasource = datasource\n",
    "        self.model = model\n",
    "        self.created = created\n",
    "        self.total_steps = total_steps\n",
    "        self.completed_steps = completed_steps\n",
    "        self.region = region\n",
    "        self.cloud_provider = cloud_provider\n",
    "        self.error = error\n",
    "        self.disabled = disabled\n",
    "        ProgressStatus.__init__(self, relative_url=f\"/prediction/{self.uuid}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _download_prediction_file_to_local(\n",
    "        file_name: str, url: str, path: Union[str, Path]\n",
    "    ) -> None:\n",
    "        \"\"\"Download the file to local directory.\n",
    "\n",
    "        Args:\n",
    "            file_name: Name of the file\n",
    "            url: Url of the file\n",
    "            path: Local directory path\n",
    "\n",
    "        Raises:\n",
    "            HTTPError: If the **url** is invalid or not reachable.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            raise requests.exceptions.HTTPError(e)\n",
    "\n",
    "        else:\n",
    "            with open(Path(path) / file_name, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "    @staticmethod\n",
    "    def ls(\n",
    "        offset: int = 0,\n",
    "        limit: int = 100,\n",
    "        disabled: bool = False,\n",
    "        completed: bool = False,\n",
    "    ) -> List[\"Prediction\"]:\n",
    "        \"\"\"Return the list of Prediction instances available in the server.\n",
    "\n",
    "        Args:\n",
    "            offset: The number of predictions to offset at the beginning. If None, then the default value **0** will be used.\n",
    "            limit: The maximum number of predictions to return from the server. If None,\n",
    "                then the default value **100** will be used.\n",
    "            disabled: If set to **True**, then only the deleted predictions will be returned. Else, the default value\n",
    "                **False** will be used to return only the list of active predictions.\n",
    "            completed: If set to **True**, then only the predictions that are successfully processed in server will be returned.\n",
    "                Else, the default value **False** will be used to return all the predictions.\n",
    "\n",
    "        Returns:\n",
    "            A list of Prediction instances available in the server.\n",
    "\n",
    "        Raises:\n",
    "            ConnectionError: If the server address is invalid or not reachable.\n",
    "        \"\"\"\n",
    "        lists = Client._get_data(\n",
    "            relative_url=f\"/prediction/?disabled={disabled}&completed={completed}&offset={offset}&limit={limit}\"\n",
    "        )\n",
    "\n",
    "        predx = [\n",
    "            Prediction(\n",
    "                uuid=pred[\"uuid\"],\n",
    "                model=pred[\"model\"],\n",
    "                datasource=pred[\"datasource\"],\n",
    "                created=pred[\"created\"],\n",
    "                total_steps=pred[\"total_steps\"],\n",
    "                completed_steps=pred[\"completed_steps\"],\n",
    "                region=pred[\"region\"],\n",
    "                cloud_provider=pred[\"cloud_provider\"],\n",
    "                error=pred[\"error\"],\n",
    "                disabled=pred[\"disabled\"],\n",
    "            )\n",
    "            for pred in lists\n",
    "        ]\n",
    "\n",
    "        return predx\n",
    "\n",
    "    @staticmethod\n",
    "    def as_df(predx: List[\"Prediction\"]) -> pd.DataFrame:\n",
    "        \"\"\"Return the details of prediction instances as a pandas dataframe.\n",
    "\n",
    "        Args:\n",
    "            predx: List of prediction instances.\n",
    "\n",
    "        Returns:\n",
    "            Details of all the prediction in a dataframe.\n",
    "\n",
    "        Raises:\n",
    "            ConnectionError: If the server address is invalid or not reachable.\n",
    "        \"\"\"\n",
    "        response = get_attributes_from_instances(predx, Prediction.BASIC_PRED_COLS)  # type: ignore\n",
    "\n",
    "        df = generate_df(response, Prediction.BASIC_PRED_COLS)\n",
    "\n",
    "        df = df.rename(columns=Prediction.COLS_TO_RENAME)\n",
    "\n",
    "        return add_ready_column(df)\n",
    "\n",
    "    def details(self) -> pd.DataFrame:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def to_pandas(self) -> pd.DataFrame:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def delete(self) -> pd.DataFrame:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def to_s3(\n",
    "        self,\n",
    "        uri: str,\n",
    "        access_key: Optional[str] = None,\n",
    "        secret_key: Optional[str] = None,\n",
    "    ) -> ProgressStatus:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def to_azure_blob_storage(\n",
    "        self,\n",
    "        uri: str,\n",
    "        credential: Optional[str] = None,\n",
    "    ) -> ProgressStatus:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def to_local(\n",
    "        self,\n",
    "        path: Union[str, Path],\n",
    "        show_progress: Optional[bool] = True,\n",
    "    ) -> None:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def to_mysql(\n",
    "        self,\n",
    "        *,\n",
    "        host: str,\n",
    "        database: str,\n",
    "        table: str,\n",
    "        port: int = 3306,\n",
    "        username: Optional[str] = None,\n",
    "        password: Optional[str] = None,\n",
    "    ) -> ProgressStatus:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def to_clickhouse(\n",
    "        self,\n",
    "        *,\n",
    "        host: str,\n",
    "        database: str,\n",
    "        table: str,\n",
    "        port: int = 0,\n",
    "        protocol: str,\n",
    "        username: Optional[str] = None,\n",
    "        password: Optional[str] = None,\n",
    "    ) -> ProgressStatus:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "\n",
    "def _docstring_example():\n",
    "    \"\"\"\n",
    "    Example:\n",
    "        ```python\n",
    "        # Importing necessary libraries\n",
    "        import os\n",
    "        import tempfile\n",
    "        from datetime import timedelta\n",
    "\n",
    "        from azure.identity import DefaultAzureCredential\n",
    "        from azure.mgmt.storage import StorageManagementClient\n",
    "\n",
    "        from  airt.client import Client, DataBlob, DataSource, Model, Prediction\n",
    "\n",
    "        # Authenticate\n",
    "        Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")\n",
    "\n",
    "        # Create a datablob\n",
    "        # In this example, the datablob will be stored in an AWS S3 bucket. The\n",
    "        # access_key and the secret_key are set in the AWS_ACCESS_KEY_ID and\n",
    "        # AWS_SECRET_ACCESS_KEY environment variables, and the region is set to\n",
    "        # eu-west-3; feel free to change the cloud provider and the region to\n",
    "        # suit your needs.\n",
    "        db = DataBlob.from_s3(\n",
    "            uri=\"{fill in uri}\",\n",
    "            cloud_provider=\"aws\",\n",
    "            region=\"eu-west-3\"\n",
    "        )\n",
    "\n",
    "        # Display the status in a progress bar\n",
    "        db.progress_bar()\n",
    "\n",
    "        # Create a datasource\n",
    "        ds = db.to_datasource(\n",
    "            file_type=\"{fill in file_type}\",\n",
    "            index_column=\"{fill in index_column}\",\n",
    "            sort_by=\"{fill in sort_by}\",\n",
    "        )\n",
    "\n",
    "        # Display the status in a progress bar\n",
    "        ds.progress_bar()\n",
    "\n",
    "        # Train a model to predicts which users will perform a purchase\n",
    "        # event (\"*purchase\") three hours before they actually do it.\n",
    "        model = ds.train(\n",
    "            client_column=\"{fill in client_column}\",\n",
    "            target_column=\"{fill in target_column}\",\n",
    "            target=\"*purchase\",\n",
    "            predict_after=timedelta(hours=3)\n",
    "        )\n",
    "\n",
    "        # Display the status in a progress bar\n",
    "        model.progress_bar()\n",
    "\n",
    "        # Run predictions\n",
    "        prediction = model.predict()\n",
    "        prediction.progress_bar()\n",
    "\n",
    "        # Print the details of the newly created prediction\n",
    "        print(prediction.details())\n",
    "\n",
    "        # Get the list of all prediction instances created by the currently logged-in user\n",
    "        predx = Prediction.ls()\n",
    "        print(predx)\n",
    "\n",
    "        # Display the details of the prediction instances in a pandas dataframe\n",
    "        df = Prediction.as_df(predx)\n",
    "        print(df)\n",
    "\n",
    "        # Display the prediction results in a pandas DataFrame\n",
    "        print(prediction.to_pandas())\n",
    "\n",
    "        # Push the prediction results to an AWS S3 bucket\n",
    "        s3_status = prediction.to_s3(uri=\"{fill in s3_target_uri}\")\n",
    "\n",
    "        # Push the prediction results to an Azure Blob Storage\n",
    "        os.environ[\"AZURE_SUBSCRIPTION_ID\"] = \"{fill in azure_subscription_id}\"\n",
    "        os.environ[\"AZURE_CLIENT_ID\"] = \"{fill in azure_client_id}\"\n",
    "        os.environ[\"AZURE_CLIENT_SECRET\"] = \"{fill in azure_client_secret}\"\n",
    "        os.environ[\"AZURE_TENANT_ID\"]= \"{fill in azure_tenant_id}\"\n",
    "        azure_group_name = \"{fill in azure_group_name}\"\n",
    "        azure_storage_account_name = \"{fill in azure_storage_account_name}\"\n",
    "        azure_storage_client = StorageManagementClient(\n",
    "            DefaultAzureCredential(), os.environ[\"AZURE_SUBSCRIPTION_ID\"]\n",
    "        )\n",
    "        azure_storage_keys = azure_storage_client.storage_accounts.list_keys(\n",
    "            azure_group_name, azure_storage_account_name\n",
    "        )\n",
    "        azure_storage_keys = {v.key_name: v.value for v in azure_storage_keys.keys}\n",
    "        azure_credential = azure_storage_keys['key1']\n",
    "\n",
    "        azure_status = prediction.to_azure_blob_storage(\n",
    "            uri=\"{fill in azure_target_uri}\",\n",
    "            credential=azure_credential\n",
    "        )\n",
    "\n",
    "        # Push the prediction results to a MySQL database\n",
    "        mysql_status = prediction.to_mysql(\n",
    "            username=\"{fill in mysql_db_username}\",\n",
    "            password=\"{fill in mysql_db_password}\",\n",
    "            host=\"{fill in mysql_host}\",\n",
    "            database=\"{fill in mysql_database}\",\n",
    "            table=\"{fill in mysql_table}\",\n",
    "        )\n",
    "\n",
    "        # Push the prediction results to a ClickHouse database\n",
    "        clickhouse_status = prediction.to_clickhouse(\n",
    "            username=\"{fill in clickhouse_db_username}\",\n",
    "            password=\"{fill in clickhouse_db_password}\",\n",
    "            host=\"{fill in clickhouse_host}\",\n",
    "            database=\"{fill in clickhouse_database}\",\n",
    "            table=\"{fill in clickhouse_table}\",\n",
    "            protocol=\"native\",\n",
    "        )\n",
    "\n",
    "        # Download the predictions to a local directory\n",
    "        # In this example, the prediction results are downloaded\n",
    "        # to a temporary directory\n",
    "        with tempfile.TemporaryDirectory(prefix=\"predictions_results_\") as d:\n",
    "            prediction.to_local(path=d)\n",
    "            # Check the downloaded prediction files\n",
    "            downloaded_files = sorted(list(os.listdir(d)))\n",
    "            print(downloaded_files)\n",
    "\n",
    "\n",
    "        # Check the status\n",
    "        s3_status.wait()\n",
    "        azure_status.progress_bar()\n",
    "        mysql_status.progress_bar()\n",
    "        clickhouse_status.progress_bar()\n",
    "\n",
    "        # Delete the prediction\n",
    "        prediction.delete()\n",
    "        ```\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: Bucket already created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Example:                                                                                                        │\n",
       "│                                                                                                                 │\n",
       "│     # Importing necessary libraries                                                                             │\n",
       "│     import os                                                                                                   │\n",
       "│     import tempfile                                                                                             │\n",
       "│     from datetime import timedelta                                                                              │\n",
       "│                                                                                                                 │\n",
       "│     from azure.identity import DefaultAzureCredential                                                           │\n",
       "│     from azure.mgmt.storage import StorageManagementClient                                                      │\n",
       "│                                                                                                                 │\n",
       "│     from  airt.client import Client, DataBlob, DataSource, Model, Prediction                                    │\n",
       "│                                                                                                                 │\n",
       "│     # Authenticate                                                                                              │\n",
       "│     Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")                              │\n",
       "│                                                                                                                 │\n",
       "│     # Create a datablob                                                                                         │\n",
       "│     # In this example, the datablob will be stored in an AWS S3 bucket. The                                     │\n",
       "│     # access_key and the secret_key are set in the AWS_ACCESS_KEY_ID and                                        │\n",
       "│     # AWS_SECRET_ACCESS_KEY environment variables, and the region is set to                                     │\n",
       "│     # eu-west-3; feel free to change the cloud provider and the region to                                       │\n",
       "│     # suit your needs.                                                                                          │\n",
       "│     db = DataBlob.from_s3(                                                                                      │\n",
       "│         uri=\"{fill in uri}\",                                                                                    │\n",
       "│         cloud_provider=\"aws\",                                                                                   │\n",
       "│         region=\"eu-west-3\"                                                                                      │\n",
       "│     )                                                                                                           │\n",
       "│                                                                                                                 │\n",
       "│     # Display the status in a progress bar                                                                      │\n",
       "│     db.progress_bar()                                                                                           │\n",
       "│                                                                                                                 │\n",
       "│     # Create a datasource                                                                                       │\n",
       "│     ds = db.to_datasource(                                                                                      │\n",
       "│         file_type=\"{fill in file_type}\",                                                                        │\n",
       "│         index_column=\"{fill in index_column}\",                                                                  │\n",
       "│         sort_by=\"{fill in sort_by}\",                                                                            │\n",
       "│     )                                                                                                           │\n",
       "│                                                                                                                 │\n",
       "│     # Display the status in a progress bar                                                                      │\n",
       "│     ds.progress_bar()                                                                                           │\n",
       "│                                                                                                                 │\n",
       "│     # Train a model to predicts which users will perform a purchase                                             │\n",
       "│     # event (\"*purchase\") three hours before they actually do it.                                               │\n",
       "│     model = ds.train(                                                                                           │\n",
       "│         client_column=\"{fill in client_column}\",                                                                │\n",
       "│         target_column=\"{fill in target_column}\",                                                                │\n",
       "│         target=\"*purchase\",                                                                                     │\n",
       "│         predict_after=timedelta(hours=3)                                                                        │\n",
       "│     )                                                                                                           │\n",
       "│                                                                                                                 │\n",
       "│     # Display the status in a progress bar                                                                      │\n",
       "│     model.progress_bar()                                                                                        │\n",
       "│                                                                                                                 │\n",
       "│     # Run predictions                                                                                           │\n",
       "│     prediction = model.predict()                                                                                │\n",
       "│     prediction.progress_bar()                                                                                   │\n",
       "│                                                                                                                 │\n",
       "│     # Print the details of the newly created prediction                                                         │\n",
       "│     print(prediction.details())                                                                                 │\n",
       "│                                                                                                                 │\n",
       "│     # Get the list of all prediction instances created by the currently logged-in user                          │\n",
       "│     predx = Prediction.ls()                                                                                     │\n",
       "│     print(predx)                                                                                                │\n",
       "│                                                                                                                 │\n",
       "│     # Display the details of the prediction instances in a pandas dataframe                                     │\n",
       "│     df = Prediction.as_df(predx)                                                                                │\n",
       "│     print(df)                                                                                                   │\n",
       "│                                                                                                                 │\n",
       "│     # Display the prediction results in a pandas DataFrame                                                      │\n",
       "│     print(prediction.to_pandas())                                                                               │\n",
       "│                                                                                                                 │\n",
       "│     # Push the prediction results to an AWS S3 bucket                                                           │\n",
       "│     s3_status = prediction.to_s3(uri=\"{fill in s3_target_uri}\")                                                 │\n",
       "│                                                                                                                 │\n",
       "│     # Push the prediction results to an Azure Blob Storage                                                      │\n",
       "│     os.environ[\"AZURE_SUBSCRIPTION_ID\"] = \"{fill in azure_subscription_id}\"                                     │\n",
       "│     os.environ[\"AZURE_CLIENT_ID\"] = \"{fill in azure_client_id}\"                                                 │\n",
       "│     os.environ[\"AZURE_CLIENT_SECRET\"] = \"{fill in azure_client_secret}\"                                         │\n",
       "│     os.environ[\"AZURE_TENANT_ID\"]= \"{fill in azure_tenant_id}\"                                                  │\n",
       "│     azure_group_name = \"{fill in azure_group_name}\"                                                             │\n",
       "│     azure_storage_account_name = \"{fill in azure_storage_account_name}\"                                         │\n",
       "│     azure_storage_client = StorageManagementClient(                                                             │\n",
       "│         DefaultAzureCredential(), os.environ[\"AZURE_SUBSCRIPTION_ID\"]                                           │\n",
       "│     )                                                                                                           │\n",
       "│     azure_storage_keys = azure_storage_client.storage_accounts.list_keys(                                       │\n",
       "│         azure_group_name, azure_storage_account_name                                                            │\n",
       "│     )                                                                                                           │\n",
       "│     azure_storage_keys = {v.key_name: v.value for v in azure_storage_keys.keys}                                 │\n",
       "│     azure_credential = azure_storage_keys['key1']                                                               │\n",
       "│                                                                                                                 │\n",
       "│     azure_status = prediction.to_azure_blob_storage(                                                            │\n",
       "│         uri=\"{fill in azure_target_uri}\",                                                                       │\n",
       "│         credential=azure_credential                                                                             │\n",
       "│     )                                                                                                           │\n",
       "│                                                                                                                 │\n",
       "│     # Push the prediction results to a MySQL database                                                           │\n",
       "│     mysql_status = prediction.to_mysql(                                                                         │\n",
       "│         username=\"{fill in mysql_db_username}\",                                                                 │\n",
       "│         password=\"{fill in mysql_db_password}\",                                                                 │\n",
       "│         host=\"{fill in mysql_host}\",                                                                            │\n",
       "│         database=\"{fill in mysql_database}\",                                                                    │\n",
       "│         table=\"{fill in mysql_table}\",                                                                          │\n",
       "│     )                                                                                                           │\n",
       "│                                                                                                                 │\n",
       "│     # Push the prediction results to a ClickHouse database                                                      │\n",
       "│     clickhouse_status = prediction.to_clickhouse(                                                               │\n",
       "│         username=\"{fill in clickhouse_db_username}\",                                                            │\n",
       "│         password=\"{fill in clickhouse_db_password}\",                                                            │\n",
       "│         host=\"{fill in clickhouse_host}\",                                                                       │\n",
       "│         database=\"{fill in clickhouse_database}\",                                                               │\n",
       "│         table=\"{fill in clickhouse_table}\",                                                                     │\n",
       "│         protocol=\"native\",                                                                                      │\n",
       "│     )                                                                                                           │\n",
       "│                                                                                                                 │\n",
       "│     # Download the predictions to a local directory                                                             │\n",
       "│     # In this example, the prediction results are downloaded                                                    │\n",
       "│     # to a temporary directory                                                                                  │\n",
       "│     with tempfile.TemporaryDirectory(prefix=\"predictions_results_\") as d:                                       │\n",
       "│         prediction.to_local(path=d)                                                                             │\n",
       "│         # Check the downloaded prediction files                                                                 │\n",
       "│         downloaded_files = sorted(list(os.listdir(d)))                                                          │\n",
       "│         print(downloaded_files)                                                                                 │\n",
       "│                                                                                                                 │\n",
       "│                                                                                                                 │\n",
       "│     # Check the status                                                                                          │\n",
       "│     s3_status.wait()                                                                                            │\n",
       "│     azure_status.progress_bar()                                                                                 │\n",
       "│     mysql_status.progress_bar()                                                                                 │\n",
       "│     clickhouse_status.progress_bar()                                                                            │\n",
       "│                                                                                                                 │\n",
       "│     # Delete the prediction                                                                                     │\n",
       "│     prediction.delete()                                                                                         │\n",
       "│                                                                                                                 │\n",
       "│ ╭────────────────────────────────────────────────── stdout ───────────────────────────────────────────────────╮ │\n",
       "│ │                         prediction_uuid              created  ... error ready                               │ │\n",
       "│ │ 0  497a1c21-ca14-414a-beb6-b1ab0e7b8749  2022-11-02T10:34:24  ...  None  True                               │ │\n",
       "│ │                                                                                                             │ │\n",
       "│ │ [1 rows x 8 columns]                                                                                        │ │\n",
       "│ │ [&lt;airt.client.Prediction object at 0x7fcb34c6aa60&gt;, &lt;airt.client.Prediction object at 0x7fcb34c6a7c0&gt;,      │ │\n",
       "│ │ &lt;airt.client.Prediction object at 0x7fcb34c6aa90&gt;, &lt;airt.client.Prediction object at 0x7fcb34c6ac70&gt;,       │ │\n",
       "│ │ &lt;airt.client.Prediction object at 0x7fcb34c6ad30&gt;, &lt;airt.client.Prediction object at 0x7fcb34c6af40&gt;,       │ │\n",
       "│ │ &lt;airt.client.Prediction object at 0x7fcb34c6aa00&gt;, &lt;airt.client.Prediction object at 0x7fcb34c6abe0&gt;,       │ │\n",
       "│ │ &lt;airt.client.Prediction object at 0x7fcb34c6ac10&gt;, &lt;airt.client.Prediction object at 0x7fcb34c6af10&gt;,       │ │\n",
       "│ │ &lt;airt.client.Prediction object at 0x7fcb34c6aee0&gt;, &lt;airt.client.Prediction object at 0x7fcb34c6a5b0&gt;]       │ │\n",
       "│ │                          prediction_uuid              created  ready                                        │ │\n",
       "│ │ 0   883bac83-1376-4139-8f2b-1a5d60b59043  2022-11-02T08:49:52   True                                        │ │\n",
       "│ │ 1   2713fc2c-8a46-4e46-8e4b-3f8c44ad1a3a  2022-11-02T08:50:55   True                                        │ │\n",
       "│ │ 2   f3ae698e-3a2a-4dc6-8eb8-cf358f8851a9  2022-11-02T08:50:56   True                                        │ │\n",
       "│ │ 3   cad071a7-6e6e-40fe-97db-1f3107665e4b  2022-11-02T08:51:07   True                                        │ │\n",
       "│ │ 4   07507373-c927-437d-9024-41cb928404a2  2022-11-02T08:52:32   True                                        │ │\n",
       "│ │ 5   4f017211-0b39-4666-b184-73f5b570a18a  2022-11-02T08:52:57   True                                        │ │\n",
       "│ │ 6   cbc2a3a6-75ca-478b-8871-85fcc677c47b  2022-11-02T08:53:03   True                                        │ │\n",
       "│ │ 7   272f3840-d43a-412c-b7e9-6583e57e4ce8  2022-11-02T08:53:32   True                                        │ │\n",
       "│ │ 8   eb3ebcec-0b24-49fe-b62d-2f7a85025d0f  2022-11-02T08:54:23   True                                        │ │\n",
       "│ │ 9   2187b579-9889-481b-b0aa-b682e79f7bad  2022-11-02T08:54:47   True                                        │ │\n",
       "│ │ 10  f32900e3-fb83-4ccf-96ed-aac2d9b48b25  2022-11-02T10:00:03   True                                        │ │\n",
       "│ │ 11  497a1c21-ca14-414a-beb6-b1ab0e7b8749  2022-11-02T10:34:24   True                                        │ │\n",
       "│ │               Score                                                                                         │ │\n",
       "│ │ user_id                                                                                                     │ │\n",
       "│ │ 520088904  0.979853                                                                                         │ │\n",
       "│ │ 530496790  0.979157                                                                                         │ │\n",
       "│ │ 561587266  0.979055                                                                                         │ │\n",
       "│ │ 518085591  0.978915                                                                                         │ │\n",
       "│ │ 558856683  0.977960                                                                                         │ │\n",
       "│ │ 520772685  0.004043                                                                                         │ │\n",
       "│ │ 514028527  0.003890                                                                                         │ │\n",
       "│ │ 518574284  0.001346                                                                                         │ │\n",
       "│ │ 532364121  0.001341                                                                                         │ │\n",
       "│ │ 532647354  0.001139                                                                                         │ │\n",
       "│ │ ['part.0.parquet']                                                                                          │ │\n",
       "│ │                                                                                                             │ │\n",
       "│ ╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯ │\n",
       "│ ╭────────────────────────────────────────────────── stderr ───────────────────────────────────────────────────╮ │\n",
       "│ │                                                                                                             │ │\n",
       "│ │   0%|          | 0/1 [00:00&lt;?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:05&lt;?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:10&lt;?, ?it/s]                                                                       │ │\n",
       "│ │ 100%|██████████| 1/1 [00:15&lt;00:00,  5.05s/it]                                                               │ │\n",
       "│ │ 100%|██████████| 1/1 [00:15&lt;00:00, 15.19s/it]                                                               │ │\n",
       "│ │                                                                                                             │ │\n",
       "│ │   0%|          | 0/1 [00:00&lt;?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:05&lt;?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:10&lt;?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:15&lt;?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:20&lt;?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:25&lt;?, ?it/s]                                                                       │ │\n",
       "│ │ 100%|██████████| 1/1 [00:30&lt;00:00,  5.05s/it]                                                               │ │\n",
       "│ │ 100%|██████████| 1/1 [00:30&lt;00:00, 30.33s/it]                                                               │ │\n",
       "│ │                                                                                                             │ │\n",
       "│ │   0%|          | 0/5 [00:00&lt;?, ?it/s]                                                                       │ │\n",
       "│ │ 100%|██████████| 5/5 [00:00&lt;00:00, 149.65it/s]                                                              │ │\n",
       "│ │                                                                                                             │ │\n",
       "│ │   0%|          | 0/3 [00:00&lt;?, ?it/s]                                                                       │ │\n",
       "│ │ 100%|██████████| 3/3 [00:05&lt;00:00,  1.69s/it]                                                               │ │\n",
       "│ │ 100%|██████████| 3/3 [00:05&lt;00:00,  1.69s/it]                                                               │ │\n",
       "│ │                                                                                                             │ │\n",
       "│ │   0%|          | 0/1 [00:00&lt;?, ?it/s]                                                                       │ │\n",
       "│ │ 100%|██████████| 1/1 [00:02&lt;00:00,  2.82s/it]                                                               │ │\n",
       "│ │ 100%|██████████| 1/1 [00:02&lt;00:00,  2.82s/it]                                                               │ │\n",
       "│ │                                                                                                             │ │\n",
       "│ │   0%|          | 0/1 [00:00&lt;?, ?it/s]                                                                       │ │\n",
       "│ │ 100%|██████████| 1/1 [00:05&lt;00:00,  5.09s/it]                                                               │ │\n",
       "│ │ 100%|██████████| 1/1 [00:05&lt;00:00,  5.09s/it]                                                               │ │\n",
       "│ │                                                                                                             │ │\n",
       "│ │   0%|          | 0/1 [00:00&lt;?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:05&lt;?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:10&lt;?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:15&lt;?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:20&lt;?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:25&lt;?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:30&lt;?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:35&lt;?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:40&lt;?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:45&lt;?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:50&lt;?, ?it/s]                                                                       │ │\n",
       "│ │ 100%|██████████| 1/1 [00:55&lt;00:00,  5.06s/it]                                                               │ │\n",
       "│ │ 100%|██████████| 1/1 [00:55&lt;00:00, 55.58s/it]                                                               │ │\n",
       "│ │                                                                                                             │ │\n",
       "│ │   0%|          | 0/1 [00:00&lt;?, ?it/s]                                                                       │ │\n",
       "│ │ 100%|██████████| 1/1 [00:00&lt;00:00, 25.66it/s]                                                               │ │\n",
       "│ │                                                                                                             │ │\n",
       "│ ╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯ │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Example:                                                                                                        │\n",
       "│                                                                                                                 │\n",
       "│     # Importing necessary libraries                                                                             │\n",
       "│     import os                                                                                                   │\n",
       "│     import tempfile                                                                                             │\n",
       "│     from datetime import timedelta                                                                              │\n",
       "│                                                                                                                 │\n",
       "│     from azure.identity import DefaultAzureCredential                                                           │\n",
       "│     from azure.mgmt.storage import StorageManagementClient                                                      │\n",
       "│                                                                                                                 │\n",
       "│     from  airt.client import Client, DataBlob, DataSource, Model, Prediction                                    │\n",
       "│                                                                                                                 │\n",
       "│     # Authenticate                                                                                              │\n",
       "│     Client.get_token(username=\"{fill in username}\", password=\"{fill in password}\")                              │\n",
       "│                                                                                                                 │\n",
       "│     # Create a datablob                                                                                         │\n",
       "│     # In this example, the datablob will be stored in an AWS S3 bucket. The                                     │\n",
       "│     # access_key and the secret_key are set in the AWS_ACCESS_KEY_ID and                                        │\n",
       "│     # AWS_SECRET_ACCESS_KEY environment variables, and the region is set to                                     │\n",
       "│     # eu-west-3; feel free to change the cloud provider and the region to                                       │\n",
       "│     # suit your needs.                                                                                          │\n",
       "│     db = DataBlob.from_s3(                                                                                      │\n",
       "│         uri=\"{fill in uri}\",                                                                                    │\n",
       "│         cloud_provider=\"aws\",                                                                                   │\n",
       "│         region=\"eu-west-3\"                                                                                      │\n",
       "│     )                                                                                                           │\n",
       "│                                                                                                                 │\n",
       "│     # Display the status in a progress bar                                                                      │\n",
       "│     db.progress_bar()                                                                                           │\n",
       "│                                                                                                                 │\n",
       "│     # Create a datasource                                                                                       │\n",
       "│     ds = db.to_datasource(                                                                                      │\n",
       "│         file_type=\"{fill in file_type}\",                                                                        │\n",
       "│         index_column=\"{fill in index_column}\",                                                                  │\n",
       "│         sort_by=\"{fill in sort_by}\",                                                                            │\n",
       "│     )                                                                                                           │\n",
       "│                                                                                                                 │\n",
       "│     # Display the status in a progress bar                                                                      │\n",
       "│     ds.progress_bar()                                                                                           │\n",
       "│                                                                                                                 │\n",
       "│     # Train a model to predicts which users will perform a purchase                                             │\n",
       "│     # event (\"*purchase\") three hours before they actually do it.                                               │\n",
       "│     model = ds.train(                                                                                           │\n",
       "│         client_column=\"{fill in client_column}\",                                                                │\n",
       "│         target_column=\"{fill in target_column}\",                                                                │\n",
       "│         target=\"*purchase\",                                                                                     │\n",
       "│         predict_after=timedelta(hours=3)                                                                        │\n",
       "│     )                                                                                                           │\n",
       "│                                                                                                                 │\n",
       "│     # Display the status in a progress bar                                                                      │\n",
       "│     model.progress_bar()                                                                                        │\n",
       "│                                                                                                                 │\n",
       "│     # Run predictions                                                                                           │\n",
       "│     prediction = model.predict()                                                                                │\n",
       "│     prediction.progress_bar()                                                                                   │\n",
       "│                                                                                                                 │\n",
       "│     # Print the details of the newly created prediction                                                         │\n",
       "│     print(prediction.details())                                                                                 │\n",
       "│                                                                                                                 │\n",
       "│     # Get the list of all prediction instances created by the currently logged-in user                          │\n",
       "│     predx = Prediction.ls()                                                                                     │\n",
       "│     print(predx)                                                                                                │\n",
       "│                                                                                                                 │\n",
       "│     # Display the details of the prediction instances in a pandas dataframe                                     │\n",
       "│     df = Prediction.as_df(predx)                                                                                │\n",
       "│     print(df)                                                                                                   │\n",
       "│                                                                                                                 │\n",
       "│     # Display the prediction results in a pandas DataFrame                                                      │\n",
       "│     print(prediction.to_pandas())                                                                               │\n",
       "│                                                                                                                 │\n",
       "│     # Push the prediction results to an AWS S3 bucket                                                           │\n",
       "│     s3_status = prediction.to_s3(uri=\"{fill in s3_target_uri}\")                                                 │\n",
       "│                                                                                                                 │\n",
       "│     # Push the prediction results to an Azure Blob Storage                                                      │\n",
       "│     os.environ[\"AZURE_SUBSCRIPTION_ID\"] = \"{fill in azure_subscription_id}\"                                     │\n",
       "│     os.environ[\"AZURE_CLIENT_ID\"] = \"{fill in azure_client_id}\"                                                 │\n",
       "│     os.environ[\"AZURE_CLIENT_SECRET\"] = \"{fill in azure_client_secret}\"                                         │\n",
       "│     os.environ[\"AZURE_TENANT_ID\"]= \"{fill in azure_tenant_id}\"                                                  │\n",
       "│     azure_group_name = \"{fill in azure_group_name}\"                                                             │\n",
       "│     azure_storage_account_name = \"{fill in azure_storage_account_name}\"                                         │\n",
       "│     azure_storage_client = StorageManagementClient(                                                             │\n",
       "│         DefaultAzureCredential(), os.environ[\"AZURE_SUBSCRIPTION_ID\"]                                           │\n",
       "│     )                                                                                                           │\n",
       "│     azure_storage_keys = azure_storage_client.storage_accounts.list_keys(                                       │\n",
       "│         azure_group_name, azure_storage_account_name                                                            │\n",
       "│     )                                                                                                           │\n",
       "│     azure_storage_keys = {v.key_name: v.value for v in azure_storage_keys.keys}                                 │\n",
       "│     azure_credential = azure_storage_keys['key1']                                                               │\n",
       "│                                                                                                                 │\n",
       "│     azure_status = prediction.to_azure_blob_storage(                                                            │\n",
       "│         uri=\"{fill in azure_target_uri}\",                                                                       │\n",
       "│         credential=azure_credential                                                                             │\n",
       "│     )                                                                                                           │\n",
       "│                                                                                                                 │\n",
       "│     # Push the prediction results to a MySQL database                                                           │\n",
       "│     mysql_status = prediction.to_mysql(                                                                         │\n",
       "│         username=\"{fill in mysql_db_username}\",                                                                 │\n",
       "│         password=\"{fill in mysql_db_password}\",                                                                 │\n",
       "│         host=\"{fill in mysql_host}\",                                                                            │\n",
       "│         database=\"{fill in mysql_database}\",                                                                    │\n",
       "│         table=\"{fill in mysql_table}\",                                                                          │\n",
       "│     )                                                                                                           │\n",
       "│                                                                                                                 │\n",
       "│     # Push the prediction results to a ClickHouse database                                                      │\n",
       "│     clickhouse_status = prediction.to_clickhouse(                                                               │\n",
       "│         username=\"{fill in clickhouse_db_username}\",                                                            │\n",
       "│         password=\"{fill in clickhouse_db_password}\",                                                            │\n",
       "│         host=\"{fill in clickhouse_host}\",                                                                       │\n",
       "│         database=\"{fill in clickhouse_database}\",                                                               │\n",
       "│         table=\"{fill in clickhouse_table}\",                                                                     │\n",
       "│         protocol=\"native\",                                                                                      │\n",
       "│     )                                                                                                           │\n",
       "│                                                                                                                 │\n",
       "│     # Download the predictions to a local directory                                                             │\n",
       "│     # In this example, the prediction results are downloaded                                                    │\n",
       "│     # to a temporary directory                                                                                  │\n",
       "│     with tempfile.TemporaryDirectory(prefix=\"predictions_results_\") as d:                                       │\n",
       "│         prediction.to_local(path=d)                                                                             │\n",
       "│         # Check the downloaded prediction files                                                                 │\n",
       "│         downloaded_files = sorted(list(os.listdir(d)))                                                          │\n",
       "│         print(downloaded_files)                                                                                 │\n",
       "│                                                                                                                 │\n",
       "│                                                                                                                 │\n",
       "│     # Check the status                                                                                          │\n",
       "│     s3_status.wait()                                                                                            │\n",
       "│     azure_status.progress_bar()                                                                                 │\n",
       "│     mysql_status.progress_bar()                                                                                 │\n",
       "│     clickhouse_status.progress_bar()                                                                            │\n",
       "│                                                                                                                 │\n",
       "│     # Delete the prediction                                                                                     │\n",
       "│     prediction.delete()                                                                                         │\n",
       "│                                                                                                                 │\n",
       "│ ╭────────────────────────────────────────────────── stdout ───────────────────────────────────────────────────╮ │\n",
       "│ │                         prediction_uuid              created  ... error ready                               │ │\n",
       "│ │ 0  497a1c21-ca14-414a-beb6-b1ab0e7b8749  2022-11-02T10:34:24  ...  None  True                               │ │\n",
       "│ │                                                                                                             │ │\n",
       "│ │ [1 rows x 8 columns]                                                                                        │ │\n",
       "│ │ [<airt.client.Prediction object>, <airt.client.Prediction object>,      │ │\n",
       "│ │ <airt.client.Prediction object>, <airt.client.Prediction object>,       │ │\n",
       "│ │ <airt.client.Prediction object>, <airt.client.Prediction object>,       │ │\n",
       "│ │ <airt.client.Prediction object>, <airt.client.Prediction object>,       │ │\n",
       "│ │ <airt.client.Prediction object>, <airt.client.Prediction object>,       │ │\n",
       "│ │ <airt.client.Prediction object>, <airt.client.Prediction object>]       │ │\n",
       "│ │                          prediction_uuid              created  ready                                        │ │\n",
       "│ │ 0   883bac83-1376-4139-8f2b-1a5d60b59043  2022-11-02T08:49:52   True                                        │ │\n",
       "│ │ 1   2713fc2c-8a46-4e46-8e4b-3f8c44ad1a3a  2022-11-02T08:50:55   True                                        │ │\n",
       "│ │ 2   f3ae698e-3a2a-4dc6-8eb8-cf358f8851a9  2022-11-02T08:50:56   True                                        │ │\n",
       "│ │ 3   cad071a7-6e6e-40fe-97db-1f3107665e4b  2022-11-02T08:51:07   True                                        │ │\n",
       "│ │ 4   07507373-c927-437d-9024-41cb928404a2  2022-11-02T08:52:32   True                                        │ │\n",
       "│ │ 5   4f017211-0b39-4666-b184-73f5b570a18a  2022-11-02T08:52:57   True                                        │ │\n",
       "│ │ 6   cbc2a3a6-75ca-478b-8871-85fcc677c47b  2022-11-02T08:53:03   True                                        │ │\n",
       "│ │ 7   272f3840-d43a-412c-b7e9-6583e57e4ce8  2022-11-02T08:53:32   True                                        │ │\n",
       "│ │ 8   eb3ebcec-0b24-49fe-b62d-2f7a85025d0f  2022-11-02T08:54:23   True                                        │ │\n",
       "│ │ 9   2187b579-9889-481b-b0aa-b682e79f7bad  2022-11-02T08:54:47   True                                        │ │\n",
       "│ │ 10  f32900e3-fb83-4ccf-96ed-aac2d9b48b25  2022-11-02T10:00:03   True                                        │ │\n",
       "│ │ 11  497a1c21-ca14-414a-beb6-b1ab0e7b8749  2022-11-02T10:34:24   True                                        │ │\n",
       "│ │               Score                                                                                         │ │\n",
       "│ │ user_id                                                                                                     │ │\n",
       "│ │ 520088904  0.979853                                                                                         │ │\n",
       "│ │ 530496790  0.979157                                                                                         │ │\n",
       "│ │ 561587266  0.979055                                                                                         │ │\n",
       "│ │ 518085591  0.978915                                                                                         │ │\n",
       "│ │ 558856683  0.977960                                                                                         │ │\n",
       "│ │ 520772685  0.004043                                                                                         │ │\n",
       "│ │ 514028527  0.003890                                                                                         │ │\n",
       "│ │ 518574284  0.001346                                                                                         │ │\n",
       "│ │ 532364121  0.001341                                                                                         │ │\n",
       "│ │ 532647354  0.001139                                                                                         │ │\n",
       "│ │ ['part.0.parquet']                                                                                          │ │\n",
       "│ │                                                                                                             │ │\n",
       "│ ╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯ │\n",
       "│ ╭────────────────────────────────────────────────── stderr ───────────────────────────────────────────────────╮ │\n",
       "│ │                                                                                                             │ │\n",
       "│ │   0%|          | 0/1 [00:00<?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:05<?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:10<?, ?it/s]                                                                       │ │\n",
       "│ │ 100%|██████████| 1/1 [00:15<00:00,  5.05s/it]                                                               │ │\n",
       "│ │ 100%|██████████| 1/1 [00:15<00:00, 15.19s/it]                                                               │ │\n",
       "│ │                                                                                                             │ │\n",
       "│ │   0%|          | 0/1 [00:00<?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:05<?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:10<?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:15<?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:20<?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:25<?, ?it/s]                                                                       │ │\n",
       "│ │ 100%|██████████| 1/1 [00:30<00:00,  5.05s/it]                                                               │ │\n",
       "│ │ 100%|██████████| 1/1 [00:30<00:00, 30.33s/it]                                                               │ │\n",
       "│ │                                                                                                             │ │\n",
       "│ │   0%|          | 0/5 [00:00<?, ?it/s]                                                                       │ │\n",
       "│ │ 100%|██████████| 5/5 [00:00<00:00, 149.65it/s]                                                              │ │\n",
       "│ │                                                                                                             │ │\n",
       "│ │   0%|          | 0/3 [00:00<?, ?it/s]                                                                       │ │\n",
       "│ │ 100%|██████████| 3/3 [00:05<00:00,  1.69s/it]                                                               │ │\n",
       "│ │ 100%|██████████| 3/3 [00:05<00:00,  1.69s/it]                                                               │ │\n",
       "│ │                                                                                                             │ │\n",
       "│ │   0%|          | 0/1 [00:00<?, ?it/s]                                                                       │ │\n",
       "│ │ 100%|██████████| 1/1 [00:02<00:00,  2.82s/it]                                                               │ │\n",
       "│ │ 100%|██████████| 1/1 [00:02<00:00,  2.82s/it]                                                               │ │\n",
       "│ │                                                                                                             │ │\n",
       "│ │   0%|          | 0/1 [00:00<?, ?it/s]                                                                       │ │\n",
       "│ │ 100%|██████████| 1/1 [00:05<00:00,  5.09s/it]                                                               │ │\n",
       "│ │ 100%|██████████| 1/1 [00:05<00:00,  5.09s/it]                                                               │ │\n",
       "│ │                                                                                                             │ │\n",
       "│ │   0%|          | 0/1 [00:00<?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:05<?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:10<?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:15<?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:20<?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:25<?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:30<?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:35<?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:40<?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:45<?, ?it/s]                                                                       │ │\n",
       "│ │   0%|          | 0/1 [00:50<?, ?it/s]                                                                       │ │\n",
       "│ │ 100%|██████████| 1/1 [00:55<00:00,  5.06s/it]                                                               │ │\n",
       "│ │ 100%|██████████| 1/1 [00:55<00:00, 55.58s/it]                                                               │ │\n",
       "│ │                                                                                                             │ │\n",
       "│ │   0%|          | 0/1 [00:00<?, ?it/s]                                                                       │ │\n",
       "│ │ 100%|██████████| 1/1 [00:00<00:00, 25.66it/s]                                                               │ │\n",
       "│ │                                                                                                             │ │\n",
       "│ ╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯ │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a test s3 bucket for pushing predictions results\n",
    "\n",
    "Client.get_token()\n",
    "\n",
    "user_details = User.details()\n",
    "DEV_BUCKET_NAME = f'{os.environ[\"STORAGE_BUCKET_PREFIX\"]}-eu-west-1'\n",
    "TEST_OBJECT_NAME = f\"{user_details['uuid']}/test_API_prediction_to_s3\"\n",
    "PREDICTION_TO_S3_URL = f\"s3://{DEV_BUCKET_NAME}/{TEST_OBJECT_NAME}\"\n",
    "\n",
    "# Create a new key in the s3 bucket\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "try:\n",
    "    s3_client.create_bucket(\n",
    "        Bucket=DEV_BUCKET_NAME,\n",
    "        CreateBucketConfiguration={\"LocationConstraint\": \"eu-west-1\"},\n",
    "    )\n",
    "except s3_client.exceptions.BucketAlreadyOwnedByYou as e:\n",
    "    logger.info(\"Bucket already created\")\n",
    "\n",
    "s3_client.put_object(Bucket=DEV_BUCKET_NAME, Key=(TEST_OBJECT_NAME + \"/\"))\n",
    "\n",
    "# Run example for _docstring_example\n",
    "username = os.environ[SERVICE_USERNAME]\n",
    "password = os.environ[SERVICE_PASSWORD]\n",
    "\n",
    "run_examples_from_docstring(\n",
    "    _docstring_example,\n",
    "    azure_subscription_id=os.environ[\"AZURE_SUBSCRIPTION_ID\"],\n",
    "    azure_client_id=os.environ[\"AZURE_CLIENT_ID\"],\n",
    "    azure_client_secret=os.environ[\"AZURE_CLIENT_SECRET\"],\n",
    "    azure_tenant_id=os.environ[\"AZURE_TENANT_ID\"],\n",
    "    azure_group_name=\"test-airt-service\",\n",
    "    azure_storage_account_name=\"testairtservice\",\n",
    "    username=username,\n",
    "    password=password,\n",
    "    uri=TEST_S3_URI,\n",
    "    file_type=\"parquet\",\n",
    "    index_column=\"user_id\",\n",
    "    sort_by=\"event_time\",\n",
    "    client_column=\"user_id\",\n",
    "    target_column=\"category_code\",\n",
    "    s3_target_uri=PREDICTION_TO_S3_URL,\n",
    "    azure_target_uri=TEST_AZURE_PUSH_URI,\n",
    "    mysql_host=os.environ[\"DB_HOST\"],\n",
    "    mysql_database=os.environ[\"DB_DATABASE\"],\n",
    "    mysql_table=\"prediction_to_mysql\",\n",
    "    mysql_db_username=os.environ[\"DB_USERNAME\"],\n",
    "    mysql_db_password=os.environ[\"DB_PASSWORD\"],\n",
    "    clickhouse_host=os.environ.get(\"CLICKHOUSE_HOST\"),\n",
    "    clickhouse_database=os.environ.get(\"CLICKHOUSE_DATABASE\"),\n",
    "    clickhouse_table=\"test_clickhouse_push_prediction_airt_client\",\n",
    "    clickhouse_db_username=os.environ[\"CLICKHOUSE_USERNAME\"],\n",
    "    clickhouse_db_password=os.environ[\"CLICKHOUSE_PASSWORD\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "add_example_to_docs(Prediction, _docstring_example.__doc__)  # type: ignore\n",
    "add_example_to_docs(Prediction.ls, _docstring_example.__doc__)  # type: ignore\n",
    "add_example_to_docs(Prediction.as_df, _docstring_example.__doc__)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context manager for creating and a trained model id\n",
    "\n",
    "# Authentication\n",
    "Client.get_token()\n",
    "\n",
    "_prediction = None\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def generate_prediction(force_create: bool = False):\n",
    "    global _prediction\n",
    "\n",
    "    if _prediction is None or force_create:\n",
    "        # Create a s3 datasource\n",
    "        db = DataBlob.from_s3(\n",
    "            uri=TEST_S3_URI,\n",
    "            access_key=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "            secret_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "            cloud_provider=\"aws\",\n",
    "            region=\"eu-west-1\",\n",
    "        )\n",
    "\n",
    "        db.progress_bar()\n",
    "        display(f\"{db.uuid=}\")\n",
    "        assert len(db.uuid.replace(\"-\", \"\")) == 32\n",
    "\n",
    "        ds = db.to_datasource(\n",
    "            file_type=\"parquet\", index_column=\"user_id\", sort_by=\"event_time\"\n",
    "        )\n",
    "\n",
    "        display(f\"{ds.uuid=}\")\n",
    "        assert len(ds.uuid.replace(\"-\", \"\")) == 32\n",
    "\n",
    "        ds.progress_bar()\n",
    "\n",
    "        # Train a model\n",
    "        model = ds.train(\n",
    "            client_column=\"user_id\",\n",
    "            target_column=\"category_code\",\n",
    "            target=\"*checkout\",\n",
    "            predict_after=timedelta(hours=3),\n",
    "        )\n",
    "        model.progress_bar()\n",
    "\n",
    "        # Run Predictions\n",
    "        _prediction = model.predict()\n",
    "        _prediction.progress_bar()\n",
    "\n",
    "    yield _prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:15<00:00, 15.21s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"db.uuid='bc63fa44-0184-464a-8f47-ac6dbb2d5310'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"ds.uuid='37a7513d-bc17-4b08-ad5e-906802728bc4'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:30<00:00, 30.34s/it]\n",
      "100%|██████████| 5/5 [00:00<00:00, 125.26it/s]\n",
      "100%|██████████| 3/3 [00:10<00:00,  3.38s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'part.0.parquet': 'https://s3.eu-west-1.amazonaws.com/harish-airt-client-dev-eu-west-1/1/prediction/18/part.0.parquet?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=********************%2F20221102%2Feu-west-1%2Fs3%2Faws4_request&X-Amz-Date=20221102T103650Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=06f499f5593177531237ab5d7dffa3ed6483e74031666b61d0ae81a92226ac2b'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'part.0.parquet'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://s3.eu-west-1.amazonaws.com/harish-airt-client-dev-eu-west-1/1/prediction/18/part.0.parquet?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=********************%2F20221102%2Feu-west-1%2Fs3%2Faws4_request&X-Amz-Date=20221102T103650Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=06f499f5593177531237ab5d7dffa3ed6483e74031666b61d0ae81a92226ac2b'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"downloaded_files=['part.0.parquet']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for Prediction._download_prediction_file_to_local\n",
    "# Testing positive scenario\n",
    "\n",
    "with generate_prediction() as prediction:\n",
    "    # Get sample files URL to download\n",
    "    response = Client._get_data(relative_url=f\"/prediction/{prediction.uuid}/to_local\")\n",
    "    display(response)\n",
    "    with tempfile.TemporaryDirectory(prefix=\"test_to_local_\") as d:\n",
    "        assert os.listdir(d) == []\n",
    "        display(list(os.listdir(d)))\n",
    "\n",
    "        for file_name, url in response.items():\n",
    "            display(file_name, url)\n",
    "            Prediction._download_prediction_file_to_local(file_name, url, d)\n",
    "\n",
    "        downloaded_files = sorted(list(os.listdir(d)))\n",
    "        assert downloaded_files == [\"part.0.parquet\"], downloaded_files\n",
    "        display(f\"{downloaded_files=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"str(e.value)='403 Client Error: Forbidden for url: https://random-name.s3.amazonaws.com/random-object'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for Prediction._download_prediction_file_to_local\n",
    "# Testing negative scenario. Passing invalid url.\n",
    "\n",
    "with generate_prediction() as prediction:\n",
    "    # Get sample files URL to download\n",
    "    response = {\"random-name\": \"https://random-name.s3.amazonaws.com/random-object\"}\n",
    "\n",
    "    with tempfile.TemporaryDirectory(prefix=\"test_to_local_\") as d:\n",
    "        for file_name, url in response.items():\n",
    "            with pytest.raises(requests.exceptions.HTTPError) as e:\n",
    "                Prediction._download_prediction_file_to_local(file_name, url, d)\n",
    "\n",
    "        display(f\"{str(e.value)=}\")\n",
    "        assert \"403 Client Error\" in str(e.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "def details(self: Prediction) -> pd.DataFrame:\n",
    "    \"\"\"Return the details of a prediction.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame encapsulating the details of the prediction.\n",
    "\n",
    "    Raises:\n",
    "        ConnectionError: If the server address is invalid or not reachable.\n",
    "    \"\"\"\n",
    "    response = Client._get_data(relative_url=f\"/prediction/{self.uuid}\")\n",
    "\n",
    "    df = pd.DataFrame(response, index=[0])[Prediction.ALL_PRED_COLS]\n",
    "\n",
    "    df = df.rename(columns=Prediction.COLS_TO_RENAME)\n",
    "\n",
    "    return add_ready_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "add_example_to_docs(Prediction.details, _docstring_example.__doc__)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_uuid</th>\n",
       "      <th>created</th>\n",
       "      <th>model_uuid</th>\n",
       "      <th>datasource_uuid</th>\n",
       "      <th>region</th>\n",
       "      <th>cloud_provider</th>\n",
       "      <th>error</th>\n",
       "      <th>ready</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a4f72526-c7be-4067-9d01-373c47082062</td>\n",
       "      <td>2022-11-02T10:36:40</td>\n",
       "      <td>b6b5a9c2-3dc9-4bf5-933e-5a7e02fa155d</td>\n",
       "      <td>37a7513d-bc17-4b08-ad5e-906802728bc4</td>\n",
       "      <td>eu-west-1</td>\n",
       "      <td>aws</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        prediction_uuid              created  \\\n",
       "0  a4f72526-c7be-4067-9d01-373c47082062  2022-11-02T10:36:40   \n",
       "\n",
       "                             model_uuid                       datasource_uuid  \\\n",
       "0  b6b5a9c2-3dc9-4bf5-933e-5a7e02fa155d  37a7513d-bc17-4b08-ad5e-906802728bc4   \n",
       "\n",
       "      region cloud_provider error  ready  \n",
       "0  eu-west-1            aws  None   True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for Prediction.details\n",
    "\n",
    "with generate_prediction() as prediction:\n",
    "    # getting the details\n",
    "    df = prediction.details()\n",
    "\n",
    "    display(df)\n",
    "    assert df.prediction_uuid[0] == prediction.uuid\n",
    "    assert df.shape == (1, len(Prediction.ALL_PRED_COLS) - 1), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"e.value=ValueError('The prediction uuid is incorrect. Please try again.')\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for Prediction.details\n",
    "# Testing negative scenario. Passing invalid data ID\n",
    "\n",
    "with pytest.raises(ValueError) as e:\n",
    "    pred = Prediction(uuid=RANDOM_UUID_FOR_TESTING)\n",
    "    pred.details()\n",
    "\n",
    "display(f\"{e.value=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "def delete(self: Prediction) -> pd.DataFrame:\n",
    "    \"\"\"Delete a prediction from the server.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame encapsulating the details of the deleted prediction.\n",
    "\n",
    "    Raises:\n",
    "        ConnectionError: If the server address is invalid or not reachable.\n",
    "    \"\"\"\n",
    "    response = Client._delete_data(relative_url=f\"/prediction/{self.uuid}\")\n",
    "\n",
    "    df = pd.DataFrame(response, index=[0])[Prediction.BASIC_PRED_COLS]\n",
    "\n",
    "    df = df.rename(columns=Prediction.COLS_TO_RENAME)\n",
    "\n",
    "    return add_ready_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "add_example_to_docs(Prediction.delete, _docstring_example.__doc__)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_uuid</th>\n",
       "      <th>created</th>\n",
       "      <th>ready</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a4f72526-c7be-4067-9d01-373c47082062</td>\n",
       "      <td>2022-11-02T10:36:40</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        prediction_uuid              created  ready\n",
       "0  a4f72526-c7be-4067-9d01-373c47082062  2022-11-02T10:36:40   True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"e.value=ValueError('The prediction has already been deleted.')\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for Prediction.delete\n",
    "\n",
    "with generate_prediction() as prediction:\n",
    "    df = prediction.delete()\n",
    "\n",
    "    display(df)\n",
    "\n",
    "    assert df.shape == (1, 3), df.shape\n",
    "    assert df.prediction_uuid[0] == prediction.uuid\n",
    "\n",
    "    # Testing negative scenario. Deleting already deleted model\n",
    "    with pytest.raises(ValueError) as e:\n",
    "        prediction.delete()\n",
    "\n",
    "    display(f\"{e.value=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pred_uuid_list=['883bac83-1376-4139-8f2b-1a5d60b59043', '2713fc2c-8a46-4e46-8e4b-3f8c44ad1a3a', 'f3ae698e-3a2a-4dc6-8eb8-cf358f8851a9', 'cad071a7-6e6e-40fe-97db-1f3107665e4b', '07507373-c927-437d-9024-41cb928404a2', '4f017211-0b39-4666-b184-73f5b570a18a', 'cbc2a3a6-75ca-478b-8871-85fcc677c47b', '272f3840-d43a-412c-b7e9-6583e57e4ce8', 'eb3ebcec-0b24-49fe-b62d-2f7a85025d0f', '2187b579-9889-481b-b0aa-b682e79f7bad', 'f32900e3-fb83-4ccf-96ed-aac2d9b48b25']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"pred_uuid_list=['7243b10c-c655-4833-983c-e0818a80f235', 'c1a7b2a0-6e8b-4663-9d52-a784bd4dd50e', 'ca9eac04-9a44-4568-8316-ac04f24cabe4', 'ee6714f5-e6c6-45a6-94eb-9dac2d1a8264', 'c66f06ef-c88f-4dcc-a80d-741fe528c503', '497a1c21-ca14-414a-beb6-b1ab0e7b8749', 'a4f72526-c7be-4067-9d01-373c47082062']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for Prediction.ls\n",
    "# Testing with disabled flag\n",
    "\n",
    "with generate_prediction() as prediction:\n",
    "    uuid = prediction.uuid\n",
    "\n",
    "    # Passing disabled=False. Should show only the active predictions.\n",
    "    predx = Prediction.ls()\n",
    "    pred_uuid_list = [pred.uuid for pred in predx]\n",
    "\n",
    "    display(f\"{pred_uuid_list=}\")\n",
    "    assert uuid not in pred_uuid_list\n",
    "\n",
    "    # Passing disabled=True. Should show only the deleted predictions.\n",
    "    predx = Prediction.ls(disabled=True)\n",
    "    pred_uuid_list = [pred.uuid for pred in predx]\n",
    "\n",
    "    display(f\"{pred_uuid_list=}\")\n",
    "    assert uuid in pred_uuid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:15<00:00, 15.19s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"db.uuid='09276f4e-fa31-449d-955a-8a4105635620'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"ds.uuid='ae398ccb-eaba-4570-8fc1-9c65dd7f3929'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:30<00:00, 30.34s/it]\n",
      "100%|██████████| 5/5 [00:00<00:00, 118.23it/s]\n",
      "100%|██████████| 3/3 [00:10<00:00,  3.38s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'len(predx)=12'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'len(predx)=3'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'len(predx)=0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for Prediction ls\n",
    "\n",
    "with generate_prediction(force_create=True) as prediction:\n",
    "    # Testing list without offset and limit\n",
    "    predx = Prediction.ls()\n",
    "\n",
    "    display(f\"{len(predx)=}\")\n",
    "    assert len(predx) > 0\n",
    "\n",
    "    # Testing list with offset and limit\n",
    "    offset = 1\n",
    "    limit = 3\n",
    "\n",
    "    predx = Prediction.ls(offset=offset, limit=limit)\n",
    "\n",
    "    display(f\"{len(predx)=}\")\n",
    "    assert 0 <= len(predx) <= limit\n",
    "\n",
    "    # Testing list with invalid offset and limit\n",
    "    offset = 1_000_000_000\n",
    "    limit = 3\n",
    "\n",
    "    predx = Prediction.ls(offset=offset, limit=limit)\n",
    "\n",
    "    display(f\"{len(predx)=}\")\n",
    "    assert predx == []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_uuid</th>\n",
       "      <th>created</th>\n",
       "      <th>ready</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>883bac83-1376-4139-8f2b-1a5d60b59043</td>\n",
       "      <td>2022-11-02T08:49:52</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2713fc2c-8a46-4e46-8e4b-3f8c44ad1a3a</td>\n",
       "      <td>2022-11-02T08:50:55</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f3ae698e-3a2a-4dc6-8eb8-cf358f8851a9</td>\n",
       "      <td>2022-11-02T08:50:56</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cad071a7-6e6e-40fe-97db-1f3107665e4b</td>\n",
       "      <td>2022-11-02T08:51:07</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07507373-c927-437d-9024-41cb928404a2</td>\n",
       "      <td>2022-11-02T08:52:32</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4f017211-0b39-4666-b184-73f5b570a18a</td>\n",
       "      <td>2022-11-02T08:52:57</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cbc2a3a6-75ca-478b-8871-85fcc677c47b</td>\n",
       "      <td>2022-11-02T08:53:03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>272f3840-d43a-412c-b7e9-6583e57e4ce8</td>\n",
       "      <td>2022-11-02T08:53:32</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>eb3ebcec-0b24-49fe-b62d-2f7a85025d0f</td>\n",
       "      <td>2022-11-02T08:54:23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2187b579-9889-481b-b0aa-b682e79f7bad</td>\n",
       "      <td>2022-11-02T08:54:47</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>f32900e3-fb83-4ccf-96ed-aac2d9b48b25</td>\n",
       "      <td>2022-11-02T10:00:03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6ff64784-a5ab-4433-8cee-028905eb2e77</td>\n",
       "      <td>2022-11-02T10:37:58</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         prediction_uuid              created  ready\n",
       "0   883bac83-1376-4139-8f2b-1a5d60b59043  2022-11-02T08:49:52   True\n",
       "1   2713fc2c-8a46-4e46-8e4b-3f8c44ad1a3a  2022-11-02T08:50:55   True\n",
       "2   f3ae698e-3a2a-4dc6-8eb8-cf358f8851a9  2022-11-02T08:50:56   True\n",
       "3   cad071a7-6e6e-40fe-97db-1f3107665e4b  2022-11-02T08:51:07   True\n",
       "4   07507373-c927-437d-9024-41cb928404a2  2022-11-02T08:52:32   True\n",
       "5   4f017211-0b39-4666-b184-73f5b570a18a  2022-11-02T08:52:57   True\n",
       "6   cbc2a3a6-75ca-478b-8871-85fcc677c47b  2022-11-02T08:53:03   True\n",
       "7   272f3840-d43a-412c-b7e9-6583e57e4ce8  2022-11-02T08:53:32   True\n",
       "8   eb3ebcec-0b24-49fe-b62d-2f7a85025d0f  2022-11-02T08:54:23   True\n",
       "9   2187b579-9889-481b-b0aa-b682e79f7bad  2022-11-02T08:54:47   True\n",
       "10  f32900e3-fb83-4ccf-96ed-aac2d9b48b25  2022-11-02T10:00:03   True\n",
       "11  6ff64784-a5ab-4433-8cee-028905eb2e77  2022-11-02T10:37:58   True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tests for Prediction.as_df:\n",
    "\n",
    "predx = Prediction.ls()\n",
    "\n",
    "df = Prediction.as_df(predx)\n",
    "\n",
    "assert df.shape == (len(predx), len(Prediction.BASIC_PRED_COLS) - 1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_uuid</th>\n",
       "      <th>created</th>\n",
       "      <th>ready</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [prediction_uuid, created, ready]\n",
       "Index: []"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tests for Prediction.as_df:\n",
    "# Passing empty predx list\n",
    "\n",
    "predx = []\n",
    "\n",
    "df = Prediction.as_df(predx)\n",
    "\n",
    "assert df.shape == (len(predx), len(Prediction.BASIC_PRED_COLS) - 1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "def to_pandas(self: Prediction) -> pd.DataFrame:\n",
    "    \"\"\"Return the prediction results as a pandas DataFrame\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame encapsulating the results of the prediction.\n",
    "\n",
    "    Raises:\n",
    "        ConnectionError: If the server address is invalid or not reachable.\n",
    "    \"\"\"\n",
    "    response = Client._get_data(relative_url=f\"/prediction/{self.uuid}/pandas\")\n",
    "    keys = list(response.keys())\n",
    "    keys.remove(\"Score\")\n",
    "    index_name = keys[0]\n",
    "    return (\n",
    "        pd.DataFrame(response)\n",
    "        .set_index(index_name)\n",
    "        .sort_values(\"Score\", ascending=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "add_example_to_docs(Prediction.to_pandas, _docstring_example.__doc__)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>520088904</th>\n",
       "      <td>0.979853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530496790</th>\n",
       "      <td>0.979157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561587266</th>\n",
       "      <td>0.979055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518085591</th>\n",
       "      <td>0.978915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558856683</th>\n",
       "      <td>0.977960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520772685</th>\n",
       "      <td>0.004043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514028527</th>\n",
       "      <td>0.003890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518574284</th>\n",
       "      <td>0.001346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532364121</th>\n",
       "      <td>0.001341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532647354</th>\n",
       "      <td>0.001139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Score\n",
       "user_id            \n",
       "520088904  0.979853\n",
       "530496790  0.979157\n",
       "561587266  0.979055\n",
       "518085591  0.978915\n",
       "558856683  0.977960\n",
       "520772685  0.004043\n",
       "514028527  0.003890\n",
       "518574284  0.001346\n",
       "532364121  0.001341\n",
       "532647354  0.001139"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for prediction.to_pandas:\n",
    "# Checking positive scenario. Passing all the required variables\n",
    "\n",
    "with generate_prediction() as prediction:\n",
    "    display(prediction.to_pandas())\n",
    "    assert prediction.to_pandas().shape == (10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "def to_s3(\n",
    "    self: Prediction,\n",
    "    uri: str,\n",
    "    access_key: Optional[str] = None,\n",
    "    secret_key: Optional[str] = None,\n",
    ") -> ProgressStatus:\n",
    "    \"\"\"Push the prediction results to the target AWS S3 bucket.\n",
    "\n",
    "    Args:\n",
    "        uri: Target S3 bucket uri.\n",
    "        access_key: Access key for the target S3 bucket. If **None** (default value), then the value\n",
    "            from **AWS_ACCESS_KEY_ID** environment variable is used.\n",
    "        secret_key: Secret key for the target S3 bucket. If **None** (default value), then the value\n",
    "            from **AWS_SECRET_ACCESS_KEY** environment variable is used.\n",
    "\n",
    "    Returns:\n",
    "        An instance of `ProgressStatus` class.\n",
    "\n",
    "    Raises:\n",
    "        ConnectionError: If the server address is invalid or not reachable.\n",
    "    \"\"\"\n",
    "    access_key = (\n",
    "        access_key if access_key is not None else os.environ[\"AWS_ACCESS_KEY_ID\"]\n",
    "    )\n",
    "    secret_key = (\n",
    "        secret_key if secret_key is not None else os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "    )\n",
    "\n",
    "    response = Client._post_data(\n",
    "        relative_url=f\"/prediction/{self.uuid}/to_s3\",\n",
    "        json=dict(uri=uri, access_key=access_key, secret_key=secret_key),\n",
    "    )\n",
    "\n",
    "    return ProgressStatus(relative_url=f\"/prediction/push/{response['uuid']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "add_example_to_docs(Prediction.to_s3, _docstring_example.__doc__)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"prediction.uuid='6ff64784-a5ab-4433-8cee-028905eb2e77'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.09s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'status.is_ready()=True'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_s3_contents=['06a385d1-66a1-4ffc-8306-7f5821902fcc/test_API_prediction_to_s3/', '06a385d1-66a1-4ffc-8306-7f5821902fcc/test_API_prediction_to_s3/part.0.parquet']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'s3_contents=[]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for Prediction.to_s3\n",
    "# Testing positive scenario\n",
    "\n",
    "\n",
    "with generate_prediction() as prediction:\n",
    "    display(f\"{prediction.uuid=}\")\n",
    "\n",
    "    status = prediction.to_s3(\n",
    "        uri=PREDICTION_TO_S3_URL,\n",
    "        access_key=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "        secret_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "    )\n",
    "\n",
    "    status.progress_bar()\n",
    "\n",
    "    assert status.is_ready()\n",
    "    display(f\"{status.is_ready()=}\")\n",
    "\n",
    "\n",
    "# Check in s3 if the uploaded files are present\n",
    "time.sleep(10)\n",
    "response = s3_client.list_objects(Bucket=DEV_BUCKET_NAME, Prefix=TEST_OBJECT_NAME)\n",
    "actual_s3_contents = [content.get(\"Key\") for content in response.get(\"Contents\", [])]\n",
    "expected_s3_contents = [\n",
    "    f\"{TEST_OBJECT_NAME}/\",\n",
    "    f\"{TEST_OBJECT_NAME}/part.0.parquet\",\n",
    "]\n",
    "\n",
    "assert len(actual_s3_contents) == 2, len(actual_s3_contents)\n",
    "assert actual_s3_contents == expected_s3_contents, actual_s3_contents\n",
    "display(f\"{actual_s3_contents=}\")\n",
    "\n",
    "# Finally, delete the object in s3\n",
    "for k in actual_s3_contents:\n",
    "    s3_client.delete_object(Bucket=DEV_BUCKET_NAME, Key=k)\n",
    "\n",
    "response = s3_client.list_objects(Bucket=DEV_BUCKET_NAME, Prefix=TEST_OBJECT_NAME)\n",
    "s3_contents = [content.get(\"Key\") for content in response.get(\"Contents\", [])]\n",
    "\n",
    "assert s3_contents == [], s3_contents\n",
    "display(f\"{s3_contents=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"prediction.uuid='6ff64784-a5ab-4433-8cee-028905eb2e77'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"str(e.value)='An error occurred (InvalidAccessKeyId) when calling the ListObjects operation: The AWS Access Key Id you provided does not exist in our records.'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for Prediction.to_s3\n",
    "# Testing negative scenario\n",
    "\n",
    "with generate_prediction() as prediction:\n",
    "    display(f\"{prediction.uuid=}\")\n",
    "\n",
    "    status = prediction.to_s3(\n",
    "        uri=\"s3://random-bucket-name/random-object-name\",\n",
    "        access_key=\"fake_access_key\",\n",
    "        secret_key=\"fake_secret_key\",\n",
    "    )\n",
    "\n",
    "    with pytest.raises(ValueError) as e:\n",
    "        status.progress_bar()\n",
    "\n",
    "    display(f\"{str(e.value)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "def to_azure_blob_storage(\n",
    "    self: Prediction,\n",
    "    uri: str,\n",
    "    credential: str,\n",
    ") -> ProgressStatus:\n",
    "    \"\"\"Push the prediction results to the target Azure Blob Storage.\n",
    "\n",
    "    Args:\n",
    "        uri: Target Azure Blob Storage uri.\n",
    "        credential: Credential to access the Azure Blob Storage.\n",
    "\n",
    "    Returns:\n",
    "        An instance of `ProgressStatus` class.\n",
    "\n",
    "    Raises:\n",
    "        ConnectionError: If the server address is invalid or not reachable.\n",
    "    \"\"\"\n",
    "    response = Client._post_data(\n",
    "        relative_url=f\"/prediction/{self.uuid}/to_azure_blob_storage\",\n",
    "        json=dict(uri=uri, credential=credential),\n",
    "    )\n",
    "\n",
    "    return ProgressStatus(relative_url=f\"/prediction/push/{response['uuid']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "add_example_to_docs(Prediction.to_azure_blob_storage, _docstring_example.__doc__)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"prediction.uuid='6ff64784-a5ab-4433-8cee-028905eb2e77'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.10s/it]\n"
     ]
    }
   ],
   "source": [
    "# Tests for prediction.to_azure_blob_storage\n",
    "# Positive scenario: Passing the credential in the parameter\n",
    "\n",
    "storage_client = StorageManagementClient(\n",
    "    DefaultAzureCredential(), os.environ[\"AZURE_SUBSCRIPTION_ID\"]\n",
    ")\n",
    "keys = storage_client.storage_accounts.list_keys(\"test-airt-service\", \"testairtservice\")\n",
    "credential = keys.keys[0].value\n",
    "\n",
    "with generate_prediction() as prediction:\n",
    "    display(f\"{prediction.uuid=}\")\n",
    "\n",
    "    status = prediction.to_azure_blob_storage(\n",
    "        uri=TEST_AZURE_PUSH_URI,\n",
    "        credential=credential,\n",
    "    )\n",
    "\n",
    "    status.progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"prediction.uuid='6ff64784-a5ab-4433-8cee-028905eb2e77'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"str(e.value)='Unable to determine account name for shared key credential.'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for prediction.to_azure_blob_storage\n",
    "# Testing negative scenario\n",
    "\n",
    "with generate_prediction() as prediction:\n",
    "    display(f\"{prediction.uuid=}\")\n",
    "\n",
    "    status = prediction.to_azure_blob_storage(\n",
    "        uri=\"https://invalid-blob-storage-path\",\n",
    "        credential=credential,\n",
    "    )\n",
    "\n",
    "    with pytest.raises(ValueError) as e:\n",
    "        status.progress_bar()\n",
    "\n",
    "    display(f\"{str(e.value)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "def to_local(\n",
    "    self: Prediction,\n",
    "    path: Union[str, Path],\n",
    "    show_progress: Optional[bool] = True,\n",
    ") -> None:\n",
    "    \"\"\"Download the prediction results to a local directory.\n",
    "\n",
    "    Args:\n",
    "        path: Local directory path.\n",
    "        show_progress: Flag to set the progressbar visibility. If not passed, then the default value **True** will be used.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the **path** is invalid.\n",
    "        HTTPError: If the presigned AWS s3 uri to download the prediction results are invalid or not reachable.\n",
    "    \"\"\"\n",
    "    response = Client._get_data(relative_url=f\"/prediction/{self.uuid}/to_local\")\n",
    "\n",
    "    # Initiate progress bar\n",
    "    t = tqdm(total=len(response), disable=not show_progress)\n",
    "\n",
    "    for file_name, url in response.items():\n",
    "        Prediction._download_prediction_file_to_local(file_name, url, Path(path))\n",
    "        t.update()\n",
    "\n",
    "    t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "add_example_to_docs(Prediction.to_local, _docstring_example.__doc__)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"prediction.uuid='6ff64784-a5ab-4433-8cee-028905eb2e77'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"downloaded_files=['part.0.parquet']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for Prediction.to_local\n",
    "# Testing positive scenario\n",
    "\n",
    "with generate_prediction() as prediction:\n",
    "    display(f\"{prediction.uuid=}\")\n",
    "\n",
    "    with tempfile.TemporaryDirectory(prefix=\"test_to_local_\") as d:\n",
    "        assert os.listdir(d) == []\n",
    "        display(list(os.listdir(d)))\n",
    "\n",
    "        r = prediction.to_local(path=d)\n",
    "        time.sleep(10)\n",
    "\n",
    "        downloaded_files = sorted(list(os.listdir(d)))\n",
    "        assert downloaded_files == [\"part.0.parquet\"], downloaded_files\n",
    "        display(f\"{downloaded_files=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"prediction.uuid='6ff64784-a5ab-4433-8cee-028905eb2e77'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"e.value=FileNotFoundError(2, 'No such file or directory')\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for Prediction.to_local\n",
    "# Testing negative scenario\n",
    "\n",
    "with generate_prediction() as prediction:\n",
    "    display(f\"{prediction.uuid=}\")\n",
    "\n",
    "    d = Path(\"my-fake-path\")\n",
    "    with pytest.raises(FileNotFoundError) as e:\n",
    "        prediction.to_local(path=d)\n",
    "\n",
    "    display(f\"{e.value=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "def to_mysql(\n",
    "    self: Prediction,\n",
    "    *,\n",
    "    host: str,\n",
    "    database: str,\n",
    "    table: str,\n",
    "    port: int = 3306,\n",
    "    username: Optional[str] = None,\n",
    "    password: Optional[str] = None,\n",
    ") -> ProgressStatus:\n",
    "    \"\"\"Push the prediction results to a mysql database.\n",
    "\n",
    "    If the database requires authentication, pass the username/password as parameters or store it in\n",
    "    the **AIRT_CLIENT_DB_USERNAME** and **AIRT_CLIENT_DB_PASSWORD** environment variables.\n",
    "\n",
    "    Args:\n",
    "        host: Database host name.\n",
    "        database: Database name.\n",
    "        table: Table name.\n",
    "        port: Host port number. If not passed, then the default value **3306** will be used.\n",
    "        username: Database username. If not passed, then the value set in the environment variable\n",
    "            **AIRT_CLIENT_DB_USERNAME** will be used else the default value \"root\" will be used.\n",
    "        password: Database password. If not passed, then the value set in the environment variable\n",
    "            **AIRT_CLIENT_DB_PASSWORD** will be used else the default value \"\" will be used.\n",
    "\n",
    "    Returns:\n",
    "        An instance of `ProgressStatus` class.\n",
    "\n",
    "    Raises:\n",
    "        ConnectionError: If the server address is invalid or not reachable.\n",
    "    \"\"\"\n",
    "    username = (\n",
    "        username if username is not None else os.environ.get(CLIENT_DB_USERNAME, \"root\")\n",
    "    )\n",
    "\n",
    "    password = (\n",
    "        password if password is not None else os.environ.get(CLIENT_DB_PASSWORD, \"\")\n",
    "    )\n",
    "\n",
    "    req_json = dict(\n",
    "        host=host,\n",
    "        port=port,\n",
    "        username=username,\n",
    "        password=password,\n",
    "        database=database,\n",
    "        table=table,\n",
    "    )\n",
    "\n",
    "    response = Client._post_data(\n",
    "        relative_url=f\"/prediction/{self.uuid}/to_mysql\", json=req_json\n",
    "    )\n",
    "\n",
    "    return ProgressStatus(relative_url=f\"/prediction/push/{response['uuid']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "add_example_to_docs(Prediction.to_mysql, _docstring_example.__doc__)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"prediction.uuid='6ff64784-a5ab-4433-8cee-028905eb2e77'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:05<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:10<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:15<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:20<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:25<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:30<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:35<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:40<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:45<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:50<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:55<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [01:00<00:00, 60.67s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# Tests for prediction.to_mysql\n",
    "# Testing positive scenario\n",
    "with generate_prediction() as prediction:\n",
    "    display(f\"{prediction.uuid=}\")\n",
    "\n",
    "    status = prediction.to_mysql(\n",
    "        host=os.environ[\"DB_HOST\"],\n",
    "        database=os.environ[\"DB_DATABASE\"],\n",
    "        table=\"prediction_to_mysql\",\n",
    "        username=os.environ[\"DB_USERNAME\"],\n",
    "        password=os.environ[\"DB_PASSWORD\"],\n",
    "    )\n",
    "\n",
    "    status.progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"prediction.uuid='6ff64784-a5ab-4433-8cee-028905eb2e77'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [01:01<?, ?it/s]\n",
      "  0%|          | 0/1 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'str(e.value)=\\'(MySQLdb.OperationalError) (2005, \"Unknown MySQL server host \\\\\\'fake-host-name\\\\\\' (-3)\")\\\\n(Background on this error at: https://sqlalche.me/e/14/e3q8)\\''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for prediction.to_mysql\n",
    "# Testing negative scenario\n",
    "with generate_prediction() as prediction:\n",
    "    display(f\"{prediction.uuid=}\")\n",
    "\n",
    "    status = prediction.to_mysql(\n",
    "        host=\"fake-host-name\", database=\"fake-database-name\", table=\"fake-table-name\"\n",
    "    )\n",
    "\n",
    "    with pytest.raises(ValueError) as e:\n",
    "        status.progress_bar()\n",
    "\n",
    "    display(f\"{str(e.value)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "def to_clickhouse(\n",
    "    self: Prediction,\n",
    "    *,\n",
    "    host: str,\n",
    "    database: str,\n",
    "    table: str,\n",
    "    protocol: str,\n",
    "    port: int = 0,\n",
    "    username: Optional[str] = None,\n",
    "    password: Optional[str] = None,\n",
    ") -> ProgressStatus:\n",
    "    \"\"\"Push the prediction results to a clickhouse database.\n",
    "\n",
    "    If the database requires authentication, pass the username/password as parameters or store it in\n",
    "    the **CLICKHOUSE_USERNAME** and **CLICKHOUSE_PASSWORD** environment variables.\n",
    "\n",
    "    Args:\n",
    "        host: Remote database host name.\n",
    "        database: Database name.\n",
    "        table: Table name.\n",
    "        protocol: Protocol to use (native/http).\n",
    "        port: Host port number. If not passed, then the default value **0** will be used.\n",
    "        username: Database username. If not passed, then the value set in the environment variable\n",
    "            **CLICKHOUSE_USERNAME** will be used else the default value \"root\" will be used.\n",
    "        password: Database password. If not passed, then the value set in the environment variable\n",
    "            **CLICKHOUSE_PASSWORD** will be used else the default value \"\" will be used.\n",
    "\n",
    "    Returns:\n",
    "        An instance of `ProgressStatus` class.\n",
    "\n",
    "    Raises:\n",
    "        ConnectionError: If the server address is invalid or not reachable.\n",
    "    \"\"\"\n",
    "    username = (\n",
    "        username\n",
    "        if username is not None\n",
    "        else os.environ.get(\"CLICKHOUSE_USERNAME\", \"root\")\n",
    "    )\n",
    "\n",
    "    password = (\n",
    "        password if password is not None else os.environ.get(\"CLICKHOUSE_PASSWORD\", \"\")\n",
    "    )\n",
    "\n",
    "    req_json = dict(\n",
    "        host=host,\n",
    "        database=database,\n",
    "        table=table,\n",
    "        protocol=protocol,\n",
    "        port=port,\n",
    "        username=username,\n",
    "        password=password,\n",
    "    )\n",
    "\n",
    "    response = Client._post_data(\n",
    "        relative_url=f\"/prediction/{self.uuid}/to_clickhouse\", json=req_json\n",
    "    )\n",
    "\n",
    "    return ProgressStatus(relative_url=f\"/prediction/push/{response['uuid']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "add_example_to_docs(Prediction.to_clickhouse, _docstring_example.__doc__)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"prediction.uuid='6ff64784-a5ab-4433-8cee-028905eb2e77'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"str(e.value)='Orig exception: Code: 210. Temporary failure in name resolution (fake-host-name:9000)'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests for prediction.to_clickhouse\n",
    "# Testing negative scenario\n",
    "with generate_prediction() as prediction:\n",
    "    display(f\"{prediction.uuid=}\")\n",
    "\n",
    "    status = prediction.to_clickhouse(\n",
    "        host=\"fake-host-name\",\n",
    "        database=\"fake-database-name\",\n",
    "        table=\"fake-table-name\",\n",
    "        protocol=\"native\",\n",
    "    )\n",
    "\n",
    "    with pytest.raises(ValueError) as e:\n",
    "        status.progress_bar()\n",
    "\n",
    "    display(f\"{str(e.value)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"prediction.uuid='6ff64784-a5ab-4433-8cee-028905eb2e77'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.08s/it]\n"
     ]
    }
   ],
   "source": [
    "# Tests for prediction.to_clickhouse\n",
    "# Testing positive scenario\n",
    "\n",
    "with generate_prediction() as prediction:\n",
    "    display(f\"{prediction.uuid=}\")\n",
    "\n",
    "    status = prediction.to_clickhouse(\n",
    "        host=os.environ.get(\"CLICKHOUSE_HOST\"),\n",
    "        database=os.environ.get(\"CLICKHOUSE_DATABASE\"),\n",
    "        table=\"test_clickhouse_push_prediction_airt_client\",\n",
    "        protocol=\"native\",\n",
    "    )\n",
    "\n",
    "    status.progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
